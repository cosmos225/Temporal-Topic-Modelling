Authors,Title,year,Abstract,Keywords
"Nguyen TT,Abdelrazek M,Nguyen DT,Aryal S,Nguyen DT,Reddy S,Nguyen QV,Khatami A,Nguyen TT,Hsu EB,Yang S",Origin of novel coronavirus causing COVID-19: A computational biology study using artificial intelligence,2022,"Origin of the COVID-19 virus (SARS-CoV-2) has been intensely debated in the scientific community since the first infected cases were detected in December 2019. The disease has caused a global pandemic, leading to deaths of thousands of people across the world and thus finding origin of this novel coronavirus is important in responding and controlling the pandemic. Recent research results suggest that bats or pangolins might be the hosts for SARS-CoV-2 based on comparative studies using its genomic sequences. This paper investigates the SARS-CoV-2 origin by using artificial intelligence (AI)-based unsupervised learning algorithms and raw genomic sequences of the virus. More than 300 genome sequences of COVID-19 infected cases collected from different countries are explored and analysed using unsupervised clustering methods. The results obtained from various AI-enabled experiments using clustering algorithms demonstrate that all examined SARS-CoV-2 genomes belong to a cluster that also contains bat and pangolin coronavirus genomes. This provides evidence strongly supporting scientific hypotheses that bats and pangolins are probable hosts for SARS-CoV-2. At the whole genome analysis level, our findings also indicate that bats are more likely the hosts for the COVID-19 virus than pangolins.","Artificial intelligence, AI, Machine learning, COVID-19, SARS-coV-2, Origin, Bat, Pangolin, Pandemic"
"Nodehi AK,Charkari NM",A metaheuristic with a neural surrogate function for Word Sense Disambiguation,2022,"Word Sense Disambiguation (WSD) is one of the earliest problems in natural language processing which aims to determine the correct sense of words in context. The semantic information provided by WSD systems is highly beneficial to many tasks such as machine translation, information extraction, and semantic parsing. In this work, a new approach for WSD is proposed which uses a neural network as a surrogate fitness function in a metaheuristic algorithm. Also, a new method for simultaneous training of word and sense embeddings is proposed in this work. Accordingly, the node2vec algorithm is employed on the WordNet graph to generate sequences containing both words and senses. These sequences are then used along with paragraphs from Wikipedia in the word2vec algorithm to generate embeddings for words and senses at the same time. In order to address data imbalance in this task, sense probability distribution data extracted from the training corpus is used in the search process of the proposed simulated annealing algorithm. Furthermore, we introduce a new approach for clustering and mapping senses in the WordNet graph, which considerably improves the accuracy of the proposed method. In this approach, nodes in the WordNet graph are clustered on the condition that no two senses of the same word be present in one cluster. Then, repeatedly, all nodes in each cluster are mapped to a randomly selected node from that cluster, meaning that the representative node can take advantage of the training instances of all the other nodes in the cluster. Training the proposed method in this work is done using the SemCor dataset and the SemEval-2015 dataset has been used as the validation set. The final evaluation of the system is performed on SensEval-2, SensEval-3, SemEval-2007, SemEval-2013, SemEval-2015, and the concatenation of all five mentioned datasets. The performance of the system is also evaluated on the four content word categories, namely, nouns, verbs, adjectives, and adverbs. Experimental results show that the proposed method achieves accuracies in the range of 74.8 to 84.6 percent in the ten aforementioned evaluation categories which are close to and in some cases better than the state of the art in this task.","Word Sense Disambiguation, Metaheuristics, Surrogate Functions, Sense Mapping"
"Tautenhain CP,Nascimento MC",SpecRp: A spectral-based community embedding algorithm,2022,"Community embeddings are useful in node classification since they allow nodes to aggregate relevant information regarding the network structure. Modularity maximization-based algorithms are the most common approach to detect communities in networks. Moreover, spectral theory plays an important role in community detection by providing a matrix representation of the network structure. However, the literature is still scarce on spectral and modularity maximization-based community embedding methods. Besides, the node features of attributed graphs are usually not considered for producing the community embeddings. This paper introduces a community embedding algorithm based on spectral theory, called SpecRp, that has an overlapping modularity maximization-based step also herein proposed. SpecRp is a community detection method that considers node attributes and vertex proximity to obtain community embeddings. Computational experiments showed that SpecRp outperformed the literature in most of the tested benchmark datasets for the node classification task. Moreover, we observed that to detect disjoint communities, SpecRp and the reference literature algorithms presented a conflicting behavior concerning performance measures. While the reference methods achieved better results for modularity, SpecRp performed better concerning the Normalized Mutual Information to the ground-truth partitions. On detecting overlapping communities, SpecRp was considerably faster than the state-of-the-art algorithms, despite presenting worse results in most of the datasets.","Community embedding, Community detection in networks, Network embedding, Spectral algorithms, Autoencoders"
"Ringer C,Nicolaou MA,Walker JA",Autohighlight: Highlight detection in League of Legends esports broadcasts via crowd-sourced data,2022,"Every minute, 500 h of footage is uploaded to Youtube.com, and ∼1900 h of footage is livestreamed on Twitch.tv. It can therefore be challenging for viewers to find the content they are most likely to enjoy. Highlight videos can entertain users who did not watch a broadcast, e.g. due to a lack of awareness, availability, or willingness. Furthermore, livestream content creators can grow their audiences by using highlights as advertisement, while also engaging casual followers who do not watch full broadcasts. However, hand-generating these videos is laborious, thus automatic highlight detection is an active research challenge. We examine automatic highlight detection by focusing on esports broadcasts. Esports are an emerging genre of sport played using a video games. We focus on League of Legends, a popular title with multiple professional leagues. Esports broadcasts are high-quality and professionally produced, mirroring traditional sports. We tackle the problem in a weakly supervised manner, utilising two datasets, one of ‘crowd-sourced’ highlight videos and one of unedited broadcasts. These datasets allow us to leverage massive data while hugely reducing the human cost of data curation and annotation. We propose two novel extensions to state-of-the-art rank-based highlight detection architectures. Firstly, a multimodal hybrid–fusion architecture that enables audio-visual highlight detection, and secondly, a smoothing step to incorporate context into decision making. Both extensions show significant improvement over state-of-the-art ranking models, in places performing nearly twice as well as competing architectures. Additionally, we examine the effectiveness of each modality and compare ranking models with classification based systems.","Highlight detection, Neural networks, Livestreaming, Deep learning, Ranking networks, Weakly supervised learning"
"Helder VG,Filomena TP,Ferreira L,Kirch G",Application of the VNS heuristic for feature selection in credit scoring problems,2022,"Credit scoring plays a major role for financial institutions when making credit-granting decisions. In this context, machine learning techniques have been used to develop credit scoring models, as they seek to recognize existing patterns in databases containing the credit history of borrowers to infer potential defaulters. However, these databases often contain a large number of variables, some of which can be noisy, leading to imprecise results and loss of performance/accuracy. In the present work, a feature selection technique is proposed based on a variable neighborhood concept, so-called VNS. The applicability of the method is assessed in conjunction with seven of the main techniques used to make default prediction in credit analysis problems. Its performance was compared to the feature selection obtained by the well-known PCA statistical method. The results indicate superior performance of the VNS in most of the applied tests, suggesting the robustness of the method.","Credit scoring, Machine learning, Feature selection"
"Evin M,Hidalgo-Munoz A,Béquet AJ,Moreau F,Tattegrain H,Berthelon C,Fort A,Jallais C",Personality trait prediction by machine learning using physiological data and driving behavior,2022,"This article explores the influence of personality on physiological data while driving in reaction to near crashes and risky situations using Machine Learning (ML). The objective is to improve the driving assistance systems in considering drivers’ characteristics. Methods: Physiological and behavioral data were recorded in sixty-three healthy volunteers during risky urban situations and analyzed using 5 ML algorithms to discriminate the driver’s personality according to Big Five Inventory and STAI trait. Seven step process was performed including data pre-processing, Electrodermal Activity (EDA) time windows selection (one by one backward and forward approach comparison with a pseudo-wrapped), personality traits assessment, input algorithms parameters optimization, algorithm comparison and personality trait cluster prediction. ROC Area Under the Curve (AUC) was used to describe improvement. Results/discussion: The pseudo-wrapped/all possibilities method comparison resulted in 8.3% on average for all personality traits and all algorithms (% of ROC AUC of backward and forward approach). The ROC AUC for the detection of the personality ranged between 0.968 to 0.974 with better detection of Openness, Agreeability and Neuroticism. Use of association between Neuroticism, Extraversion and Conscientiousness previously defined in the literature slightly improve personality detection (maximum ROC AUC of 0.961 to 0.993 for cluster). Results are discussed in terms of contribution to driving aids. Conclusion: This study is one of the first to use machine learning techniques to detect personality traits using behavioral and physiological measures in a driving context. Additionally, it questions input parameters optimization approach, time windows selection, as well as clustering and association of personality trait for detection improvement.","Driver physiological data, Personality traits, Machine learning, Anxiety, Electrodermal activity"
"Wen Y,Rahman MF,Zhuang Y,Pokojovy M,Xu H,McCaffrey P,Vo A,Walser E,Moen S,Tseng TL",Time-to-event modeling for hospital length of stay prediction for COVID-19 patients,2022,"Providing timely patient care while maintaining optimal resource utilization is one of the central operational challenges hospitals have been facing throughout the pandemic. Hospital length of stay (LOS) is an important indicator of hospital efficiency, quality of patient care, and operational resilience. Numerous researchers have developed regression or classification models to predict LOS. However, conventional models suffer from the lack of capability to make use of typically censored clinical data. We propose to use time-to-event modeling techniques, also known as survival analysis, to predict the LOS for patients based on individualized information collected from multiple sources. The performance of six proposed survival models is evaluated and compared based on clinical data from COVID-19 patients.","Length of stay, Survival analysis, Time-to-event modeling, Deep learning, COVID-19"
"Basher SA,Sadorsky P","Forecasting Bitcoin price direction with random forests: How important are interest rates, inflation, and market volatility?",2022,"Bitcoin has grown in popularity and has now attracted the attention of individual and institutional investors. Accurate Bitcoin price direction forecasts are important for determining the trend in Bitcoin prices and asset allocation. This paper addresses several unanswered questions. How important are business cycle variables like interest rates, inflation, and market volatility for forecasting Bitcoin prices? Does the importance of these variables change across time? Are the most important macroeconomic variables for forecasting Bitcoin prices the same as those for gold prices? To answer these questions, we utilize tree-based machine learning classifiers, along with traditional logit econometric models. The analysis reveals several important findings. First, random forests predict Bitcoin and gold price directions with a higher degree of accuracy than logit models. Prediction accuracy for bagging and random forests is between 75% and 80% for a five-day prediction. For 10-day to 20-day forecasts bagging and random forests record accuracies greater than 85%. Second, technical indicators are the most important features for predicting Bitcoin and gold price direction, suggesting some degree of market inefficiency. Third, oil price volatility is important for predicting Bitcoin and gold prices indicating that Bitcoin is a substitute for gold in diversifying this type of volatility. By comparison, gold prices are more influenced by inflation than Bitcoin prices, indicating that gold can be used as a hedge or diversification asset against inflation.","Forecasting, Machine learning, Random forests, Bitcoin, Gold, Inflation"
"Roegiers S,Corneillie E,Lievens F,Anseel F,Veelaert P,Philips W",Distinctive features of nonverbal behavior and mimicry in application interviews through data analysis and machine learning,2022,"This paper reveals the characteristics and effects of nonverbal behavior and human mimicry in the context of application interviews. It discloses a novel analyzation method for psychological research by utilizing machine learning. In comparison to traditional manual data analysis, machine learning proves to be able to analyze the data more deeply and to discover connections in the data invisible to the human eye. The paper describes an experiment to measure and analyze the reactions of evaluators to job applicants who adopt specific behaviors: mimicry, suppress, immediacy and natural behavior. First, evaluation of the applicant qualifications by the interviewer reveals how behavioral self-management can improve the interviewer’s opinion of the candidate. Secondly, the underlying mechanics of mimicry behavior are exposed through analysis of seven nonverbal actions. Manual data analysis determines the frequency features of the actions and answers how often the actions are performed and how often they are mimicked during application interviews. Two of the seven actions are here deemed negligible due too low frequency features. Finally, machine learning is employed to analyze the data in great detail and distinguish the four behavior categories from each other. A Random Forest classifier is able to achieve 55.2% accuracy for predicting the behavior condition of the interviews while human observers reach an accuracy of 32.9%. The feature set for the classifier is reduced to 130 features with the most important features relating to the correlations between the leaning forward actions of the interview participants.","Mimicry, Nonverbal behavior, Data analysis, Machine-learning, Classification experiment, Feature selection"
"Hossain MM,Swarna RA,Mostafiz R,Shaha P,Pinky LY,Rahman MM,Rahman W,Hossain MS,Hossain ME,Iqbal MS",Analysis of the performance of feature optimization techniques for the diagnosis of machine learning-based chronic kidney disease,2022,"Chronic kidney disease (CKD) slowly decreases one’s kidney ability. A machine learning (ML) based early CKD diagnosis scheme can be an effective solution to reduce this harm. The efficiency of ML techniques depends on the selection and use of the appropriate features. Hence, this research analysis several feature optimization approaches along with a max voting ensemble model to establish a highly accurate CKD diagnosis system by using an appropriate feature set. The ensemble model of this research is structured with five existing classifiers. Three types of feature optimization namely feature importance, feature reduction, and feature selection where for each approach two most proficient techniques are analyzed with the mentioned ensemble model. Based on all analysis the research gets a feature optimization technique called Linear discriminant analysis belonging to the feature selection approach provides the most outstanding result of 99.5% accuracy by using 10-fold cross-validation. The results of this research indicate the efficiency of feature optimization for the diagnosis of ML-based CKD.","Chronic kidney disease (CKD), Feature optimization, Feature selection, Machine learning (ML), Feature reduction, Feature importance"
"Ahmed J,Green II RC",Predicting severely imbalanced data disk drive failures with machine learning models,2022,"Datasets related to hard drive failure, particularly BackBlaze Hard Drive Data, have been widely studied in the literature using many statistical, machine learning, and deep learning techniques. These datasets are severely imbalanced due to the presence of a small number of failed drives compared to huge amounts of healthy drives in the operational data centers. It is challenging to mitigate the adverse consequence of the class imbalance due to the presence of bias towards the majority class during learning. SMART (self monitoring analysis and reporting technology) attributes of the disk drives were utilized in the past to design standard classification or regression algorithms. Although few machine learning (ML) models, for instance, tree based methods and ensemble learning algorithms, addressed the failure prediction, the effects of class imbalance were rarely properly considered under the ML framework. This study, based on a review of the state-of-the-art in the area, evaluates current methodologies to identify areas that were either overlooked or lacking, proposes methods for remediating these issues, and performs some baseline experiments to demonstrate the proposed methodologies including data sampling techniques and cost-sensitive learning.","Machine learning, Cost-sensitive learning, Class imbalance, Predictive maintenance (PdM)"
Kamath C,"Intelligent sampling for surrogate modeling, hyperparameter optimization, and data analysis",2022,"Sampling techniques are used in many fields, including design of experiments, image processing, and graphics. The techniques in each field are designed to meet the constraints specific to that field such as uniform coverage of the range of each dimension or random samples that are at least a certain distance apart from each other. When an application imposes new constraints, for example, by requiring samples in a non-rectangular domain or the addition of new samples to an existing set, a common solution is to modify the algorithm currently in use, often with less than satisfactory results. As an alternative, we propose the concept of intelligent sampling, where we devise solutions specifically tailored to meet our sampling needs, either by improving existing algorithms or by modifying suitable algorithms from other fields. Surprisingly, both qualitative and quantitative comparisons indicate that some relatively simple algorithms can be easily modified to meet the many sampling requirements of surrogate modeling, hyperparameter optimization, and data analysis; these algorithms outperform their more sophisticated counterparts currently in use, resulting in better use of time and computer resources.","Sampling, Space filling, Surrogate modeling, Hyperparameter optimization, Data analysis"
"Casola S,Lauriola I,Lavelli A",Pre-trained transformers: an empirical comparison,2022,"Pre-trained transformers have rapidly become very popular in the Natural Language Processing (NLP) community, surpassing the previous state of the art in a wide variety of tasks. While their effectiveness is indisputable, these methods are expensive to fine-tune on the target domain due to the high number of hyper-parameters; this aspect significantly affects the model selection phase and the reliability of the experimental assessment. This paper serves a double purpose: we first describe five popular transformer models and survey their typical use in previous literature, focusing on reproducibility; then, we perform comparisons in a controlled environment over a wide range of NLP tasks. Our analysis reveals that only a minority of recent NLP papers that use pre-trained transformers reported multiple runs (20%), standard deviation or statistical significance (10%), and other crucial information, seriously hurting replicability and reproducibility. Through a vast empirical comparison on real-world datasets and benchmarks, we also show how the hyper-parameters and the initial seed impact results, and highlight the low models’ robustness.","Natural Language Processing, Deep Neural Networks, Transformer models, Pre-training, Reproducibility, Survey"
"Campbell TW,Roder H,Georgantas III RW,Roder J",Exact Shapley values for local and model-true explanations of decision tree ensembles,2022,"Additive feature explanations using Shapley values have become popular for providing transparency into the relative importance of each feature to an individual prediction of a machine learning model. While Shapley values provide a unique additive feature attribution in cooperative game theory, the Shapley values that can be generated for even a single machine learning model are far from unique, with theoretical and implementational decisions affecting the resulting attributions. Here, we consider the application of Shapley values for explaining decision tree ensembles and present a novel approach to Shapley value-based feature attribution that can be applied to random forests and boosted decision trees. This new method provides attributions that accurately reflect details of the model prediction algorithm for individual instances, while being computationally competitive with one of the most widely used current methods. We explain the theoretical differences between the standard and novel approaches and compare their performance using synthetic and real data.","Explainability, Shapley values, Machine learning, Interpretability, Decision trees"
"Chetouane N,Wotawa F",On the application of clustering for extracting driving scenarios from vehicle data,2022,"If we want to extract test cases from driving data for the purpose of testing vehicles, we want to avoid using similar test cases. In this paper, we focus on this topic. We provide a method for extracting driving episodes from data utilizing clustering algorithms. This method starts with clustering driving data. Afterward, data points representing time-ordered sequences are obtained from the cluster forming a driving episode. Besides outlying the foundations, we present the results of an experimental evaluation where we considered six different clustering algorithms and available driving data from three German cities. To evaluate the cluster quality, we utilize three cluster validity metrics. In addition, we introduce a measure for the quality of extracted episodes relying on the Pearson coefficient. Experimental evaluation showed that the Pearson coefficient can rank clustering algorithms better than the three cluster validity metrics. We can extract meaningful episodes from driving data using any clustering algorithm considering four to eight clusters. Combining k-means clustering with auto-encoders leads to the best Pearson correlation. SOM is the slowest clustering method, and Canopy is the fastest.","Clustering for information extraction, Driving data extraction, Experimental evaluation, Comparison of clustering algorithms"
"Arend D,Yuwono S,Diprasetya MR,Schwung A",MLPro 1.0 - Standardized reinforcement learning and game theory in Python,2022,"Nowadays there are numerous powerful software packages available for most areas of machine learning (ML). These can be roughly divided into frameworks that solve detailed aspects of ML and those that pursue holistic approaches for one or two learning paradigms. For the implementation of own ML applications, several packages often have to be involved and integrated through individual coding. The latter aspect in particular makes it difficult for newcomers to get started. It also makes a comparison with other works difficult, if not impossible. Especially in the area of reinforcement learning (RL), there is a lack of frameworks that fully implement the current concepts up to multi-agents (MARL) and model-based agents (MBRL). For the related field of game theory (GT), there are hardly any packages available that aim to solve real-world applications. Here we would like to make a contribution and propose the new framework MLPro, which is designed for the holistic realization of hybrid ML applications across all learning paradigms. This is made possible by an additional base layer in which the fundamentals of ML (interaction, adaptation, training, hyperparameter optimization) are defined on an abstract level. In contrast, concrete learning paradigms are implemented in higher sub-frameworks that build on the conventions of this additional base layer. This ensures a high degree of standardization and functional recombinability. Proven concepts and algorithms of existing frameworks can still be used. The first version of MLPro includes sub-frameworks for RL and cooperative GT.","Machine learning, Reinforcement learning, Game theory, Automation, Scientific software development, Python"
"Chen L,Zhu H",Behavior prediction based on a Commodity Utility-Behavior Sequence model,2022,"With the rise of social e-commerce and live broadcast e-commerce, real-time recommendations based on consumers’ browsing behavior are becoming more and more important. Traditional utility recommendation has some problems such as cold start and subjectivity. And traditional sequential recommendation relies on behavior sequences. However, these data contain some irrelevant data of products, which will lead to wrong dependencies and affect the accuracy of recommendation. To solve such problems, this research builds a Commodity Utility-Behavior Sequence (CUBS) dual-utility model. CUBS consists of two models: Commodity Utility (CU) and Behavior Sequence (BS). The Commodity Utility can evaluate the psychological motivation of consumer and transform it into commodity utility. The Behavior Sequence can predict preference by calculating the behavior sequences. CUBS combines the advantages of the Commodity Utility and Behavior Sequence. At the same time, it makes up for the shortcomings of only using a single model. A total of 22,417 records of 214 customers are randomly selected from the JD.com database as the test set. These customers are divided into 4 groups and calculated by CU, BS and CUBS respectively. The results show that the accuracy of CUBS model is the highest. This also confirms that customers’ click behaviors and behavior sequences have an important influence on purchase intention prediction.","Commodity utility, Behavior sequence, Implicit feedback, Behavior prediction"
"Timilsina M,Tandan M,Nováček V",Machine learning approaches for predicting the onset time of the adverse drug events in oncology,2022,"Predicting the onset time of adverse drug events can substantially lessen the negative impact on the prognosis of cancer patients who are often subject of aggressive and highly toxic treatment regimens. However, the laboratory verification of each patient case to study the mechanics of adverse drug events requires costly, time-intensive research. Thus, to alleviate the efforts required to tackle this problem, using computational models is highly desirable. To provide a suite of such applicable models, we used openly available adverse drug event data resources called FAERS and explored various machine learning paradigms to assess their performance in predicting adverse effect onset days (since the beginning of the treatment). Among various machine learning approaches, we observed that the graph-based embedding model, particularly ComplEx, performed better than other, more traditional machine learning approaches. The embedding learned from the ComplEX trained with k-NN regression for the downstream predictive task obtained the lowest root mean square error, which we consider very promising for further research.","Regression, Onset, Drugs, Supervised, Embedding"
"Suha SA,Sanam TF",A deep convolutional neural network-based approach for detecting burn severity from skin burn images,2022,"Burns being one of the leading causes of clinically significant morbidity can lead to a dramatic physiological reaction with prolonged repercussions, metabolic disturbance, severe scarring, catastrophic organ failure, and death if not properly treated. Appropriate burn treatment management is associated with the severity of burn wounds which can be extremely challenging to anticipate at an early stage due to various factors using traditional clinical methods. Therefore, this study proposed a Deep Convolutional Neural Network (DCNN) based approach for detecting the severity of burn injury utilizing real-time images of skin burns. The DCNN architecture leverage the utilization of transfer learning with fine tuning employing three types of pretrained models on top of multiple convolutional layers with hyperparameter tuning for feature extraction from the images and then a fully connected feed forward neural network to classify the images into three categories according to their burn severity : first, second and third degree burns. In order to validate the efficacy of the suggested strategy, the study also applies a traditional solution to mitigate this multi-class categorization problem, incorporating rigorous digital image processing steps with several conventional machine learning classifiers and then conducts a comparative performance assessment. The study’s findings demonstrate that using pretrained models, the recommended DCNN model has gained significantly greater accuracy, with the highest accuracy being obtained using the VGG16 pretrained model for transfer learning with an accuracy of 95.63% . Thus, through the use of intelligent technologies, the proposed DCNN-based technique can aid healthcare practitioners in evaluating the burn damage condition and providing appropriate treatments in the shortest feasible time, remarkably reducing the unfavorable consequences of burns.","Burn severity, Deep convolutional neural network, Transfer learning, Feature extraction, Image classification"
"Terao H,Noguchi W,Iizuka H,Yamamoto M",Compressed video ensemble based pseudo-labeling for semi-supervised action recognition,2022,"Some recent studies have focused on deep learning based semi-supervised learning for action recognition. However, it is difficult to scale up their training because their input is RGB frames, the obtainment of which incurs computational and storage costs. In this paper, we propose a semi-supervised action recognition method that makes it easy to scale up the training by using features stored in compressed videos. Our method directly extracts multiple types of input features from compressed videos without any decoding and generates artificial labels of unlabeled videos through the ensembling of the predictions from these features. In addition to the standard supervised training on labeled videos, our models are trained to predict the artificial labels from strongly augmented features in unlabeled compressed videos. We show that our method is more efficient and achieves a better classification performance on some widely used datasets than conventional semi-supervised learning methods applying RGB frames.","Action recognition, Compressed video action recognition, Semi-supervised learning, Pseudo labeling"
"Wenger K,Tirdad K,Dela Cruz A,Mari A,Basheer M,Kuk C,van Rhijn BW,Zlotta AR,van der Kwast TH,Sadeghian A",A semi-supervised learning approach for bladder cancer grading,2022,"Recent advances in semi-supervised learning algorithms (SSL) have made great strides in reducing the training dependency on labeled datasets and requiring that only a subset of the data be labeled. The presented work explores a class of semi-supervised learning algorithms that uses consistency regularization and self-ensembling to leverage the unlabeled portion of the dataset. Labeling medical image datasets are time-consuming and prohibitively expensive, requiring hundreds of hours of effort from expert diagnosticians. This research presents an approach for building and training a deep learning model to grade medical images while requiring only a minimal number of labels. Consistency regularization has been used in SSL to great success in datasets of natural images but not for more complex images such as pathology slides where the dataset consists of cell patterns. This research successfully proposes and applies an SSL algorithm based on the VGG-16 neural network, which combines techniques introduced by the Π model and FixMatch algorithms to a cell pattern-based pathology image dataset. The results presented in this research show that using the proposed approach, it is possible to label only 3% of the samples in a dataset, use the remaining 97% of samples as unlabeled data, and achieve a 19% increase over the baseline accuracy. The second contribution of this research shows a ratio of labeled vs. unlabeled images in a dataset beyond which continuing to label the data increases the cost but offers little performance gains.","Artificial intelligence, Deep learning, Semi-supervised learning, Pathology, Medical digital imaging"
"Klein J,Bhulai S,Hoogendoorn M,van der Mei R",Jasmine: A new Active Learning approach to combat cybercrime,2022,"One of the reasons that the deployment of network intrusion detection methods falls short is the lack of realistic labeled datasets, which makes it challenging to develop and compare techniques. It is caused by the large amounts of effort that it takes for a cyber expert to classify network connections. This has raised the need for methods that learn from both labeled and unlabeled data which observations are best to present to the human expert. Hence, Active Learning (AL) methods are of interest. In this paper, we propose a new hybrid AL method called Jasmine. Firstly, it uses the uncertainty score and anomaly score to determine how suitable each observation is for querying, i.e., how likely it is to enhance classification. Secondly, Jasmine introduces dynamic updating. This allows the model to adjust the balance between querying uncertain, anomalous and randomly selected observations. To this end, Jasmine is able to learn the best query strategy during the labeling process. This is in contrast to the other AL methods in cybersecurity that all have static, predetermined query functions. We show that dynamic updating, and therefore Jasmine, is able to consistently obtain good and more robust results than querying only uncertainties, only anomalies or a fixed combination of the two.","Active Learning, Dynamic query function, Network intrusion detection, Human oracle, Partially labeled"
"Ren Z,Qian K,Dong F,Dai Z,Nejdl W,Yamamoto Y,Schuller BW",Deep attention-based neural networks for explainable heart sound classification,2022,"Cardiovascular diseases are the leading cause of death and severely threaten human health in daily life. There have been dramatically increasing demands from both the clinical practice and the smart home application for monitoring the heart status of individuals suffering from chronic cardiovascular diseases. However, experienced physicians who can perform efficient auscultation are still lacking in terms of number. Automatic heart sound classification leveraging the power of advanced signal processing and deep learning technologies has shown encouraging results. Nevertheless, a lack of explanation for deep neural networks is a limitation for the applications of automatic heart sound classification. To this end, we propose explaining deep neural networks for heart sound classification with an attention mechanism. We evaluate the proposed approach on the heart sounds shenzhen corpus. Our approach achieves an unweighted average recall of 51.2% for classifying three categories of heart sounds, i.e., normal, mild, and moderate/severe. The experimental results also demonstrate that the global attention pooling layer improves the performance of the learnt representations by estimating the contribution of each unit in high-level features. We further analyse the deep neural networks by visualising the attention tensors.","Computer audition, Heart sound classification, Sensor signal processing, Digital health"
"Mostafa N,Ramadan HS,Elfarouk O",Renewable energy management in smart grids by using big data analytics and machine learning,2022,"The application of big data in the energy sector is considered as one of the main elements of Energy Internet. Crucial and promising challenges exist especially with the integration of renewable energy sources and smart grids. The ability to collect data and to properly use it for better decision-making is a key feature; in this work, the benefits and challenges of implementing big data analytics for renewable energy power stations are addressed. A framework was developed for the potential implementation of big data analytics for smart grids and renewable energy power utilities. A five-step approach is proposed for predicting the smart grid stability by using five different machine learning methods. Data from a decentralized smart grid data system consisting of 60,000 instances and 12 attributes was used to predict the stability of the system through three different machine learning methods. The results of fitting the penalized linear regression model show an accuracy of 96% for the model implemented using 70% of the data as a training set. Using the random forest tree model has shown 84% accuracy, and the decision tree model has shown 78% accuracy. Both the convolutional neural network model and the gradient boosted decision tree model yielded 87% for the classification model. The main limitation of this work is that the amount of data available in the dataset is considered relatively small for big data analytics; however the cloud computing and real-time event analysis provided was suitable for big data analytics framework. Future research should include bigger datasets with variety of renewable energy sources and demand across more countries.","Energy internet, Renewable energy, Smart grid, Big data analytics, Machine learning, Predictive models"
"Temraz M,Keane MT",Solving the class imbalance problem using a counterfactual method for data augmentation,2022,"Learning from class imbalanced datasets poses challenges for many machine learning algorithms. Many real-world domains are, by definition, class imbalanced by virtue of having a majority class that naturally has many more instances than its minority class (e.g., genuine bank transactions occur much more often than fraudulent ones). Many methods have been proposed to solve the class imbalance problem, among the most popular being oversampling techniques (such as SMOTE). These methods generate synthetic instances in the minority class, to balance the dataset, performing data augmentations that improve the performance of predictive machine learning (ML). In this paper, we advance a novel, data augmentation method (adapted from eXplainable AI), that generates synthetic, counterfactual instances in the minority class. Unlike other oversampling techniques, this method adaptively combines existing instances from the dataset, using actual feature-values rather than interpolating values between instances. Several experiments using four different classifiers and 25 datasets involving binary classes are reported, which show that this Counterfactual Augmentation (CFA) method generates useful synthetic datapoints in the minority class. The experiments also show that CFA is competitive with many other oversampling methods, many of which are variants of SMOTE. The basis for CFA’s performance is discussed, along with the conditions under which it is likely to perform better or worse in future tests.","Counterfactual, Class imbalance problem, Data augmentation, XAI"
Nyamawe AS,Mining commit messages to enhance software refactorings recommendation: A machine learning approach,2022,"Software refactoring is the common practice that is applied to improve the internal structure of software systems without altering their external behaviors. Software developers sometimes apply refactoring to prepare software systems for further extensions of requirements or adaptation to new requirements often presented as feature requests. However, in such context, identifying where and what type of refactoring to use is very challenging and mostly relies on developer’s intuition and experience. To facilitate refactorings selection during feature requests implementation, existing studies have relied on the past software change history to predict and recommend future refactorings. However, none of these approaches have attempted to exploit the potential of commit messages to drive refactoring recommendation. To this end, this paper proposes a machine-learning approach trained with the past history of previously applied refactorings detected using both traditional refactoring detectors and analysis of commit messages. The approach implements binary classifier to predict the need for refactoring, and a multi-label classifier to recommend required refactorings. The evaluation of the proposed approach based on the dataset comprised of commit messages of 65 open source projects suggest that, the approach significantly outperforms the state-of-the-art approach.","Commit messages, Feature requests, Recommendation, Software refactoring, Machine learning"
"Bhandari HN,Rimal B,Pokhrel NR,Rimal R,Dahal KR,Khatri RK",Predicting stock market index using LSTM,2022,"The rapid advancement in artificial intelligence and machine learning techniques, availability of large-scale data, and increased computational capabilities of the machine opens the door to develop sophisticated methods in predicting stock price. In the meantime, easy access to investment opportunities has made the stock market more complex and volatile than ever. The world is looking for an accurate and reliable predictive model which can capture the market’s highly volatile and nonlinear behavior in a holistic framework. This study uses a long short-term memory (LSTM), a particular neural network architecture, to predict the next-day closing price of the S&P 500 index. A well-balanced combination of nine predictors is carefully constructed under the umbrella of the fundamental market data, macroeconomic data, and technical indicators to capture the behavior of the stock market in a broader sense. Single layer and multilayer LSTM models are developed using the chosen input variables, and their performances are compared using standard assessment metrics–Root Mean Square Error (RMSE), Mean Absolute Percentage Error (MAPE), and Correlation Coefficient (R). The experimental results show that the single layer LSTM model provides a superior fit and high prediction accuracy compared to multilayer LSTM models.","Stock market index, LSTM, Prediction, Machine learning, Deep learning, Denoising"
"van Ruitenbeek RE,Bhulai S",Convolutional Neural Networks for vehicle damage detection,2022,"Vehicle damages are increasingly becoming a liability for shared mobility services. The large number of handovers between drivers demands for an accurate and fast inspection system, which locates small damages and classifies these into the correct damage category. To address this, a damage detection model is developed to locate vehicle damages and classify these into twelve categories. Multiple deep learning algorithms are used, and the effect of different transfer learning and training strategies is evaluated, to optimize the detection performance. The final model, trained on more than 10,000 damage images, is able to accurately detect small damages under various conditions such as water and dirt. A performance evaluation with domain experts shows, that the model achieves comparable performance. In addition, the model is evaluated in a specially designed light street, indicating that strong reflections complicate the detection performance.","Computer vision, Image recognition, Object detection, Deep learning, Vehicle damage detection"
Garcia J,Bankruptcy prediction using synthetic sampling,2022,"The prediction of corporate bankruptcy has been widely studied. However, low bankruptcy rates lead to highly imbalanced bankruptcy class distributions, increasing the difficulty of accurately predicting a firm’s bankruptcy. Based on a large sample of 1824 U.S. firms, the study shows that classification accuracy significantly improves when the training dataset is balanced using the synthetic minority oversampling technique or one of its extensions. The results indicate that combining SMOTE with cluster-based undersampling leads to the best classification performance, and the increase in accuracy, specifically in terms of recall and AUC, is significant, thus justifying synthetic sampling when training a bankruptcy prediction classifier.","Bankruptcy, Imbalanced data, SMOTE, Oversampling, Machine learning"
"Stepinski TF,Dmowska A",Machine-learning models for spatially-explicit forecasting of future racial segregation in US cities,2022,"Residential racial segregation in large US cities is a complex phenomenon with important social, political, and economic ramifications. In this paper, we demonstrate that the prediction of future segregation can be achieved by using an empirical model generated by a machine learning (ML) algorithm. Specifically, we predict a future map of neighborhood types — racial compositions quantized to several archetypes. Within such a framework, the prediction of segregation is tantamount to the prediction of a thematic map of future neighborhood types. An ML model of change is trained on historical changes and used to make predictions. The key predicate of an ML model is the choice of attributes — variables that drive the change. We hypothesize that neighborhood type’s change of a spatial unit depends only on its present type and statistics of types in surrounding units. The paper asks and positively answers three questions. Is our hypothesis validated by the results? Does the proposed methodology yield useful predictions? Do our results agree with competing predictions? To answer these questions we train and validate a number of change models using, as the case study, 1990, 2000, 2010, and 2020 US Census Bureau block-level data for Cook County, IL (Chicago). We investigated four different algorithms, Random Forest, Gradient Boosted Trees, Neural Network, and Self-Normalizing Net, and have found that Gradient Boosted Trees (GBT) yields the best predictions. Using the GBT-generated model we make a prediction of residential segregation in Cook County in the year 2030.","Spatially-explicit forecasting, Supervised learning, Social computing, Racial segregation"
"Vanetik N,Litvak M,Krimberg S",Summarization of financial reports with TIBER,2022,"This paper reports an approach for summarizing financial texts that combine several techniques for sentence representation and neural document modeling. Our approach is extractive and it follows the classic pipeline of ranking and consequent selecting of the top-ranked text chunks. We evaluate our method on the financial reports provided in the Financial Narrative Summarization (FNS 2021) shared task. The data for the shared task was created and collected from publicly available UK annual reports published by firms listed on the London Stock Exchange. The reports composed FNS 2021 dataset are very long, have many sections, and are written in “financial” language using various special terms, numerical data, and tables. The results show that our approach outperforms the FNS topline with a very serious advantage. In addition to its performance, our approach is also time-efficient.","Extractive summarization, Financial reports, Node embeddings, BERT"
"Bellocca GP,Attanasio G,Cagliero L,Fior J",Leveraging the momentum effect in machine learning-based cryptocurrency trading,2022,"Cryptocurrency trading has become more and more popular among private investors. According to recent studies, the momentum effect influences the underlying market. Quantitative trading systems can leverage momentum indicators to open and close trading positions. However, existing approaches that exploit the momentum effect in cryptocurrency trading do not rely on machine learning. Since these systems are based on human generated rules they are not suited to highly volatile market conditions, which are quite common in cryptocurrency markets. This paper proposes to leverage machine learning approaches to automatically detect the momentum effect in cryptocurrency market data. For each cryptocurrency it estimates the likelihood of being affected by the momentum effect on the next trading day as well as the momentum direction. A backtesting session, performed on three very popular cryptocurrencies, shows that the machine learning models are able to predict, to a good approximation, short-term price volatility thus reducing the number of false trading signals and increasing the return on investments compared to state-of-the-art approaches.","Machine learning, Cryptocurrency trading, Quantitative trading systems"
"Yang X,Zhang N,Schrader P",A study of brain networks for autism spectrum disorder classification using resting-state functional connectivity,2022,"This paper presents a comprehensive and practical review of autism spectrum disorder (ASD) classification using several traditional machine learning and deep learning methods on data from the Autism Brain Imaging Data Exchange (ABIDE) repository. The objective of this study was to investigate different brain networks and determine their functional connectivity to distinguish between subjects with ASD and those considered typically developing (TD). In the experiments of this paper, functional connectivity was used as a classification feature for 871 resting-state functional magnetic resonance imaging (rs-fMRI) samples collected from the ABIDE repository. The methodology and results of this paper have three main parts. First, we reviewed eight different brain parcellation techniques used for ASD classification from structural, functional, and data-driven perspectives to identify the most promising brain atlas. Second, we evaluate the stability and efficiency of the correlation, partial correlation, and tangent space functional connectivity metrics, and identify the most stable functional connectivity metric. Third, we compared four different supervised learning models used in the ASD classification domain and evaluated the learning performance of each model. In summary, our experimental results show that Bootstrap Analysis of Stable Clusters (BASC) provides the most predictive power for ASD classification, while the correlation metric is the most stable candidate among those models considered. Furthermore, by comparing different classifiers, we conclude that among all the experimentally compared classifiers in this paper, the kernel support vector machine (kSVM) is the optimal classifier for classifying ABIDE fMRI data. The highest sensitivity 64.57% is identified in Table 7. This result was produced using the correlation metric with functional atlas BASC444 and RBF kernel SVM. The corresponding specificity is 73.61%, and the accuracy is 69.43%. Overall, this is the optimal result.","Functional connectivity, Brain networks, rs-fMRI, ASD, ROIs ABIDE, Deep Neural Network"
"Tertychnyi P,Godgildieva M,Dumas M,Ollikainen M",Time-aware and interpretable predictive monitoring system for Anti-Money Laundering,2022,"Money laundering is a global threat to society nowadays. Governments and governmental authorities fight money laundering, in part, by regulating banks and financial institutions. Financial institutions, in turn, are obligated to implement mechanisms to prevent money laundering. Usually, these prevention mechanisms include automated monitoring systems. In this paper, we propose an Anti-Money Laundering monitoring system based on machine learning techniques, which addresses three requirements: (i) generating accurate and non-redundant alerts; (ii) generating timely alerts; and (iii) associating explanations and risk estimates to each alert. The first requirement is addressed by training a machine learning classification model on different snapshots of customers’ history and then feeding the classification scores generated by this model into an alerting policy designed to prevent redundant alerts. The second requirement is addressed via custom metrics for assessing the performance of classification models, which take into account the timeliness requirements that arise in the Anti-Money Laundering domain. Finally, the third requirement is addressed by applying a method for class probability calibration and by an interpretability layer based on Shapley values. The proposed monitoring system has been designed based on requirements provided by an investigation unit at a financial institution and evaluated using real-life data as well as multiple rounds of feedback from specialized subject-matter experts.","Anti-Money Laundering, Machine learning, Predictive monitoring"
Naser MZ,Deriving mapping functions to tie anthropometric measurements to body mass index via interpretable machine learning,2022,"This paper aims at leveraging recent advancements in interpretable machine learning to better understand how anthropometric measurements can be tied to body mass index (BMI). Two objectives are of interest to this work, the first is to develop a properly validated interpretable machine learning (ML) ensemble capable of accurately predicting BMI, and the second is to derive a mapping function (i.e., a ML-based expression) that can describe the relationship between BMI and anthropometric measurements. This paper analyzes a historical database published by Penrose et al. (1985) containing thirteen body circumference measurements for 252 men. Four ML algorithms are then blended into an ensemble to examine the collected anthropometric measurements, namely, Extreme Gradient Boosted Trees, Light Gradient Boosted Trees, Random Forest, and Keras Slim Residual Network. The ensemble was then augmented with the SHAP (SHapley Additive exPlanations) and partial dependence plot techniques to understand the effect of each anthropometric measurement on BMI and the interaction between these anthropometric measurements. The proposed ensemble not only can comprehend the relation between anthropometric measurements and BMI index and derive a new non-parametric expression to predict BMI, but can also be used to interpret such relation and help us understand the logic driving ML’s predictions. Further, the interpretability analysis reveals that the main anthropometric measurements influencing BMI are the chest, abdomen, and hip circumference. Finally, clinicians and researchers are encouraged to leverage interpretability ML tools in their works instead of those of “black-box” nature.","Machine learning, BMI, Anthropometric measurements, Interpretability"
"Ford E,Maneparambil K,Kumar A,Sant G,Neithalath N",Transfer (machine) learning approaches coupled with target data augmentation to predict the mechanical properties of concrete,2022,"Transfer learning, a machine learning technique which employs prior knowledge from solving a source problem to solve a related target problem, is utilized in this work to predict the compressive strength and modulus of elasticity of different concrete mixtures. The use of data augmentation through empirical models to estimate missing data outputs allows for the use of inductive parameter transfer-learning artificial neural network (ANN) models for fast convergence. The paper considers two distinct cases: one where the domain of the target lies somewhat outside that of the source — termed domain expansion, and another where the target output (e.g., elastic modulus) is different, but related to the source output (e.g., compressive strength) — termed domain adaptation. Transfer learning is found to be most accurate when the source dataset is more complex than the target dataset, since more features could be learned. Data augmentation and the coupling of traditional machine learning with transfer learning are demonstrated to greatly enhance the predictive capability for important concrete properties, from mixture proportions. Limited experimental data can be used to transfer-learn the properties (output) of a new dataset from a reliable source model for a related system.","Machine learning, Transfer learning, Data augmentation, Elastic modulus, Compressive strength, High performance concrete"
"Dubey A,Santra A,Fuchs J,Lübke M,Weigel R,Lurz F",HARadNet: Anchor-free target detection for radar point clouds using hierarchical attention and multi-task learning,2022,"Target localization and classification from radar point clouds is a challenging task due to the inherently sparse nature of the data with highly non-uniform target distribution. This work presents HARadNet, a novel attention based anchor free target detection and classification network architecture in a multi-task learning framework for radar point clouds data. A direction field vector is used as motion modality to achieve attention inside the network. The attention operates at different hierarchy of the feature abstraction layer with each point sampled according to a conditional direction field vector, allowing the network to exploit and learn a joint feature representation and correlation to its neighborhood. This leads to a significant improvement in the performance of the classification. Additionally, a parameter-free target localization is proposed using Bayesian sampling conditioned on a pre-trained direction field vector. The extensive evaluation on a public radar dataset shows an substantial increase in localization and classification performance.","Multi-task learning, Radar detection, Scene understanding"
"Benchimol J,Kazinnik S,Saadon Y",Text mining methodologies with R: An application to central bank texts,2022,We review several existing text analysis methodologies and explain their formal application processes using the open-source software R and relevant packages. Several text mining applications to analyze central bank texts are presented.,"Text mining, R programming, Sentiment analysis, Topic modeling, Natural language processing, Central bank communication, Bank of Israel"
"Solaiyappan S,Wen Y",Machine learning based medical image deepfake detection: A comparative study,2022,"Deep generative networks in recent years have reinforced the need for caution while consuming various modalities of digital information. One avenue of deepfake creation is aligned with injection and removal of tumors from medical scans. Failure to detect medical deepfakes can lead to large setbacks on hospital resources or even loss of life. This paper attempts to address the detection of such attacks with a structured case study. Specifically, we evaluate eight different machine learning algorithms, which include three conventional machine learning methods (Support Vector Machine, Random Forest, Decision Tree) and five deep learning models (DenseNet121, DenseNet201, ResNet50, ResNet101, VGG19) in distinguishing between tampered and untampered images. For deep learning models, the five models are used for feature extraction, then each pre-trained model is fine-tuned. The findings of this work show near perfect accuracy in detecting instances of tumor injections and removals.","Computed tomography, Generative adversarial networks, Deepfake detection, DICOM, Tampered images, Machine learning"
"Bhardwaj P,Tiwari P,Olejar K,Parr W,Kulasiri D",A machine learning application in wine quality prediction,2022,"The wine business relies heavily on wine quality certification. The excellence of New Zealand Pinot noir wines is well-known worldwide. Our major goal in this research is to predict wine quality by generating synthetic data and construct a machine learning model based on this synthetic data and available experimental data collected from different and diverse regions across New Zealand. We utilised 18 Pinot noir wine samples with 54 different characteristics (7 physiochemical and 47 chemical features). We generated 1381 samples from 12 original samples using the SMOTE method, and six samples were preserved for model testing. The findings were compared using four distinct feature selection approaches. Important attributes (referred as essential variables) that were shown to be relevant in at least three feature selection methods were utilised to predict wine quality. Seven machine learning algorithms were trained and tested on a holdout original sample. Adaptive Boosting (AdaBoost) classifier showed 100% accuracy when trained and evaluated without feature selection, with feature selection (XGB), and with essential variables (features found important in at least three feature selection methods). In the presence of essential variables, the Random Forest (RF) classifier performance was increased.","Machine learning, Pinot noir, SMOTE, Random Forest, XGBOOST, StochastiC Gradient Decision Classifier"
"Vogl M,Rötzel PG,Homes S",Forecasting performance of wavelet neural networks and other neural network topologies: A comparative study based on financial market data sets,2022,"In this study, we analyse the advantageous effects of neural networks in combination with wavelet functions on the performance of financial market predictions. We implement different approaches in multiple experiments and test their predictive abilities with different financial time series. We demonstrate experimentally that both wavelet neural networks and neural networks with data pre-processed by wavelets outperform classical network topologies. However, the precision of conducted forecasts implementing neural network algorithms still propose potential for further refinement and enhancement. Hence, we discuss our findings, comparisons with “buy-and-hold” strategies and ethical considerations critically and elaborate on future prospects.","Wavelet neural networks, Wavelet decomposition, Financial forecasting, Forecast evaluation, Neural network topology, Financial markets"
"Rostami M,Kolouri S,Murez Z,Owechko Y,Eaton E,Kim K",Zero-shot image classification using coupled dictionary embedding,2022,"Zero-shot learning (ZSL) is a framework to classify images that belong to unseen visual classes using their semantic descriptions about the unseen classes. We develop a new ZSL algorithm based on coupled dictionary learning. The core idea is to enforce the visual features and the semantic attributes of an image to share the same sparse representation in an intermediate embedding space, modeled as the shared input space of two sparsifying dictionaries. In the ZSL training stage, we use images from a number of seen classes for which we have access to both the visual and the semantic attributes to train two coupled dictionaries that can represent both the visual and the semantic feature vectors of an image using a single sparse vector. In the ZSL testing stage and in the absence of labeled data, images from unseen classes are mapped into the attribute space by finding the joint-sparse representations using solely the visual dictionary via solving a LASSO problem. The image is then classified in the attribute space given semantic descriptions of unseen classes. We also provide attribute-aware and transductive formulations to tackle the “domain-shift” and the “hubness” challenges for ZSL, respectively. Experiments on four primary datasets using VGG19 and GoogleNet visual features, are provided. Our performances using VGG19 features are 91.0%, 48.4%, and 89.3% on the SUN, the CUB, and the AwA1 datasets, respectively. Our performances on the SUN, the CUB, and the AwA2 datasets are 57.0%,49.7%, and 71.7%, respectively, when GoogleNet features are used. Comparison with existing methods demonstrates that our method is effective and compares favorably against the state-of-the-art. In particular, our algorithm leads to decent performance on the all four datasets.22Early partial results of this paper is presented at 2018 AAAI (Kolouri, Rostami, Owechko, & Kim, 2018).","Zero shot learning, Coupled dictionary learning, Semantic attribute embedding, Domain-shift, Hubness"
"Jaya Brindha G,Gopi ES",Masking technique based attention mechanism for off-type identification in plants,2022,"Off-type plants, or other distinct varieties of the same plant, need to be detected and removed at early stage from the fields to preserve the genetic integrity and significant traits of a given plant variety. At present, these off-type plants are manually identified in the cultivation fields through morphological analysis of leaves. This method is time-consuming and involves skilled labor to define the off-type plant. Hence, masking technique based attention mechanism is proposed for identifying the off-type from the leaf images captured in the cultivation fields. The proposed method recognizes the plant variety by locating and visualizing the prominent parts of the leaf which is similar to the human visual attention mechanism. When the prominent parts of the leaf image are masked, there is a significant drop in the class probability of the convolutional network. This reflects the importance of such prominent parts which directly account for its variety. An attention module is designed using neural networks which focuses on such significant regions and improves the performance of the network. The proposed method is tested on a field image dataset consisting of 1235 images of Sunflower leaves and achieves the highest mean accuracy of 98.25% in identifying the plant variety.","Convolutional neural networks, Distance matrices, Class conditional probabilities, Sunflower leaf dataset"
"Regan C,Nasajpour M,Parizi RM,Pouriyeh S,Dehghantanha A,Choo KK",Federated IoT attack detection using decentralized edge data,2022,"Internet of Things (IoT) devices are mass-produced and designed for different applications, ranging from monitoring of the environment to on-demand electrical switches, and so on. These IoT devices are often heterogeneous in nature, only to receive updates at infrequent intervals, and can remain ‘out of sight’ on a home or office network for extended periods. In other words, security and privacy are two key (research and operational) challenges in IoT systems. In recent years, there have been attempts to design deep learning-based solutions to mitigate limitations associated with detection systems designed for typical operational technology (OT) systems, although a number of challenges remain. This paper proposes a federated-based approach that employs a deep autoencoder to detect​ botnet attacks using on-device decentralized traffic data. Through the suggested federated solution, privacy is addressed by ensuring the device’s data is not transferred or moved off the network edge. Instead, the machine learning computation itself is brought to where the data is born (i.e. the edge layer), with the added benefit of data security. We demonstrate that using our proposed model, we can achieve up to 98% accuracy rate in the anomaly detection when using features such as source IP, MAC-IP, and destination IP, etc., for training. The overall comparative performance analysis between our decentralized proposed approach and a centralized format demonstrates a significant improvement in the accuracy rate of attack detection.","Federated learning, Internet of things, Edge sensors, Cloud sensors, IoT security, Security attacks, Botnet, Autoencoder"
"Sabeti M,Boostani R,Moradi E,Shakoor MH",Machine learning-based identification of craniosynostosis in newborns,2022,"Early closure of cranial vault sutures, defined as craniosynostosis is a relatively common condition with somehow specific head and face abnormality for each subtype. Early diagnosis results in a better prognosis but pediatricians and primary care providers are not so familiar with these abnormalities while taking 3D CT scan of skull, predisposes the growing brain to harmful effects of radiation. Thus, developing a user-friendly and accurate diagnostic system would be helpful. This study aimed to diagnose simple suture synostosis by using machine learning based methods in digital photographs of child head. Digital photos of 145 craniosynostosis infants, operated in Mofid children hospital (Tehran, Iran) are used in this study. Head border is identified by GrabCut algorithm segmentation method and then several anthropometric indices such as cranial index (CI), cranial vault asymmetry index (CVAI), anterior–midline width ratio (AMWR) and anterior–posterior​ width ratio (APWR) and left–right height ratio (LRHR) are calculated. Moreover, statistical pattern matching indices (Chi-square (CS), Hu moment invariants (HuMI), absolute difference of white pixels probability (AbsDifWPP) and pixel intensity (PI)) are calculated and compared to anthropometric indices. The classification results for statistical pattern matching indices varied in the range of 85%–92% which is statistically higher than hand crafted indices. Our proposed approach could diagnose and classify common subtypes of single suture craniosynostosis and could help pediatricians and parents in early diagnosis and follow-up of this disorder.","Craniosynostosis, Statistical pattern matching, Anthropometric indices"
"Galisot G,Ramel JY,Brouard T,Chaillou E,Serres B",Visual and structural feature combination in an interactive machine learning system for medical image segmentation,2022,"Currently, Convolutional Neural Networks achieve good performance in automatic image segmentation situations; however, they have not demonstrated sufficiently accurate and robust results in the case of more general and interactive systems. Also, they have been designed specifically for visual features and cannot integrate enough anatomical knowledge inside the learned models they produce. To address these problems, we propose a novel machine-learning-based framework for interactive medical image segmentation. The proposed method incorporates local anatomical knowledge learning capabilities into a bounding box-based segmentation pipeline. Region specific voxel classifiers can be learned and combined to make the model adaptive to different anatomical structures or image modalities. In addition, a spatial relationship learning mechanism is integrated to capture and use additional topological (anatomical) information. New learning procedures have been defined to integrate both types of information (visual features to characterize each substructure and spatial relationships for a relative positioning between the substructures) in a unified model. During incremental and interactive segmentation, local substructures are localized one by one, enabling partial image segmentation. Bounding box positioning within the entire image is performed automatically using previously learned spatial relationships or by the user when necessary. Inside each bounding box, atlas-based methods or CNNs that are dedicated to each substructure can be applied to automatically obtain each local segmentation. Experimental results show that (1) the proposed model is robust for segmenting objects with a small amount of training images; (2) the accuracy is similar to other methods but allows partial segmentation without requiring a global registration; and (3) the proposed method leads to accurate results with fewer user interactions and less user time than traditional interactive segmentation methods due to its spatial relationship learning capabilities.","3D image segmentation, Machine learning, Interactive method, Spatial relationship, Atlas, Brain images"
"G.s. T,Hariprasad Y,Iyengar SS,Sunitha NR,Badrinath P,Chennupati S",An extension of Synthetic Minority Oversampling Technique based on Kalman filter for imbalanced datasets,2022,"More often than not, data collected in real-time tends to be imbalanced i.e., the samples belonging to a particular class are significantly more than the others. This degrades the performance of the predictor. One of the most notable algorithms to handle such an imbalance in the dataset by fabricating synthetic data, is the “Synthetic Minority Oversampling Technique (SMOTE)”. However, data imbalance is not solely responsible for the poor performance of the classifier. Certain research works have demonstrated that noisy samples can have a significant role in misclassifying the dataset. Also, handling large data is computationally expensive. Hence, data reduction is imperative. In this work, we put forth a novel extension of SMOTE by integrating it with the Kalman filter. The proposed method, Kalman-SMOTE (KSMOTE), filters out the noisy samples in the final dataset after SMOTE, which includes both the raw data and the synthetically generated samples, thereby reducing the size of the dataset. Our model is validated with a wide range of datasets. An experimental analysis of the results shows that our model outperforms the presently available techniques.","Imbalanced data, Oversampling, SMOTE, Noise filter"
"Vander Wal MD,McClarren RG,Humbird KD",Neural network surrogate models for absorptivity and emissivity spectra of multiple elements,2022,"The emissivity and absorptivity of radiation by matter are fundamental physical parameters required to adequately simulate inertial confinement fusion experiments. We present novel neural network models for predicting these interaction coefficients. This research extends the methods used by Kluth et al. (2020) that made similar predictions for a single chemical element, krypton. Our models are based on fully-connected or convolutional autoencoders coupled with a deep jointly-informed neural network (DJINN) to predict the emissivity and absorptivity of a given element and temperature/radiative field. We show that the previous work could not be directly extended to lower atomic number elements due to a thresholding effect on small values caused by a log10 transformation. Thus, in order to create a multi-element model, or even a single-element model, with low atomic number elements a different transformation is necessary. Utilization of a cube-root transform enables the creation of a multi-element model can achieve mean relative errors between 1% and 2%. Our work demonstrates that a single neural network can predict the results of atomic physics calculations, but additional work is necessary to consider mixtures of elements or a wider range of elements than those used in our study.","Data transformation, Atomic physics, Deep jointly informed neural network (DJINN), Autoencoders, Surrogate modeling, Spectroscopy"
"Nagoor OH,Whittle J,Deng J,Mora B,Jones MW",Sampling strategies for learning-based 3D medical image compression,2022,"Recent achievements of sequence prediction models in numerous domains, including compression, provide great potential for novel learning-based codecs. In such models, the input sequence’s shape and size play a crucial role in learning the mapping function of the data distribution to the target output. This work examines numerous input configurations and sampling schemes for a many-to-one sequence prediction model, specifically for compressing 3D medical images (16-bit depth) losslessly. The main objective is to determine the optimal practice for enabling the proposed Long Short-Term Memory (LSTM) model to achieve high compression ratio and fast encoding–decoding performance. Our LSTM models are trained with 4-fold cross-validation on 12 high-resolution CT dataset while measuring model’s compression ratios and execution time. Several configurations of sequences have been evaluated, and our results demonstrate that pyramid-shaped sampling represents the best trade-off between performance and compression ratio (up to 3×). We solve a problem of non-deterministic environments that allow our models to run in parallel without much compression performance drop. Experimental evaluation was carried out on datasets acquired by different hospitals, representing different body segments, and distinct scanning modalities (CT and MRI). Our new methodology allows straightforward parallelisation that speeds-up the decoder by up to 37× compared to previous methods. Overall, the trained models demonstrate efficiency and generalisability for compressing 3D medical images losslessly while still outperforming well-known lossless methods by approximately 17% and 12%. To the best of our knowledge, this is the first study that focuses on voxel-wise predictions of volumetric medical imaging for lossless compression.","3D predictors, Deep learning, Lossless compression, Medical image compression, Sequence prediction model, LSTM"
"Davis SR,Worsnop CJ,Hand EM",Gender bias recognition in political news articles,2022,"Gender bias exists not only in the stereotypes used to portray male and female figures, but more importantly, in the word choice media outlets use to describe political figures. Research in computational linguistics has not yet focused on the problem of identifying gender bias in political news from a variety of leanings, despite decades of research from the political science perspective. In this work, we introduce a new dataset – News-Bias – and demonstrate through extensive experimentation that there exists significant gender bias in political news, even with all gendered terms, and personally identifiable information removed. We show that bias persists through the document embeddings, sentiment and word choice across news outlets and political leanings.","Machine learning, Bias, Natural language processing, Gender recognition, Political news"
"Antweiler D,Harmening M,Marheineke N,Schmeißer A,Wegener R,Welke P",Graph-based tensile strength approximation of random nonwoven materials by interpretable regression,2022,"Nonwoven materials consist of random fiber structures. They are essential to diverse application areas such as clothing, insulation and filtering. A long term goal in industry is the simulation-based optimization of material properties in dependence of the manufacturing parameters. Recent works developed a framework to predict tensile strength properties representing the fiber structure as a stochastic graph. In this paper we present an efficient machine learning approach using a regression model trained on features extracted from the graph, for which we develop a novel graph stretching algorithm. We demonstrate that applying our method to a practically relevant dataset yields similar prediction results as the original ODE approach (R2=0.98), while achieving a significant speedup by up to three orders of magnitude. This opens the field to optimization, as Monte Carlo simulations accounting for the stochastic nature of nonwovens become easily accessible. Our model generalizes well to unseen parameter combinations. Additionally, our approach produces interpretable results by using a simple linear model for the regression task.","Nonwoven fiber material, Manufacturing, Textile fabrics, Material property prediction, Graph representation, Interpretable machine learning"
"Stephan M,Servadei L,Arjona-Medina J,Santra A,Wille R,Fischer G",Scene-adaptive radar tracking with deep reinforcement learning,2022,"Multi-target tracking with radars is a highly challenging problem due to detection artifacts, sensor noise, and interference sources. The traditional signal processing chain is, therefore, a complex combination of various algorithms with several tunable tracking-parameters. Usually, these are initially set by engineers and are independent of the scene tracked. For this reason, they are often non-optimal and generate poorly performing tracking. In this context, scene-adaptive radar processing refers to algorithms that can sense, understand and learn information related to detected targets as well as the environment and adapt its tracking-parameters to optimize the desired goal. In this paper, we propose a Deep Reinforcement Learning framework that guides the scene-adaptive choice of radar tracking-parameters towards an improved performance on multi-target tracking.","Reinforcement learning, Radar tracking, Scene adaptation"
"Lokanan ME,Sharma K",Fraud prediction using machine learning: The case of investment advisors in Canada,2022,"The paper contributes to a growing body of empirical work on regulatory technology by proposing machine learning models to detect fraud in financial markets. The recent spate of investment fraud in Canada has exposed regulators’ inability to protect vulnerable investors and the financial markets from financial abuse. As evident by the numerous regulatory task force commissioned in the past two years, Canadian regulators have been looking for ways to detect and prevent fraudulent activities before they occur and support enhanced enforcement powers. The purpose of this study is to use data collected from the Investment Industry Regulatory Organization of Canada (IIROC) to build a machine-learning algorithm to predict fraud in the Canadian securities industry. Data for this project were collected from IIROC’s tribunal cases covering June 2008 to December 2019. In total, 406 cases were retrieved from the IIROC’s website. The results from four machine learning models reveal that across all the features, the amount of money invested and whether the offender was from a bank-owned investment firm were the high predictors of fraud in terms of the standardized coefficient. Branch managers and regulators should pay careful attention to portfolios that continuously incur losses as a sign of potential fraud. The findings are particularly relevant to regulators seeking new and effective fraud detection techniques while providing enhanced clarity to Canada’s financial markets’ self-regulation.","Fraud, Machine learning, Financial markets, Regulation"
"Shahi S,Fenton FH,Cherry EM",Prediction of chaotic time series using recurrent neural networks and reservoir computing techniques: A comparative study,2022,"In recent years, machine-learning techniques, particularly deep learning, have outperformed traditional time-series forecasting approaches in many contexts, including univariate and multivariate predictions. This study aims to investigate the capability of (i) gated recurrent neural networks, including long short-term memory (LSTM) and gated recurrent unit (GRU) networks, (ii) reservoir computing (RC) techniques, such as echo state networks (ESNs) and hybrid physics-informed ESNs, and (iii) the nonlinear vector autoregression (NVAR) approach, which has recently been introduced as the next generation RC, for the prediction of chaotic time series and to compare their performance in terms of accuracy, efficiency, and robustness. We apply the methods to predict time series obtained from two widely used chaotic benchmarks, the Mackey–Glass and Lorenz-63 models, as well as two other chaotic datasets representing a bursting neuron and the dynamics of the El Niño Southern Oscillation, and to one experimental dataset representing a time series of cardiac voltage with complex dynamics. We find that even though gated RNN techniques have been successful in forecasting time series generally, they can fall short in predicting chaotic time series for the methods, datasets, and ranges of hyperparameter values considered here. In contrast, for the chaotic datasets studied, we found that reservoir computing and NVAR techniques are more computationally efficient and offer more promise in long-term prediction of chaotic time series.","Recurrent neural networks, Reservoir computing, Echo state networks, Deep learning, Chaotic time series, Nonlinear vector autoregression"
"Vidal A,Jha S,Hassler S,Price T,Busso C",Face detection and grimace scale prediction of white furred mice,2022,"Studying the facial expressions of humans has been one of the major applications of computer vision. An open question is whether common machine learning techniques can also be used to track behaviors of animals, which is a less explored research problem. Since animals are not capable of verbal communication, computer vision solutions can provide valuable information to track the animal’s state. We are particularly interested in pain neurobiology research, where rodent models are extensively used to investigate pain interventions. A grimace scale is used to understand the suffering of a mouse in the presence of interventions, which is inferred from various facial features such as the shape of the eyes and ears. In this work, we automate the prediction of the grimace scale on white furred mice using a machine learning approach, following the same principles used for human facial expression recognition: face detection, landmark region extraction, and expression recognition. We demonstrate the use of the you only look once (YOLO) framework for face detection of the mice with outstanding results. For eye region extraction and grimace pain prediction, we propose a novel structure based on a dilated convolutional network. The experimental results are promising, showing that it is possible to differentiate among the pain scale of the mice.","Mice pain detection, Deep learning, Convolutional neural networks"
"Packwood D,Nguyen LT,Cesana P,Zhang G,Staykov A,Fukumoto Y,Nguyen DH",Machine Learning in Materials Chemistry: An Invitation,2022,"Materials chemistry is being profoundly influenced by the uptake of machine learning methodologies. Machine learning techniques, in combination with established techniques from computational physics, promise to accelerate the discovery of new materials by elucidating complex structure–property relationships from massive material databases. Despite exciting possibilities, further methodological developments call for a greater synergism between materials chemists, physicists, and engineers on one side, with computer science and math majors on the other. In this review, we provide a non-exhaustive account of machine learning in materials chemistry for computer scientists and applied mathematicians, with an emphasis on molecule datasets and materials chemistry problems. The first part of this review provides a tutorial on how to prepare such datasets for subsequent model building, with an emphasis on the construction of feature vectors. We also provide a self-contained introduction to density functional theory, a method from computational physics which is widely used to generate datasets and compute response variables. The second part reviews two machine learning methodologies which represent the status quo in materials chemistry at present – kernelized machine learning and Bayesian machine learning – and discusses their application to real datasets. In the third part of the review, we introduce some emerging machine learning techniques which have not been widely adopted by materials scientists and therefore present potential avenues for computer science and applied math majors. In the final concluding section, we discuss some recent machine learning-based approaches to real materials discovery problems and speculate on some promising future directions.","Materials chemistry, Kernelized machine learning, Density functional theory, Bayesian optimization, Ensemble methods, Reinforcement learning, Federated learning"
"Mark M,Chehrazi N,Liu H,Weber TA",Optimal recovery of unsecured debt via interpretable reinforcement learning,2022,"This paper addresses the issue of interpretability and auditability of reinforcement-learning agents employed in the recovery of unsecured consumer debt. To this end, we develop a deterministic policy-gradient method that allows for a natural integration of domain expertise into the learning procedure so as to encourage learning of consistent, and thus interpretable, policies. Domain knowledge can often be expressed in terms of policy monotonicity and/or convexity with respect to relevant state inputs. We augment the standard actor–critic policy approximator using a monotonically regularized loss function which integrates domain expertise into the learning. Our formulation overcomes the challenge of learning interpretable policies by constraining the search to policies satisfying structural-consistency properties. The resulting state-feedback control laws can be readily understood and implemented by human decision makers. This new domain-knowledge enhanced learning approach is applied to the problem of optimal debt recovery which features a controlled Hawkes process and an asynchronous action–feedback relationship.","Reinforcement learning, Interpretable machine learning, Deterministic policy gradient, Monotonicity constrained learning, Debt recovery, Control of Hawkes processes"
"Ameyaw DA,Deng Q,Söffker D",How to evaluate classifier performance in the presence of additional effects: A new POD-based approach allowing certification of machine learning approaches,2022,"Classifiers are useful and well-known machine learning algorithms allowing classifications. A classifier may be suited for a specific task depending on the application and datasets. To select an approach for a task, performance evaluation may be imperative. Existing approaches like the receiver operating characteristic and precision–recall curves are popular in evaluating classifier performance, however both measures do not directly address the influence of additional and possibly unknown (process) parameters on the classification results. In this contribution, this limitation is discussed and addressed by adapting the Probability of Detection (POD) measure. The POD is a probabilistic method to quantify the reliability of a diagnostic procedure taking into account statistical variability of sensor and measurements properties. In this contribution the POD approach is adapted and extended. The introduced approach is implemented on driving behavior prediction data serving as illustrative example. Based on the introduced POD-related evaluation, different classifiers can be clearly distinguished with respect to their ability to predict the correct intended driver behavior as a function of remaining time (here assumed as process parameter) before the event itself. The introduced approach provides a new diagnostic and comprehensive interpretation of the quality of a classification model.","Performance evaluation, Classifier, Probability of Detection, Human behavior prediction"
"Islam MD,Li B,Islam KS,Ahasan R,Mia MR,Haque ME",Airbnb rental price modeling based on Latent Dirichlet Allocation and MESF-XGBoost composite model,2022,"Airbnb price modeling is an important decision-making tool that determines the acceptability and profitability of the service. In this study, we demonstrated how proper descriptions of an Airbnb listing and location could influence determining the prices. We assumed the proper description of a listing property positively influences the renter’s decision making; therefore, we applied a Latent Dirichlet Allocation (LDA) based topic model for generating synthetic variables from the textual description of property aiming to improve price prediction accuracy. Additionally, we applied a Moran Eigenvector Spatial Filtering based XGBoost (MESF-XGBoost) model to address the spatial dependence of location data and improve prediction accuracy. Our study at the San Jose County Airbnb dataset found that the number of bedrooms, accommodations, property types, and the total number of reviews positively influence the listing price, whereas the absence of a super host badge and cancellation policy negatively influence the price. The experiment demonstrates that incorporating synthetic variables from both LDA and MESF into the model specification improves the prediction accuracy. The experiment reveals that the XGBoost model with only non-spatial features is not strong enough to address spatial dependence; therefore, it cannot minimize spatial autocorrelation issues.","Machine Learning, Latent Dirichlet Allocation, Eigenvector Spatial Filtering, XGBoost, Spatial Data Modeling"
"Partovi Nia V,Li X,Asgharian M,Hu S,Geng Y,Chen Z",A causal direction test for heterogeneous populations,2022,"A probabilistic expert system emulates the decision-making ability of a human expert through a directional graphical model. The first step in building such systems is to understand data generation mechanism. To this end, one may try to decompose a multivariate distribution into product of several conditionals, and evolving a blackbox machine learning predictive models towards transparent cause-and-effect discovery. Most causal models assume a single homogeneous population, an assumption that may fail to hold in many applications. We show that when the homogeneity assumption is violated, causal models developed based on such assumption can fail to identify the correct causal direction. We propose an adjustment to a commonly used causal direction test statistic by using a k-means type clustering algorithm where both the labels and the number of components are estimated from the collected data to adjust the test statistic. Our simulation result show that the proposed adjustment significantly improves the performance of the causal direction test statistic for heterogeneous data. We study large sample behaviour of our proposed test statistic and demonstrate the application of the proposed method using real data.","Bayesian hierarchical model, Causal inference, Clustering, Graphical models, Belief network, Probabilistic expert systems, Testing statistical hypotheses"
"Shahhosseini M,Hu G,Pham H",Optimizing ensemble weights and hyperparameters of machine learning models for regression problems,2022,"Aggregating multiple learners through an ensemble of models aim to make better predictions by capturing the underlying distribution of the data more accurately. Different ensembling methods, such as bagging, boosting, and stacking/blending, have been studied and adopted extensively in research and practice. While bagging and boosting focus more on reducing variance and bias, respectively, stacking approaches target both by finding the optimal way to combine base learners. In stacking with the weighted average, ensembles are created from weighted averages of multiple base learners. It is known that tuning hyperparameters of each base learner inside the ensemble weight optimization process can produce better performing ensembles. To this end, an optimization-based nested algorithm that considers tuning hyperparameters as well as finding the optimal weights to combine ensembles (Generalized Weighted Ensemble with Internally Tuned Hyperparameters (GEM-ITH)) is designed. Besides, Bayesian search was used to speed-up the optimizing process and a heuristic was implemented to generate diverse and well-performing base learners. The algorithm is shown to be generalizable to real data sets through analyses with ten publicly available data sets.","Ensemble, Stacking, Optimization, Bias–variance tradeoff, Hyperparameters"
"Mahajan H,Banerjee S",A machine learning framework for guided wave-based damage detection of rail head using surface-bonded piezo-electric wafer transducers,2022,"Due to repeated heavy loads, environmental conditions and non-frequent monitoring, the rail is subjected to heavy damage resulting in sudden failure. Hence, a frequent, faster, and efficient monitoring strategy is required. This paper attempts to investigate the application of guided wave (GW) generated through surface-bonded piezo-electric wafer transducer (PWT) to detect damages in rail at high frequencies. Firstly, a combined experimental and simulation study is presented in an effort to understand the dispersion characteristics of guided wave and its interaction with head damages in a relatively small rail specimen. The numerical simulation results are validated with those obtained from the experiments showing a good agreement between them. Secondly, a framework based on the machine learning algorithm is proposed to efficiently detect damage in rail head. Numerous inseparable guided wave modes are observed at higher frequencies implying the inability to detect damage through specific mode. Therefore, a machine learning framework is trained using time, frequency, and time–frequency domain features of the signal. Total 672 numerical simulations of different types of damage with different severity and location in the rail head are carried out to train and validate the model. It is found that GW generated through surface bonded PWTs is able to detect minimum defect size of 5% of head area with 1 mm thickness. Finally, the proposed framework is tested using simulation and experiment results of arbitrary damage in the rail head. The error in estimating severity was found to be in the range from 2.00% to 16.67%.","Rail inspection, Guided wave, Surface bonded sensors, Rail head damage detection, Machine learning application"
"Soleymani F,Paquet E","Long-term financial predictions based on Feynman–Dirac path integrals, deep Bayesian networks and temporal generative adversarial networks",2022,"This paper presents a new deep learning framework, QuantumPath, for long-term stock price prediction, which is of great significance in portfolio management and risk mitigation, especially when the market becomes volatile due to unpredictable circumstances such as a pandemic. Our approach is based on stochastic equations, the Feynman–Dirac path integral, deep Bayesian networks, and temporal generative adversarial neural networks (t-GAN). The expected financial trajectory is evaluated with a Feynman–Dirac path integral. The latter involves summing all possible financial trajectories that could have been taken by the financial instrument. These trajectories are generated with a t-GAN. A probability is attributed to each point of each path. The probability is a function of the Lagrangian, which is derived from a stochastic equation describing the temporal evolution of the stock. The drift and the volatility at each point, which are required in order to evaluate the Lagrangian, are predicted with a deep Bayesian neural network. Given that the evolution of a stock’s price is isomorphic to a time series, our temporal GAN consists of long short-term memory (LSTM) neural networks, which introduce a memory mechanism, and temporal convolutional neural networks (TCN), which ensure causality. Stock prices are predicted over periods of twenty and thirty days for nine stocks, eight of which are included in the S&P 500 index. Our experimental results clearly demonstrate the efficiency of our approach.","Temporal generative adversarial network, Time series, Financial predictions, Long short-term memory, Temporal convolutional network"
"Dharmadhikari S,Basak A",Fatigue damage detection of aerospace-grade aluminum alloys using feature-based and feature-less deep neural networks,2022,"Fatigue damage is one of the most common causes of failure in aerospace structural components. While numerical modeling and laboratory-scale experimentation provide much insight to the physics of failure evolution, it is extremely challenging to account for all variabilies that a component may be subjected to during on-field operation. Human-supervised continuous monitoring of such components using sensors, therefore, provides a much-needed alternative for reliable operation of these components. By leveraging the concepts in deep learning, such human supervision can be assisted with an automated pre-trained deep network for damage detection. To that end, this article studies two distinct deep neural network (DNN) architectures for fatigue damage detection in aluminum using ultrasonic time-series data obtained from a novel customized fatigue testing apparatus. The first DNN, called as a feature-based network, is built by using two predefined features viz. frequency domain amplitude and autocorrelation from the ultrasonic data as the inputs. The second DNN, called as a feature-less network, uses the ultrasonic data as-is without any pre-processing and relies on the black-box features generated during training. The capability of fatigue crack detection for both DNN architectures is evaluated at two distinct stages of fatigue failure. The feature-less network is observed to outperform the feature-based network with an accuracy of 94.26% and 98.94% for the two stages. The result indicates that feature-less DNNs, owing to their construction, can formulate better, albeit black-box features, and simplify the process of choosing customized signal processing methods for similar problems.","Fatigue crack detection, Deep learning, Ultrasonics, Structural health monitoring, Neural networks, Autoencoders"
"Harrou F,Dairi A,Kadri F,Sun Y",Effective forecasting of key features in hospital emergency department: Hybrid deep learning-driven methods,2022,"Forecasting the different types of emergency department (ED) demands (patient flows) in hospital systems much aids ED managers in looking into various options to appropriately allocating the restricted resources available per patient attendance. Deep learning networks have recently gained great success in modeling time-dependent in time series data. Thus, this work advocates the use of deep learning-driven models for patient flows forecasting. Notably, we examine and compare seven deep learning models, Deep Belief Network (DBN), Restricted Boltzmann machines (RBM), Long Short Term Memory (LSTM), Gated recurrent unit (GRU), combined GRU and convolutional neural networks (CNN-GRU), LSTM-CNN, and Generative Adversarial Network based on Recurrent Neural Networks (GAN-RNN), to forecast patient flow in a hospital emergency department. We introduce a forecaster layer as output for each model to enable traffic flow forecasting. Patient flow data from different ED services, including biology, radiology, scanner, and echography, in Lille regional hospital in France, is used as a case study in assessing the considered forecasting models. Four metrics of effectiveness are adopted for evaluating and comparing the forecasting methods. The results show the promising performance of deep learning models for ED patient flow forecasting compared to shallow methods (i.e., ridge regression and support vector regression). In addition, the results highlighted the superior performance of the DBN compared to the other models by achieving an averaged mean absolute percentage error of around 4.097% and R2 of 0.973.","Hospital systems, Patient flows, ED visits, Forecasting, Hybrid deep learning methods"
"Sipper M,Moore JH",AddGBoost: A gradient boosting-style algorithm based on strong learners,2022,"We present AddGBoost, a gradient boosting-style algorithm, wherein the decision tree is replaced by a succession of (possibly) stronger learners, which are optimized via a state-of-the-art hyperparameter optimizer. Through experiments over 90 regression datasets we show that AddGBoost emerges as the top performer for 33% (with 2 stages) up to 42% (with 5 stages) of the datasets, when compared with seven well-known machine-learning algorithms: KernelRidge, LassoLars, SGDRegressor, LinearSVR, DecisionTreeRegressor, HistGradientBoostingRegressor, and LGBMRegressor.","Gradient boosting, Regression"
"Ciga O,Xu T,Martel AL",Self supervised contrastive learning for digital histopathology,2022,"Unsupervised learning has been a long-standing goal of machine learning and is especially important for medical image analysis, where the learning can compensate for the scarcity of labeled datasets. A promising subclass of unsupervised learning is self-supervised learning, which aims to learn salient features using the raw input as the learning signal. In this work, we tackle the issue of learning domain-specific features without any supervision to improve multiple task performances that are of interest to the digital histopathology community. We apply a contrastive self-supervised learning method to digital histopathology by collecting and pretraining on 57 histopathology datasets without any labels. We find that combining multiple multi-organ datasets with different types of staining and resolution properties improves the quality of the learned features. Furthermore, we find using more images for pretraining leads to a better performance in multiple downstream tasks, albeit there are diminishing returns as more unlabeled images are incorporated into the pretraining. Linear classifiers trained on top of the learned features show that networks pretrained on digital histopathology datasets perform better than ImageNet pretrained networks, boosting task performances by more than 28% in F1 scores on average. Interestingly, we did not observe a consistent correlation between the pretraining dataset site or the organ versus the downstream task (e.g., pretraining with only breast images does not necessarily lead to a superior downstream task performance for breast-related tasks). These findings may also be useful when applying newer contrastive techniques to histopathology data. Pretrained PyTorch models are made publicly available at https://github.com/ozanciga/self-supervised-histopathology.","Self supervised learning, Digital histopathology, Whole slide images, Unsupervised learning"
"Schmidt A,Ellsworth LM,Tilt JH,Gough M",Predicting conditional maximum contaminant level exceedance probabilities for drinking water after wildfires with Bayesian regularized network ensembles,2022,"The severity and frequency of wildfires have increased throughout the Pacific Northwest in recent decades, costing lives and destroying large amounts of valuable resources and assets. This trend is predicted to persist because of climate change and the associated increased fire risk caused by prolonged droughts in combination with changes in land cover and land use, including rapid increases in wildland urban interface areas. The threat of benzene and other contaminants in drinking water from water distribution systems after wildfires is a relatively recently discovered problem that gained attention because of the significant health hazards that high levels of benzene in drinking water pose for humans. Driving processes leading to post-fire benzene contamination in water distribution systems are largely unknown. Currently, no deterministic process models exist to predict the risk of exceeded benzene levels in water distribution systems after wildfires. To address the lack of predictive models, we developed and tested an approach based on neural network models to spatially predict the conditional probabilities of exceeding maximum contaminant levels for benzene after wildfires. The Bayesian regularized neural networks were trained using high-resolution data layers comprising topography, soil properties, landcover, vegetation, meteorological parameters, fuel load, and infrastructure data for two wildland urban interface areas in northern California. The generalized model ensemble encompassing data from both communities exhibits an accuracy of 83% to 88% in spatially predicting the post-fire exceedance of benzene levels, offering a planning tool for emergency response and future risk mitigation efforts.","Bayesian-regularized network ensembles, Conditional probabilities of drinking water contamination, Post-wildfire risk to water distribution systems (WDS) in the wildland urban interface (WUI), Maximum contaminant level (MCL) exceedance probabilities"
"Haselbeck F,Killinger J,Menrad K,Hannus T,Grimm DG",Machine Learning Outperforms Classical Forecasting on Horticultural Sales Predictions,2022,"Forecasting future demand is of high importance for many companies as it affects operational decisions. This is especially relevant for products with a short shelf life due to the potential disposal of unsold items. Horticultural products are highly influenced by this, however with limited attention in forecasting research so far. Beyond that, many forecasting competitions show a competitive performance of classical forecasting methods. For the first time, we empirically compared the performance of nine state-of-the-art machine learning and three classical forecasting algorithms for horticultural sales predictions. We show that machine learning methods were superior in all our experiments, with the gradient boosted ensemble learner XGBoost being the top performer in 14 out of 15 comparisons. This advantage over classical forecasting approaches increased for datasets with multiple seasons. Further, we show that including additional external factors, such as weather and holiday information, as well as meta-features led to a boost in predictive performance. In addition, we investigated whether the algorithms can capture the sudden increase in demand of horticultural products during the SARS-CoV-2 pandemic in 2020. For this special case, XGBoost was also superior. All code and data is publicly available on GitHub: https://github.com/grimmlab/HorticulturalSalesPredictions.","Sales Forecasting, Time Series Forecasting, Comparative study, Horticulture, Machine Learning"
"Ahuja S,Panigrahi BK,Gandhi TK",Enhanced performance of Dark-Nets for brain tumor classification and segmentation using colormap-based superpixel techniques,2022,"The brain tumor is the deadliest disease in adults as it arises due to an abnormal mass of cells that grows rapidly and it alters the proper functioning of the organs. In clinical practice, radiographic images of different modalities are used to diagnose types of brain tumors, their size, and location. The proposed work aims to automatically classify, localize, and segment brain tumors from T1W-CE Magnetic Resonance Image (MRI) datasets. The T1W-CE MRI dataset is divided into 8:1:1, i.e., 80% training set, 10% of each validation, and testing set. To address the overfitting issues, the training data set is augmented using 2-levels wavelet decomposition and geometrical operations (scaling, rotation, translation). Performance of pre-trained DarkNet model (DarkNet-19 and DarkNet-53) is evaluated for the multi-class classification and localization of brain tumors. The best performing pre-trained DarkNet model achieved 99.60% of training accuracy and 98.81% of validation accuracy. The performance evaluation parameters confirm the superiority of the proposed methodology in comparison to the state-of-the-art on the T1W-CE MRI dataset. On 1070 T1W-CE testing images, the best-performing pre-trained DarkNet-53 model obtained a testing accuracy of 98.54% and Area Under Curve (AUC) of 0.99. The tumor is segmented using a 2-D superpixel segmentation technique with an average dice index of 0.94 ± 2.6% on the 793 brain tumor testing data. To prove the superiority of the proposed technique, it is implemented on MRI images from the BraTS2018 dataset. The comparative analysis of performance evaluation parameters of the proposed methodology with the state-of-the-art technique proves its robustness and clinical significance.","Brain tumor, MRI, Deep learning, Superpixel segmentation"
Saracoglu BO,Initialization of profile and social network analyses robot and platform with a concise systematic review,2022,"This paper presents profile and social network analyses on concise systematic review corpora. It suggests two new robots and platforms for profile and social network analyses, that will serve previously proposed data, expert, and event-driven robots and platforms for energy and power industry. The literature is collected and stored in three topic clusters “location”, “investment”, and “DEMATEL” to prepare corpora. Twenty-five publications are selected in each sample corpus. A sample dataset of each corpus is prepared for thirty-one features such as “author’s full name and surname”, “applied methods”, and “publisher”. Afterward, “authors network matrices” are prepared in spreadsheet software. Data input files (*.csv) are prepared for each dataset. Gephi 0.9.2 201709241107 (free open-source software) is used for social network analyses with built-in layout and statistics algorithms on a desktop Windows 10 Pro, Intel(R) Core(TM) i5 CPU 650 @ 3.20 GHz, 6,00 GB RAM personal computer in an offline and active cybersecurity software environment. Force Atlas, Force Atlas 2, Fruchterman–Reingold, OpenOrd, Yifan Hu, and Yifan Hu Proportional layout algorithms with Noverlap layout algorithm are run one by one. Runtimes range 2–120 s. All default statistic algorithms are run for several metrics like average degree, average weighted degree, betweenness centrality, closeness centrality, harmonic closeness centrality, eccentricity, and density. Authors in “location” cluster have a centralized network, but authors in “investment” and “DEMATEL” clusters have distributed networks. General profile analyses are conducted based on authors’ publications in the literature without any data and information on social media sites and platforms. Two new profile analysis metrics are proposed as “researcher’s past research focus index”, and “researcher’s future research focus prediction index”. Detailed profile analysis is performed for only Burak Omer Saracoglu. All analyses and findings are compared and summarized in the end.","Decision Making Trial and Evaluation Laboratory, DEMATEL, Investment, Location, Profile analysis, Social network analysis"
"Zeinali Y,Niaki ST",Heart sound classification using signal processing and machine learning algorithms,2022,"According to global statistics and the world health organization (WHO), about 17.5 million people die each year from cardiovascular disease. In this paper, the heart sounds gathered by a stethoscope are analyzed to diagnose several diseases caused by heart failure. This research’s primary process is to identify and classify the data related to the heart sounds categorized in four general groups of S1 to S4. The sounds S1 and S2 are considered as the heart’s normal sounds, and the sounds S3 and S4 are the abnormal sounds of the heart (heart murmurs), each expressing a specific type of heart disease. In this regard, the desired features are first extracted after retrieving the data by signal processing algorithms. In the next step, feature selection algorithms are used to select the compelling features to reduce the problem’s dimensions and obtain the optimal answer faster. While the existing algorithms in the literature classify the sound into two groups of normal and abnormal, in the final section, some of the most popular classification algorithms are utilized to classify the type of sound into three classes of normal, S3 and S4 categories. The proposed methodology obtained an accuracy rate of 87.5% and 95% for multiclass data (3 classes) and 98% for binary classification (normal vs. abnormal) problems.","Heart sound, Signal processing algorithms, Machine learning algorithms, Dimensional reduction algorithms, Feature selection, Gradient boosting classifier"
"Schad J,Sambasivan R,Woodward C",Predicting help desk ticket reassignments with graph convolutional networks,2022,Efficient triaging of incident tickets is a critical task in Information Technology Service Management. Introducing interventional measures on tickets that are difficult to resolve can help improve the triaging of complex tickets. This work reports a method to predict the resolution complexity of a reported incident. The number of times a ticket is reassigned is a measure of difficulty in resolving the incident. Ticket resolution is associated with a variable workflow. A graph representation of ticket resolution offers advantages from the standpoint of running ad hoc queries. Predicting ticket reassignments requires the application of machine learning to this graph. A Relational Graph Convolutional Network is used for this purpose. The developed model provides benefits beyond predicting ticket reassignments accurately. It provides embeddings that can be used to derive insights about the operation of the help desk organization and the users of the help desk.,"Machine learning, Graph convolutional network, Graph representation"
"Moeinizade S,Pham H,Han Y,Dobbels A,Hu G",An applied deep learning approach for estimating soybean relative maturity from UAV imagery to aid plant breeding decisions,2022,"For a global breeding organization, identifying the next generation of superior crops is vital for its success. Recognizing new genetic varieties requires years of in-field testing to gather data about the crop’s yield, pest resistance, heat resistance, etc. At the conclusion of the growing season, organizations need to determine which varieties will be advanced to the next growing season (or sold to farmers) and which ones will be discarded from the candidate pool. Specifically for soybeans, identifying their relative maturity is a vital piece of information used for advancement decisions. However, this trait needs to be physically observed, and there are resource limitations (time, money, etc.) that bottleneck the data collection process. To combat this, breeding organizations are moving towards advanced image capturing devices. In this paper, we develop a robust and automatic approach for estimating the relative maturity of soybeans using a time series of UAV images. An end-to-end hybrid model combining Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) is proposed to extract features and capture the sequential behavior of time series data. The proposed deep learning model was tested on six different environments across the United States Results suggest the effectiveness of our proposed CNN-LSTM model compared to the local regression method. Furthermore, we demonstrate how this newfound information can be used to aid in plant breeding advancement decisions.","Soybean relative maturity, Prediction, Deep learning, Time series, Convolutional neural networks"
"Deb S,Chanda AK",Comparative analysis of contextual and context-free embeddings in disaster prediction from Twitter data,2022,"Twitter is a social media site where people post their personal experiences, opinions, and news. Due to the ubiquitous real-time data availability, many rescue agencies monitor this data regularly to identify disasters, reduce risk, and save lives. However, it is impossible for humans to manually check the mass amount of data and identify disasters in real-time. For this purpose, many research have been proposed to present words in machine-understandable representations and apply machine learning methods on the word representations to identify the sentiment of a text. The previous research methods provide a single vector representation or embedding of a word from a given document. However, the recent advanced contextual embedding method (BERT — Bidirectional Encoder Representations from Transformers) constructs different vectors for the same word in different contexts. The BERT embeddings have been used successfully in various Natural Language Processing (NLP) tasks, yet there is no concrete analysis of how these representations are helpful in disaster-type tweet analysis. This research study explores the efficacy of the BERT embeddings on predicting disaster from Twitter data and compares these to traditional context-free word embedding methods. We provide both quantitative and qualitative results for this study. The results show that the contextual embeddings have the best results in disaster prediction task than the traditional word embeddings. Furthermore, we discuss the opportunities and challenges of contextual embeddings on sentiment analysis of Twitter data.","Social media data, Twitter data, Disaster prediction, BERT, Kaggle competition, Natural Language Processing (NLP)"
"Paul S,Jhamb B,Mishra D,Kumar MS",Edge loss functions for deep-learning depth-map,2022,"Depth computation from an image is useful for many robotic systems like obstacle recognition, autonomous navigation, and 3D measurements. The estimation is best solved with Deep Neural Networks (DNN) as these are non-linear and ill-posed problems. The network takes single-color images with corresponding ground truth to predict depth-map after training. The depth accuracy, here, is dependent on the quality of ground truth and training images. Images have inherent blurs, which impact depth prediction and accuracy. In our work, we study different combinations of loss functions involving various edge functions to improve the depth of images. We use DenseNet and transfer learning method for learning and prediction of depth. Our analysis shows improvement in performance parameters as well as in the visual depth-map. We achieve 85% δ1 accuracy and improve log10 error using NYU Depth V2 dataset.","Depth estimation, Deep learning, Transfer learning, Ground truth, Loss functions, Modified SSIM, Edge functions, Performance metrics"
"Luo X,Oyedele LO",A self-adaptive deep learning model for building electricity load prediction with moving horizon,2022,"A self-adaptive deep learning model powered by ranking selection-based particle swarm optimisation (RSPSO) is developed to predict electricity load in buildings with moving horizons. The main features of the load prediction model include its self-adaptability, repeatability, robustness and accuracy. In real-world building applications, the relationship among weather data, time signature and electricity load is quite complicated. In the proposed self-adaptive deep learning model, a deep learning model with multiple hidden layers is implemented to improve prediction precision. Meanwhile, RSPSO is implemented to select the network’s optimum architecture, which involves discrete variables (i.e. the quantity of neurons in each layer and the quantity of hidden layers) and categorical variables (i.e. activation function in each layer and learning approach). Moreover, the moving horizon approach is adopted to update the architecture and structure of the dynamic deep learning model while enabling its capability in capturing the latest featuring patterns in the electricity load of the building. The proposed load prediction model is tested with the local meteorological profile and electricity load of an educational building. The self-adaptive load prediction model is identified to be the most effective at forecasting the next horizon’s energy consumption, while its prediction performance would deteriorate with the increase of time. The mean squared error, mean absolute error, and coefficient of determination of the proposed prediction model are within the range of 4.48 kW–11.23 kW, 1.28 kW–2.31 kW and 97.52%–98.92%, respectively, demonstrating its prediction accuracy and repeatability. When Gaussian white noise is added to meteorological data, the increase in mean absolute error is within the range of 2.08%–15.33%, demonstrating the robustness of the proposed prediction model in overcoming uncertainty in the weather forecast. Therefore, the proposed accurate, robust, repeatable and self-adaptive load prediction model can be rooted in practical energy management systems thus facilitate building operation and system control.","Moving horizon, Self-adaptability, Prediction, Deep learning, Deep neural network, Particle swarm optimisation"
"Xie J,Zhu M,Hu K,Zhang J,Hines H,Guo Y",Frog calling activity detection using lightweight CNN with multi-view spectrogram: A case study on Kroombit tinker frog,2022,"Frogs play an important role in ecological systems, while frog species across the globe are threatened and declining. Therefore, it is valuable to estimate the frog population based on an intelligent computer system. Due to the success of deep learning (DL) in various pattern recognition tasks, previous studies have used DL-based methods for frog call analysis. However, the performance of DL-based systems is highly affected by their input (feature representation). In this study, we develop a frog calling activity detection system for continuous field recordings using a light convolutional neural network (CNN) with multi-view spectrograms. To be specific, a sliding window is first applied to continuous recordings for obtaining audio segments with a fixed duration. Then, the background noise is filtered out. Next, a multi-view spectrogram is used for characterizing those segments, which has more distinctive information than a single-view spectrogram. Finally, a lightweight CNN model is used for the detection of frog calling activity with a twin loss, where different train and test sets are used to validate the model’s robustness. Our experimental results indicate that the highest macro F1-score was 99.6 ± 0.2 and 96.4 ± 2.0 using 2016 and 2017 as the train data respectively, where CNN-GAP is used as the model with multi-view spectrogram as the input.","Bioacoustic signal activity detection, Multi-view spectrogram, Lightweight CNN, Loss function"
"Barrera-Animas AY,Oyedele LO,Bilal M,Akinosho TD,Delgado JM,Akanbi LA",Rainfall prediction: A comparative analysis of modern machine learning algorithms for time-series forecasting,2022,"Rainfall forecasting has gained utmost research relevance in recent times due to its complexities and persistent applications such as flood forecasting and monitoring of pollutant concentration levels, among others. Existing models use complex statistical models that are often too costly, both computationally and budgetary, or are not applied to downstream applications. Therefore, approaches that use Machine Learning algorithms in conjunction with time-series data are being explored as an alternative to overcome these drawbacks. To this end, this study presents a comparative analysis using simplified rainfall estimation models based on conventional Machine Learning algorithms and Deep Learning architectures that are efficient for these downstream applications. Models based on LSTM, Stacked-LSTM, Bidirectional-LSTM Networks, XGBoost, and an ensemble of Gradient Boosting Regressor, Linear Support Vector Regression, and an Extra-trees Regressor were compared in the task of forecasting hourly rainfall volumes using time-series data. Climate data from 2000 to 2020 from five major cities in the United Kingdom were used. The evaluation metrics of Loss, Root Mean Squared Error, Mean Absolute Error, and Root Mean Squared Logarithmic Error were used to evaluate the models’ performance. Results show that a Bidirectional-LSTM Network can be used as a rainfall forecast model with comparable performance to Stacked-LSTM Networks. Among all the models tested, the Stacked-LSTM Network with two hidden layers and the Bidirectional-LSTM Network performed best. This suggests that models based on LSTM-Networks with fewer hidden layers perform better for this approach; denoting its ability to be applied as an approach for budget-wise rainfall forecast applications.","Rainfall prediction, LSTM Networks, Multivariate time-series, Multi-step forecast, Time-series data"
"Shen S,Guye D,Ma X,Yue S,Armanfard N",Multistep networks for roll force prediction in hot strip rolling mill,2022,"Hot rolling processes consist of multiple single rolling stand operating at high temperature and speed to achieve desired steel shapes and superior properties, via exerting roll forces that need to be accurately predicted by a model. The currently used model of the mill of this study shows prediction instability and is unable to accurately accommodate changes in steel grade. In this paper, we propose a machine learning based framework to establish a model that accurately predicts roll forces at each mill stands of the hot strip rolling mill. In contrast to the traditional models, the proposed expert system considers an individual model for each rolling stand and employs rolling history when predicting roll forces. The proposed model includes both steel chemistry and physical process parameters for its predictions. Our experimental results demonstrate that the proposed framework improves both prediction accuracy and stability by 40%–50% over the currently used mill model. The enhanced prediction accuracy will greatly improve dimensional and microstructural control, as well as ensuring the avoidance of mill overloads.","Machine learning, Multistep neural networks, Hot rolling, Roll force prediction"
"Ortu M,Vacca S,Destefanis G,Conversano C",Cryptocurrency ecosystems and social media environments: An empirical analysis through Hawkes’ models and natural language processing,2022,"We analyse, using a mixture of statistical models and natural language process techniques, what happened in social media from June 2019 onwards to understand the relationships between Cryptocurrencies’ prices and social media, focusing on the rise of the Bitcoin and Ethereum prices. In particular, we identify and model the relationship between the cryptocurrencies market price changes, and sentiment and topic discussion occurrences on social media, using Hawkes’ Model. We find that some topics occurrences and rise of sentiment in social media precedes certain types of price movements. Specifically, discussions concerning governments, trading, and Ethereum cryptocurrency as an exchange currency appear to negatively affect Bitcoin and Ethereum prices. Those concerning investments, appear to explain price rises, whilst discussions related to new decentralized realities and technological applications explain price falls. Finally, we validate our model using a real case study: the already famous case of ”Wallstreetbet and GameStop”11https://www.economist.com/finance-and-economics/2021/02/06/how-wallstreetbets-works. that took place in January 2021.","Cryptocurrencies, Social media analysis, Fundamental analysis, Forecasting price movements, Hawkes model"
"Desprez M,Zawada K,Ramp D",Overcoming the ordinal imbalanced data problem by combining data processing and stacked generalizations,2022,"Ordinal imbalanced datasets are pervasive in real world applications but remain challenging to analyse as they require specific methods to account for the ordering information and imbalanced classes. Failure to account for both those characteristics can substantially impact the model predictive performance. However, existing methods tend to focus either on ordinality or imbalance, rather than addressing both simultaneously. The few approaches that do account for both characteristics are not always easy to implement for non-advanced analysts and simpler approaches are needed to facilitate appropriate data processing. Here, we developed a general approach using some of the most popular machine learning algorithms to ensure appropriate processing of ordinal imbalanced datasets and to optimize the predictions of all classes. After transforming the multi-class ordinal problem into a well-known binary problem, we implemented several different resampling methods in a decision-tree classifier. We then used a stacked generalization algorithm to combine the classifiers to improve model predictive performance. To test our approach, we used two ordinal imbalanced datasets on student performance and wine quality. Individual resampling techniques tended to improve the accuracy of minority classes, while simultaneously increasing the number of false positives in those classes. This resulted in a decrease, sometimes substantial, in accuracy of other classes. The stacking model offered a good compromise between improvement in accuracy of minority classes and mitigation of reduced accuracy in other classes. Our approach provided useful insights into modelling strategies that should be favoured for implementation in production that involve these common datasets, depending on the end-user interests.","Stacked generalizations, Machine learning, Ordinal data, Imbalanced data, Random forests, Resampling methods, Rare events, Classification"
"Robertson DL,Goodridge WS",Predicting density of serious crime incidents using a Multiple-Input Hidden Markov Maximization a posteriori model,2022,"Accurately predicting the displacement of crime from a given state such as cold to another state such as warm or hot, facilitates the efficient allocation of resources and the mitigation of crime threats. In this study, a crime forecasting model was developed, based on Spearman’s Correlations and a clustering technique (DBSCAN), which captures significant groupings in a geospatial dataset. A Multi-Input Hidden Markov Model (MI-HMM) machine learning framework was developed to train the dataset. The results from the MI-HMM were then used to make a Maximum a Posteriori (MAP) decision over the possible state of crime for the next month. This novel model, MI-HMM-MAP, was used to predict the density of crime including criminal hot spots over time. The model was evaluated using real-world dataset. Findings show an average of 72.5% accuracy and 81.7% correctness. The model was compared to 5 classical predictive models. Results show that our model significantly outperforms a linear regression model, a neural network model, and two machine learning approaches. It slightly outperforms a deep learning approach as demonstrated statistically by an application to the crime of murder in Trinidad and Tobago.","Cluster analysis, Correlation, Machine learning, Hidden Markov Model, Multiple input training, Crime forecasting"
"Di Caprio D,Santos-Arteaga FJ",Enhancing the pattern recognition capacity of machine learning techniques: The importance of feature positioning,2022,"We design several algorithms representing evaluation processes of different complexity, ranging from basic environments based on a predetermined number of features to complex structures involving alternatives defined through decision trees whose number of nodes is determined by the cardinality of the respective power sets. The sequential structure of these evaluation processes builds on the information retrieval behavior of users in online search environments. The algorithms generate two strings of data, namely, numerical evaluations determining the retrieval behavior of users and the subsequent choices made by the latter. The way the output obtained from the algorithms is inputted within the vectors summarizing the complexity of the evaluation processes conditions the capacity of machine learning techniques to categorize them correctly. The main purpose of the research is to illustrate numerically two main results. First, machine learning techniques categorize processes correctly even if their characteristic features are presented in a way that prevents their identification using standard statistical techniques. Second, the accuracy of the categorization capacities of these techniques can be substantially enhanced by describing the retrieval processes in the way required to implement standard statistical analyses. We perform a battery of tests using machine learning techniques to demonstrate and analyze these results. Their applicability to classification and prediction problems in medical environments, particularly those constrained by the quality of the data available, is emphasized.","Feature positioning, Information retrieval, Pattern recognition, Machine learning, Decision trees"
"Kanakaris N,Giarelis N,Siachos I,Karacapilidis N",Making personnel selection smarter through word embeddings: A graph-based approach,2022,"This paper employs techniques and algorithms from the fields of natural language processing, graph representation learning and word embeddings to assist project managers in the task of personnel selection. To do so, our approach initially represents multiple textual documents as a single graph. Then, it computes word embeddings through representation learning on graphs and performs feature selection. Finally, it builds a classification model that is able to estimate how qualified a candidate employee is to work on a given task, taking as input only the descriptions of the tasks and a list of word embeddings. Our approach differs from the existing ones in that it does not require the calculation of key performance indicators or any other form of structured data in order to operate properly. For our experiments, we retrieved data from the Jira issue tracking system of the Apache Software Foundation. The evaluation results show, in most cases, an increase of 0.43% in the accuracy of the proposed classification models when compared against a widely-adopted baseline method, while their validation loss is significantly decreased by 65.54%.","Natural language processing, Text categorization, Graph representation learning, Issue management, Personnel selection, Word embeddings"
"Nasrolahzadeh M,Rahnamayan S,Haddadnia J",Alzheimer’s disease diagnosis using genetic programming based on higher order spectra features,2022,"In Alzheimer’s diagnosis field, Computer-Aided Diagnosis (CADx) technology can improve the work performance of medical researchers and practitioners since it gives early chances to patient’s eligibility for clinical trials. The aim of this study is to develop a novel CADx system for the diagnosis of Alzheimer’s disease (AD) by utilizing genetic programming (GP) as data-driven evolutionary computation based modeling. The proposed method invokes a majority voting based scheme to select a set of most discriminant features which leads to the highest diagnosis accuracy of the final classification. The effectiveness of GP in categorizing patients with Alzheimer’s versus healthy group was revealed by developing models according to their performance in terms of higher-order spectra (HOS) features. The results show that the GP method achieved better performance compared to other the-state-of-the-art approaches. It is also found that the highest accuracy index was yielded by using the proposed data-driven modeling technique. The results of this study emphasize the practicality of GP-based method for developing CADx systems, on the basis of spontaneous speech analysis; can efficiently assist in the diagnosis of Alzheimer’s disease.","Alzheimer’s disease, Spontaneous speech signal, Feature selection, Classification, Machine learning, Genetic programming"
"Agarwal S,Rattani A,Chowdary CR",A-iLearn: An adaptive incremental learning model for spoof fingerprint detection,2022,"Incremental learning enables the learner to accommodate new knowledge without retraining the existing model. It is a challenging task that requires learning from new data and preserving the knowledge extracted from the previously accessed data. This challenge is known as the stability-plasticity dilemma. We propose A-iLearn, a generic model for incremental learning which overcomes the stability-plasticity dilemma by carefully integrating the ensemble of base classifiers trained on new data with the current ensemble without retraining the model from scratch using entire data. We demonstrate the efficacy of the proposed A-iLearn model on spoof fingerprint detection application. One of the significant challenges associated with spoof fingerprint detection is the performance drop on spoofs generated using new fabrication materials. A-iLearn is an adaptive incremental learning model that adapts to the features of the “live” and “spoof” fingerprint images and efficiently recognizes the new spoof fingerprints and the known spoof fingerprints when the new data is available. To the best of our knowledge, A-iLearn is the first attempt in incremental learning algorithms that adapts to the properties of data for generating a diverse ensemble of base classifiers. From the experiments conducted on standard high-dimensional datasets LivDet 2011, LivDet 2013 and LivDet 2015, we show that the performance gain on new fake materials is significantly high. On average, we achieve 49.57% improvement in accuracy between the consecutive learning phases.","Incremental learning, Stability-plasticity dilemma, Catastrophic forgetting, Spoof fingerprint detection"
"Rutkowski GP,Azizov I,Unmann E,Dudek M,Grimes BA",Microfluidic droplet detection via region-based and single-pass convolutional neural networks with comparison to conventional image analysis methodologies,2022,"As the complexity of microfluidic experiments and the associated image data volumes scale, traditional feature extraction approaches begin to struggle at both detection and analysis pipeline throughput. Deep-neural networks trained to detect certain objects are rapidly emerging as data gathering tools that can either match or outperform the analysis capabilities of the conventional methods used in microfluidic emulsion science. We demonstrate that two types of neural-networks, You Only Look Once (YOLOv3, YOLOv5) and Faster R-CNN, can be trained on a dataset which comprises of droplets generated across several microfluidic experiments and systems. The latitude of droplets used for training and validation, produce model weights which are easily transitive to emulsion systems at large, while completely circumventing any necessity of manual feature extraction. In flow cell experiments which comprised of greater than either 10,000 mono- or polydisperse droplets, the models show excellent or superior statistical symmetry to classical implementations of the Hough transform or widely utilized ImageJ plugins. In more complex chip architectures which simulate porous media, the produced image data typically requires heavy pre-processing to extrapolate valid data, where the models were able to handle raw input and produce size distributions with accuracy of ± 2μm for intermediate magnifications. This data harvesting fidelity is extended to foreign datasets not included in the training such as micrograph observation of various emulsified systems. Implementing these neural networks as the sole feature extraction tools in these microfluidic systems not only makes the data pipelining more efficient but opens the door for live detection and development of autonomous microfluidic experimental platforms due to inference times of greater than 100 frames per second.","Droplet microfluidics, Emulsion, Image analysis, Object detection, Convolutional neural network, Deep learning"
"Egwim CN,Alaka H,Toriola-Coker LO,Balogun H,Sunmola F",Applied artificial intelligence for predicting construction projects delay,2021,"This study presents evidence of a developed ensemble of ensembles predictive model for delay prediction – a global phenomenon that has continued to strangle the construction sector despite considerable mitigation efforts. At first, a review of the existing body of knowledge on influencing factors of construction project delay was used to survey experts to approach its quantitative data collection. Secondly, data cleaning, feature selection, and engineering, hyperparameter optimization, and algorithm evaluation were carried out using the quantitative data to train ensemble machine learning algorithms (EMLA) – bagging, boosting, and naïve bayes, which in turn was used to develop hyperparameter optimized predictive models: Decision Tree, Random Forest, Bagging, Extremely Randomized Trees, Adaptive Boosting (CART), Gradient Boosting Machine, Extreme Gradient Boosting, Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes. Finally, a multilayer high performant ensemble of ensembles (stacking) predictive model was developed to maximize the overall performance of the EMLA combined. Results from the evaluation metrics: accuracy score, confusion matrix, precision, recall, f1 score, and Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) indeed proved that ensemble algorithms are capable of improving the predictive force relative to the use of a single algorithm in predicting construction projects delay.","Artificial intelligence, Machine learning, Ensemble of ensembles, Ensemble learning, Project delay, Predictive analytics"
"Ogunsina K,Bilionis I,DeLaurentis D",Exploratory data analysis for airline disruption management,2021,"Reliable platforms for data collation during airline schedule operations have significantly increased the quality and quantity of available information for effectively managing airline schedule disruptions. To that effect, this paper applies macroscopic and microscopic techniques by way of basic statistics and machine learning, respectively, to analyze historical scheduling and operations data from a major airline in the United States. Macroscopic results reveal that majority of irregular operations in airline schedule that occurred over a one-year period stemmed from disruptions due to flight delays, while microscopic results validate different modeling assumptions about key drivers for airline disruption management like turnaround as a Gaussian process.","Airline disruption management, Data analysis, Machine learning"
"Malhotra D,Goyal R",Supervised-learning link prediction in single layer and multiplex networks,2021,"The emergence of complex real-world networks has put forth a plethora of information about different domains. Link-prediction is one of the emerging research problems that utilizes the information from the networks to find future relationships between the nodes. The structure of real-world networks varies from having homogeneous relationships to having multiple associations. The homogeneous relationships are modeled by single-layer networks, while the multiplex networks represent the multiple associations. This study proposes a solution for finding future links in single-layer and multiplex networks by using supervised machine learning techniques. This study considers a set of topological features of the network for training the machine learning classifiers. The training and testing data set construction framework devised in this work helps in evaluating the proposed method on different networks. This study also contributes towards identifying four community-based features for the proposed mechanism.","Supervised learning, Link prediction, Complex networks, Multiplex networks, Social networks, Node similarity"
"Santarsiero G,Mishra M,Singh MK,Masi A",Structural health monitoring of exterior beam–column subassemblies through detailed numerical modelling and using various machine learning techniques,2021,"Structural health monitoring of beam–column joints is paramount, as they are critical load-carrying components of reinforced concrete buildings. Evaluating the ultimate joint shear capacity and failure modes of beam–columns, especially in seismic events, is a crucial task, especially in view of life safety concerns. Traditional methods used to determine the joint shear capacity of beam–column joints are often inaccurate and cumbersome owing to improper accounting of governing parameters that influence beam–column joints’ behaviour. In this study, the performance of machine learning-based structural health monitoring techniques are evaluated in predicting the joint shear capacity and the mode of failure for the exterior beam–column joint taking into account their complex structural behaviour through both numerical modelling and various machine learning techniques. The data used to train and test the model was collected from laboratory experiments and other test data available in the literature. The results indicated the superiority of the proposed particle swarm optimized artificial neural network (PSO-ANN) and XGboost over previously used approaches. Hence, the proposed techniques can be efficiently used for monitoring of structural performance by making informed decision regarding condition assessment of RC buildings.","Reinforced concrete structures, Beam–column joint, Machine learning, ANN, Artificial intelligence"
"Ezenkwu CP,Akpan UI,Stephen BU",A class-specific metaheuristic technique for explainable relevant feature selection,2021,"A significant amount of previous research into feature selection has been aimed at developing methods that can derive variables that are relevant to an entire dataset. Although these approaches have revealed substantial improvements in classification accuracy, they have failed to address the problem of explainability of outputs. This paper seeks to address this problem of identifying explainable features using a class-specific feature selection method based on genetic algorithms and the one-vs-all strategy. Our proposed method finds relevant features for each class in the dataset and uses these features to enable more accurate classification, and also interpretation of the outputs. The results of our experiments demonstrate that the proposed method provides descriptive insights into prediction outputs, and also outperforms popular global feature selection techniques in the classifications of high dimensional and noisy datasets. Since there are no known challenging benchmark datasets for evaluating class-specific feature selection algorithms, this paper also recommends an approach for combining disparate datasets for this purpose.","Feature selection, Explainable AI, XAI, Genetic algorithms, Metaheuristics, Nature-inspired"
"Singh MP,Singh G",Two phase learning technique in modular neural network for pattern classification of handwritten Hindi alphabets,2021,"Modular neural network overcomes the problem of monolithic structures of artificial neural networks. Generally modular neural network is an integration of smaller sub complete neural network models. Each model works independently on a sub portion of larger size pattern vectors. There are two ways of modularizing the neural network i.e. modularizing learning and modularizing structure. In this present work the modular neural network with modular learning for pattern classification of hand written Hindi alphabets is considered. In the presented approach 24 individual sub neural networks have been considered for first phase computing. In the second phase the collective outputs of first phase is presented as input to global neural network. Thus, the output of second phase presents the desired classification of the given large training set. Neural networks of first phase are trained locally for decomposed input patterns with gradient descent learning. Updated weights of the first phase are mapped to the global neural network. The global neural network is further trained for the collective output patterns of the first phase computing. Two phases of modular neural network i.e. decomposition and replication have been applied to perform the classification task. Simulation results are indicating that the complete neural network is approximated well when updated weights of first phase are combined with new weights of second phase and it generalized well when only updated weights of sub neural network of first phase are mapped to the connection strength of global neural network.","Modular neural networks, Pattern classification, Artificial neural networks, Modularizing learning, Pattern decomposition"
"McHugh C,Coleman S,Kerr D",Technical indicators for energy market trading,2021,"Technical indicators have been widely applied to the financial trading market, often combined with machine learning algorithms, to predict future stock market prices. The characteristics of energy market data are comparable to financial trading data; hence this research derives eight price prediction technical indicators for hourly electricity prices from the Irish Integrated Single Electricity Market. The proposed indicators consider the three key types of price indicators: trend, oscillator, and momentum. Building the technical indicators from raw electricity price data helps to capture market behaviours and find information to predict future profitable prices. The electricity price data for the proposed indicators were collected from February 2019 until March 2020. Three machine learning regression algorithms were trained with the technical indicators: Extreme Gradient Boosting, Gradient Boosting, and Random Forest. The results demonstrate that the price prediction models perform much better when trained using the proposed technical indicators when compared with baseline raw price data models.","Energy market, Hourly price forecasting, Regression machine learning, Technical indicators"
"Mallavarapu T,Cranfill L,Kim EH,Parizi RM,Morris J,Son J",A federated approach for fine-grained classification of fashion apparel,2021,"As online retail services proliferate and are pervasive in modern lives, applications for classifying fashion apparel features from image data are becoming more indispensable. Online retailers, from leading companies to start-ups, can leverage such applications in order to increase profit margin and enhance the consumer experience. Many notable schemes have been proposed to classify fashion items, however, the majority of such schemes have focused upon classifying basic-level categories, such as T-shirts, pants, skirts, shoes, bags, and so forth. In contrast to most prior efforts, this paper aims to enable an in-depth classification of fashion item attributes within the same category. Beginning with a single dress, we seek to classify the type of dress hem, the hem length, and the sleeve length. The proposed scheme is comprised of three major stages: (a) localization of a target item from an input image using semantic segmentation, (b) detection of human key points (e.g., point of shoulder) using a pre-trained CNN and a bounding box, and (c) three-phase classification of the attributes using a combination of algorithmic approaches and deep neural networks. The experimental results demonstrate that the proposed scheme is highly effective, with all categories having average precision of above 93.02%, and outperforms existing Convolutional Neural Networks (CNNs)-based schemes.","Apparel attributes, Apparel classification, Fine-grained classification, Human keypoints detection"
Taraba P,Linear regression on a set of selected templates from a pool of randomly generated templates,2021,"We study linear regression for two datasets. For the MNIST dataset we do so using max convolutions, whose parameters are generated directly from training images for the digit recognition problem, hence we call them max convolution templates. From a large pool of randomly generated convolutional templates, we select by iterative process the ones which improve defined linear regression minimization problem the most. With these templates, we use linear and logistic regression and achieve high accuracy, comparable with deep neural networks. We explain why, in a production environment, using this approach has advantages over the use of deep neural networks. On a second dataset ‘Adult Data Set’ of income predictions, we show a similar convolution type approach for generating a pool of random templates and show that the same template selection process and linear regression can be used as for the MNIST dataset.","Machine learning, Digit recognition, Linear regression, Deep networks, Image processing"
Chelgani SC,Estimation of gross calorific value based on coal analysis using an explainable artificial intelligence,2021,"Developing fuel resources is strategically crucial for Armenia. Far more than any other fossil fuel resource, coal roughly generates half the nation’s electricity. Although coal could play a critical role, no vast data is available about Armenia coal properties. Using robust modeling of energy indexes such as coal gross calorific value (GCV) by considering trivial existing datasets could be an essential clue for ensuring sustainable development. For the first time, this investigation is going to model GCV for Armenia coal samples. For this purpose, SHAP (SHapley Additive exPlanations) as a novel explainable artificial intelligence will be introduced. SHAP enables understanding the magnitude of relationships between each individual input record and its representative output and ranks input variables based on their effectiveness. SHAP was coupled by extreme gradient boosting (xgboost) as the most recently generated powerful predictive machine learning tool (SHAP-Xgboost). SHAP-Xgboost could accurately (R2=0.99) model GCV based on proximate and ultimate variables of Armenia coal samples. These significant outcomes open a new window for developing high interpretability models to assess coal properties and pinpoint the influential parameters.","Gross calorific value, SHapley Additive exPlanations, Extreme gradient boosting, Energy"
"Oyedele AO,Ajayi AO,Oyedele LO",Machine learning predictions for lost time injuries in power transmission and distribution projects,2021,"Although advanced machine learning algorithms are predominantly used for predicting outcomes in many fields, their utilisation in predicting incident outcome in construction safety is still relatively new. This study harnesses Big Data with Deep Learning to develop a robust safety management system by analysing unstructured incident datasets consisting of 168,574 data points from power transmission and distribution projects delivered across the UK from 2004 to 2016. This study compared Deep Learning performance with popular machine learning algorithms (support vector machine, random forests, multivariate adaptive regression splines, generalised linear model, and their ensembles) concerning lost time injury and risk assessment in power utility projects. Deep Learning gave the best prediction for safety outcomes with high skills (AUC = 0.95, R2 = 0.88, and multi-class ROC = 0.93), thus outperforming the other algorithms. The results from this study also highlight the significance of quantitative analysis of empirical data in safety science and contribute to an enhanced understanding of injury patterns using predictive analytics in conjunction with safety experts’ perspectives. Additionally, the results will enhance the skills of safety managers in the power utility domain to advance safety intervention efforts.","Hazard assessment, Deep learning, Big data predictive analytics, Power infrastructure, Zero count data"
"Nsugbe E,Obajemu O,Samuel OW,Sanusi I",Enhancing care strategies for preterm pregnancies by using a prediction machine to aid clinical care decisions,2021,"Preterm births are one of the main causes of death in children under the age of 5; they carry financial implications to the economy and cause exceptional psychological distress to mothers and their families. Prior work has been done in the application of classification methods towards predicting whether a pregnant patient is likely to deliver preterm, but the majority of these solutions have been done separately without full consideration of how their proposed solution can be integrated into a clinical system setup. In this work, we propose a multi order cybernetic framework to design a recommender system that can be used to form a closed loop clinical interaction poised towards steering a system from its current state into a more desirable outcome. Using fused estimates from both electrohysterogram (electrophysiology) and tocogram (mechanical) signals from uterine wall contractions, a classification machine was designed to classify between Preterm/Term states, and also predict an associated delivery imminency for the pregnant patient. The classification machine was implemented using a multilayer perceptron neural network (MLP) and a support vector machine (SVM), where it was seen that the SVM outperformed the MLP in the majority of the classification tasks. Further work in this area would involve the application of regression techniques towards the classification tasks, which is expected to also provide greater model interpretability and continuous state estimation.","Cybernetics, Electromagnetism, Decision support, SVM, Artificial intelligence, Signal processing"
"Aria M,Cuccurullo C,Gnasso A",A comparison among interpretative proposals for Random Forests,2021,"The growing success of Machine Learning (ML) is making significant improvements to predictive models, facilitating their integration in various application fields. Despite its growing success, there are some limitations and disadvantages: the most significant is the lack of interpretability that does not allow users to understand how particular decisions are made. Our study focus on one of the best performing and most used models in the Machine Learning framework, the Random Forest model. It is known as an efficient model of ensemble learning, as it ensures high predictive precision, flexibility, and immediacy; it is recognized as an intuitive and understandable approach to the construction process, but it is also considered a Black Box model due to the large number of deep decision trees produced within it. The aim of this research is twofold. We present a survey about interpretative proposal for Random Forest and then we perform a machine learning experiment providing a comparison between two methodologies, inTrees, and NodeHarvest, that represent the main approaches in the rule extraction framework. The proposed experiment compares methods performance on six real datasets covering different data characteristics: n. of observations, balanced/unbalanced response, the presence of categorical and numerical predictors. This study contributes to picture a review of the methods and tools proposed for ensemble tree interpretation, and identify, in the class of rule extraction approaches, the best proposal.","Random Forest, Model interpretation, Rule extraction, inTrees, NodeHarvest"
"Brosch T,Peters J,Groth A,Weber FM,Weese J",Model-based segmentation using neural network-based boundary detectors: Application to prostate and heart segmentation in MR images,2021,"Model-based segmentation (MBS) is a variant of active surfaces and active shape models that has successfully been used to segment anatomical structures such as the heart or the brain. We propose to integrate neural networks (NNs) into MBS for boundary detection. We formulate boundary detection as a regression task and use a NN to predict the distances between a surface mesh and the corresponding boundary points. The proposed approach has been applied to two tasks — prostate segmentation in MR images and the segmentation of the left and right ventricle in MR images. For the first task, data from the Prostate MR Image Segmentation 2012 (PROMISE12) challenge has been used. For the second task, a diverse database with cardiac MR images from six clinical sites has been used. We compare the results to the popular U-net approaches using the nnU-net implementation that is among the top performing segmentation algorithms in various challenges. In cross-validation experiments, the mean Dice scores are very similar and no statistically significant difference is observed. On the PROMISE12 test set, nnU-net Dice scores are significantly better. This is achieved by using an ensemble of 2D and 3D U-nets to generate the final segmentation, a concept that may also be adapted to NN-based boundary detection in the future. While the U-net provides a voxel labeling, our approach provides a 3D surface mesh with pre-defined mesh topology, establishes correspondences with respect to the reference mesh, avoids isolated falsely segmented regions and ensures proper connectivity of different regions.","Model-based segmentation, Boundary detection, Neural networks, Prostate, Heart, MRI"
"Chai J,Zeng H,Li A,Ngai EW",Deep learning in computer vision: A critical review of emerging techniques and application scenarios,2021,"Deep learning has been overwhelmingly successful in computer vision (CV), natural language processing, and video/speech recognition. In this paper, our focus is on CV. We provide a critical review of recent achievements in terms of techniques and applications. We identify eight emerging techniques, investigate their origins and updates, and finally emphasize their applications in four key scenarios, including recognition, visual tracking, semantic segmentation, and image restoration. We recognize three development stages in the past decade and emphasize research trends for future works. The summarizations, knowledge accumulations, and creations could benefit researchers in the academia and participators in the CV industries.","Machine learning, Deep learning, Computer vision, Literature review"
"Peng J,Debnath M,Biswas AK",Efficacy of novel Summation-based Synergetic Artificial Neural Network in ADHD diagnosis,2021,"Attention Deficit Hyperactivity Disorder (ADHD) is a critical condition that affects millions of children and often continues into adulthood. In this paper, we propose a dual 3D CNN data integration platform, that we call SSANN, a Summation-based Synergetic Artificial Neural Network, for ADHD diagnosis. The diagnosis problem in our research is simplified into a binary classification problem to detect an ADHD affected or a typical developing child given magnetic resonance imaging scans. Our proposed model has two 3D CNN branches with varying structures: (1) The first branch extracts features from the functional MRI (fMRI) data from the subjects, (2) the second branch extracts features from the structural MRI (sMRI) data of the corresponding subjects. Later, output matrices of both branches are combined with a proposed summation induced process which then is fed into a fully connected neural network and finally produce the binary classification prediction. Our proposed model achieved accuracy of 72.89% on the ADHD-200 dataset, which performs superior than the state-of-the-art approaches on the same evaluation dataset. Our proposed SSANN model can extract useful features from the fMRI and sMRI data, which can also be employed to understand the brain anatomy and its functions in the subjects better, as well as can be used in other machine learning algorithms to design and develop diagnostic tools that certainly has potential to escort ADHD research move forward. Our proposed model offers a robust multi-modal data integration platform that can also be adapted in other medical imaging domains.","Magnetic resonance imaging, fMRI, sMRI, Convolution Neural Network (CNN), Bilinear CNN, Synergetic Artificial Neural Network, Data integration"
"Sharifi A,Zibaei A,Rezaei M",A deep learning based hazardous materials (HAZMAT) sign detection robot with restricted computational resources,2021,"One of the most challenging and non-trivial tasks in robot-based rescue operations is the Hazardous Materials (HAZMAT) sign detection in dangerous operation fields, in order to prevent further unexpected disasters. Each HAZMAT sign has a specific meaning that the rescue robot should detect and interpret to take a safe action, accordingly. Accurate HAZMAT detection and real-time processing are the two most important factors in such robotics applications. Furthermore, the rescue robot should cope with some secondary challenges such as image distortion and restricted CPU and computational resources, embedded in the robot. In this research, we propose a CNN-Based pipeline called DeepHAZMAT for HAZMAT sign detection and segmentation in four steps: (1) Input data volume optimisation before feeding into the CNN network, (2) Application of a YOLO-based structure to collect the required visual information from the hazardous areas, (3) HAZMAT sign segmentation and separation from the background using adaptive GrabCut technique, and (4) Post-processing optimisation using morphological operators and convex hull algorithms. In spite of the utilisation of a very limited CPU and memory resources, the experimental results show the proposed method has successfully maintained a better performance in terms of detection-speed and detection-accuracy, compared to classical and modern state-of-the-art methods.","Hazardous materials, Object recognition, HAZMAT sign detection, Segmentation, CNN, Rescue robotics"
Bhatnagar JR,Basic bounds on cluster error using distortion-rate,2021,"Clustering is a popular type of unsupervised learning technique that performs natural groupings on samples to generate probably approximately correct groups. These clusters or groups are expected to have high intra-similarity and high inter-distinctiveness. Practical clustering problems may combine varying levels of intra-similarity or quality and distinctiveness or diversity. We propose an information analytic approach to measure the quality and diversity given in terms of the cluster error. Unlike previous models that show information measures derived from probability of samples in cluster, the proposed framework employs distortion-rate approach by first formulating the probability of distortion for multiple-types of samples in the cluster. In this framework, cluster formation is shown as naturally greedy action which leads to showing the average minimum distortion of cluster. We also obtain probabilistic bounds on the cluster error and present case study on use of distortion-rate approach for clustering. For limiting case of binary typical cluster, the bound is shown to resemble Fano inequality. For the first time, analytic performance limits along with notion of bias and variance are formalized for clustering.","Cluster error, Distortion-rate, Greedy search, Fano inequality, Unsupervised learning"
"Bugnon LA,Raad J,Merino GA,Yones C,Ariel F,Milone DH,Stegmayer G",Deep Learning for the discovery of new pre-miRNAs: Helping the fight against COVID-19,2021,"The Severe Acute Respiratory Syndrome-Coronavirus 2 (SARS-CoV-2) has been recently found responsible for the pandemic outbreak of a novel coronavirus disease (COVID-19). In this work, a novel approach based on deep learning is proposed for identifying precursors of small active RNA molecules named microRNA (miRNA) in the genome of the novel coronavirus. Viral miRNA-like molecules have shown to modulate the host transcriptome during the infection progression, thus their identification is crucial for helping the diagnosis or medical treatment of the disease. The existence of the mature miRNAs derived from computationally predicted miRNA precursors (pre-miRNAs) in the novel coronavirus was validated with small RNA-seq data from SARS-CoV-2-infected human cells. The results demonstrate that computational models can provide accurate and useful predictions of pre-miRNAs in the SARS-CoV-2 genome, underscoring the relevance of machine learning in the response to a global sanitary emergency. Moreover, the interpretability of our model shed light on the molecular mechanisms underlying the viral infection, thus contributing to the fight against the COVID-19 pandemic and the fast development of new treatments. Our study shows how recent advances in machine learning can be used, effectively, in response to public health emergencies. The approach developed in this work could be of great help in future similar emergencies to accelerate the understanding of the singularities of any viral agent and for the development of novel therapies. Data and source code available at: https://sourceforge.net/projects/sourcesinc/files/aicovid/.","COVID-19, Deep learning, Computational prediction, Pre-miRNAs"
"Dikshit A,Pradhan B",Explainable AI in drought forecasting,2021,"Droughts are one of the disastrous natural hazards which has severe impacts on agricultural production, economy, and society. One of the critical steps for effective drought management is developing a robust forecasting model and understanding how the variables affect the model outcomes. The present study forecasts SPI-12 at a lead time of 3 months, using the Long Short-Term Memory (LSTM) model, and further interprets the spatial and temporal relationship between variables and forecasting results using SHapley Additive exPlanations (SHAP). The developed model is tested in four different regions in New South Wales (NSW), Australia. SPI-12 was computed using monthly rainfall data collected from Scientific Information for Land Owners (SILO) for 1901–2018. The model was trained from 1901–2000 and tested from 2001–2018, and the performance was measured using Coefficient of Determination (R2), Nash–Sutcliffe Efficiency (NSE) and Root-Mean-Square-Error (RMSE). To understand the underlying impact of variables on the model outcomes, SHAPley values were calculated for the entire testing period and also at three different temporal ranges, which are during the Millennium Drought (2001–2010), post drought period (2011–2018) and at a seasonal scale (summer months). The comparison of the results shows a significant variation in the impact of variables on forecasting, both temporally and spatially. It also shows the need to study the model outcomes for specific regions and for a shorter duration than the entire testing period. This is a first of its study towards interpreting the forecasting model in drought studies, which could help understand the behaviour of drought variables.","Drought forecasting, Standard precipitation index, Deep learning, Explainable AI"
"Hasan MM,Young GJ,Patel MR,Modestino AS,Sanchez LD,Noor-E-Alam M",A machine learning framework to predict the risk of opioid use disorder,2021,"Opioid overdose epidemic is a national public health crisis in the US. Little is known about how large-scale data analytics can be leveraged to help physicians predict whether a prescription opioid user will develop opioid use disorder. To that end, we proposed a machine learning framework for identifying potential risk factors of opioid use disorder from a large-scale healthcare claims data. These risk factors identified by the proposed framework can be used to predict which patient will be at higher risk of opioid use disorder following an opioid prescription. We utilized clinical diagnosis and prescription histories from Massachusetts commercially insured individuals who were prescribed opioids. We performed several feature selection techniques on a class imbalanced analytic sample to identify patient-level demographic and clinical features that were influential predictors of opioid use disorder. We, then compared the predictive power of four well-known machine learning algorithms: Logistic Regression, Random Forest, Decision Tree, and Gradient Boosting to predict the patients’ risk of opioid use disorder. The study results showed that the Random Forest model achieved superior predictive performance in terms of AUC and recall. Alongside the higher predictive accuracy, the random forest model identified clinical features, some of which were fairly consistent with prior clinical findings. In addition, our proposed framework is capable of extracting some other clinical features, which are predictive of opioid use disorder and indicative as the proxies of patients’ health status. We anticipate that the findings of our study will potentially help reduce in-appropriate and over prescription of opioids.","Opioid use disorder, Opioid addiction epidemic, Risk prediction, Big data analytics, Machine learning, Predictive analytics"
"Le QT,Ooi C",Surrogate modeling of fluid dynamics with a multigrid inspired neural network architecture,2021,"Algebraic or geometric multigrid methods are commonly used in numerical solvers as they are a multi-resolution method able to handle problems with multiple scales. In this work, we propose a modification to the commonly-used U-Net neural network architecture that is inspired by the principles of multigrid methods, referred to here as U-Net-MG. We then demonstrate that this proposed U-Net-MG architecture can successfully reduce the test prediction errors relative to the conventional U-Net architecture when modeling a set of fluid dynamic problems. In total, we demonstrate an improvement in the prediction of velocity and pressure fields for the canonical fluid dynamics cases of flow past a stationary cylinder, flow past 2 cylinders in out-of-phase motion, and flow past an oscillating airfoil in both the propulsion and energy harvesting modes. In general, while both the U-Net and U-Net-MG models can model the systems well with test RMSEs of less than 1%, the use of the U-Net-MG architecture can further reduce RMSEs by between 20% and 70%.","Surrogate modeling, Machine learning, Convolutional Neural Network (CNN), Multigrid, Computational Fluid Dynamics (CFD)"
"Ramirez-Vergara J,Bosman LB,Leon-Salas WD,Wollega E",Ambient temperature and solar irradiance forecasting prediction horizon sensitivity analysis,2021,"Selecting the correct weather forecasting technique is a crucial task when planning an efficient solar energy generation system. Estimating accurate solar photovoltaic systems power output depends on the correct modeling of solar irradiance and ambient temperature, evidencing the need for a framework to select the correct technique to forecast these parameters. This paper presents a review of the forecasting methods to predict solar irradiance and ambient temperature, considering the sensitivity to the forecasting horizon. The methodology includes estimating an interval for ambient temperature and solar irradiance by using the Mean Absolute Error as the percentage of variation in these parameters. To provide context, the study considers best-case and worst-case scenarios for four cities, estimating the power output for a sample array and analyzing the differences between the cases. The power output estimation of the PV array varied between 36% and 50% (on average) for the short-term prediction, and 54% to 95% for the long-term. The changes in the location produced an average variation of 43% in terms of power production, and up to 187% in economic value (USD) for the short term, and 44.5% and 187% for the long term. The results suggest a marked sensitivity to the variation in the forecasting horizon and significance with regards to location selection (considering the changes in solar irradiation and the cost of electricity).","Machine learning, Mean absolute error, Photovoltaic systems planning, Sensitivity analysis"
"Osegi EN,Jumbo EF",Comparative analysis of credit card fraud detection in Simulated Annealing trained Artificial Neural Network and Hierarchical Temporal Memory,2021,The problem of misclassification has always been a major concern in detecting online credit card fraud in e-commerce systems. This concern greatly poses a significant challenge to financial institutions and online merchants with regards to financial loss. This paper specifically compares an Artificial Neural Network trained by the Simulated Annealing technique (SA-ANN) with a proposed emerging online learning technology in anomaly detection known as the Hierarchical Temporal Memory based on the Cortical Learning Algorithms (HTM-CLA). Comparisons are also made with a deep recurrent neural technique based on the Long Short-Term Memory ANN (LSTM-ANN). The performances of these systems are investigated on the basis of correctly classifying credit card fraud (CCF) using an average classification performance ratio metric. The results of simulations on two CCF benchmark datasets (the Australian and German CCF data) showed promising competitive performance of the proposed HTM-CLA with the SA-ANN. The HTM-CLA also clearly outperformed the LSTM-ANN in the considered benchmark datasets by a factor of 2:1.,"Hierarchical Temporal Memory, Artificial Neural Network, Simulated Annealing Algorithm, Cortical Learning Algorithm, Misclassification, Sparse distributed representation"
"Parisi L,Ma R,RaviChandran N,Lanzillotta M",hyper-sinh: An accurate and reliable function from shallow to deep learning in TensorFlow and Keras,2021,"This paper presents the ‘hyper-sinh’, a variation of the m-arcsinh activation function suit-able for Deep Learning (DL)-based algorithms for supervised learning, including Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN), such as the Long Short-Term Memory (LSTM). hyper-sinh, developed in the open-source Python libraries TensorFlow and Keras, is thus described and validated as an accurate and reliable activation function for shallow and deep neural networks. Improvements in accuracy and reliability in image and text classification tasks on six (N=6) medium-to-large open-source benchmark datasets are discussed. Experimental results demonstrate that the overall competitive classification performance of the novel hyper-sinh function on shallow and deep neural networks yielded the highest performance. Furthermore, this activation is evaluated against other gold standard activation functions, demonstrating its overall competitive accuracy and reliability for both image and text classification tasks.","Activation, Deep learning, Convolutional Neural Network, Long short-term memory, TensorFlow, Keras"
"Murashova GA,Colbry D",GM FASST: General Method for Labeling Augmented Sub-sampled Images from a Small Data Set for Transfer Learning,2021,"In this work, the use of transfer learning was explored to achieve the overall goal of classifying a small number (approx. 215 images) of Nonlinear Multiphoton Multimodal Microscopy Images of unstained oral cancer biopsies into three categories—healthy, inflammatory, and cancerous. This is achieved by first training a neural network model to detect basic histological components of human tissues, such as the stroma and mucosa, from a much larger (5000 images) Kaggle data set containing images of stained human colorectal cancer biopsies. Experiments were conducted to optimize the model’s architecture and hyperparameters, i.e., hidden layers, optimizers, and API callback functions used prior to retraining the model on a new and much smaller data set consisting of 215 Nonlinear Multiphoton Multimodal Microscopy Images. In addition to having different class labels, these images were acquired using an entirely different imaging and detection set up, and thus have different features than the Kaggle data set. In order to expand the limited size of the Nonlinear Multiphoton Multimodal Microscopy Images data set; tiling methods were used to sub-sample and augment the images though standard transforms such as rotation, scaling and mirroring. This research shows transfer learning and data set re-sampling can improve classification accuracy by 10% over training on the smaller data set alone.","Machine learning, Transfer learning, Image classification"
Petneházi G,Quantile convolutional neural networks for Value at Risk forecasting,2021,"This article presents a new method for forecasting Value at Risk. Convolutional neural networks can do time series forecasting, since they can learn local patterns in time. A simple modification enables them to forecast not the mean, but arbitrary quantiles of the distribution, and thus allows them to be applied to VaR-forecasting. The proposed model can learn from the price history of different assets, and it seems to produce fairly accurate forecasts.","Quantile regression, Convolutional neural network, Value at Risk, Forecasting"
"Saeed A,Ungureanu V,Gfeller B",Sense and Learn: Self-supervision for omnipresent sensors,2021,"Learning general-purpose representations from multisensor data produced by the omnipresent sensing systems (or IoT in general) has numerous applications in diverse use cases. Existing purely supervised end-to-end deep learning techniques depend on the availability of a massive amount of well-curated data, acquiring which is notoriously difficult but required to achieve a sufficient level of generalization on a task of interest. In this work, we leverage the self-supervised learning paradigm towards realizing the vision of continual learning from unlabeled inputs. We present a generalized framework named Sense and Learn for representation or feature learning from raw sensory data. It consists of several auxiliary tasks that can learn high-level and broadly useful features entirely from unannotated data without any human involvement in the tedious labeling process. We demonstrate the efficacy of our approach on several publicly available datasets from different domains and in various settings, including linear separability, semi-supervised or few shot learning, and transfer learning. Our methodology achieves results that are competitive with the supervised approaches and close the gap through fine-tuning a network while learning the downstream tasks in most cases. In particular, we show that the self-supervised network can be utilized as initialization to significantly boost the performance in a low-data regime with as few as 5 labeled instances per class, which is of high practical importance to real-world problems. Likewise, the learned representations with self-supervision are found to be highly transferable between related datasets, even when few labeled instances are available from the target domains.","Self-supervised learning, Low-data regime, Sensors, Unsupervised learning, Neural networks, Time-series, Sensing"
"Sreeramula S,Rahardjo D",Estimating COVID-19 Rt in Real-time: An Indonesia health policy perspective,2021,"COVID-19 (SARS COV2 n-corona virus) is the newfangled virus of the coronavirus family. COVID-19 can cause serious illness with symptoms of fever, cold, cough, and respiratory blockage. COVID-19 is a contagious virus, which originated in Wuhan, China. After one month, WHO declared it as a Pandemic due to its rapid spreading. Presently, Indonesia is also facing a hard time controlling the spread. Hence, it is essential to understand the spread rate in Indonesia and to analyze the strategies to minimize the virus spread. The proposed study can be used to assess variations in virus spread both nationally, and sub-nationally. This allows public health officials and policy-makers to track the progress of the outbreak in near real-time using an epidemiologically valid measure.","Epidemic outbreak, Coronavirus, COVID-19, Bayesian, Likelihood, Spread rate, Posterior"
"Dong L,Inoue K",Super-resolution reconstruction based on two-stage residual neural network,2021,"With the constant update of deep learning technology, the super-resolution reconstruction technology based on deep learning has also attained a significant breakthrough. This paper primarily discusses the integration of deep learning and super-resolution reconstruction techniques. Regarding the application of deep learning in super-resolution reconstruction, the improvement is focused on the two dimensions of algorithm efficiency and reconstruction effect. On the basis of the currently available neural network algorithms, this paper puts forward the two-stage residual super-resolution reconstruction network structure. Thereinto, the improvement is mainly embodied in the modification of the image feature extraction network modules and the increase of the residual block into two stages. It is experimentally evidenced by algorithm simulation that the two-stage residual network in this paper shows a certain extent of improvement for the super-resolution reconstruction effect compared with the related methods.","Super-resolution reconstruction, Deep learning, Two-stage residual network"
"Abdollahi A,Pradhan B",Integrating semantic edges and segmentation information for building extraction from aerial images using UNet,2021,"Understanding urban dynamics, such as estimating population, urban development, and several other uses, necessitates up-to-date large-scale building maps. Since aerial imagery provides enough textural and structural details, it has been utilized as a critical data source for building detection. However, accurate mapping of building objects from aerial imagery is a challenging task. This problem is attributed due to presence of vegetation and shadows in images that present similar spectral values and transparency as a building class. To deal with the issues mentioned above, we offer a new deep-learning structure named MultiRes-UNet network, which is an improved version of the original UNet network. In the proposed network, we utilized the MultiRes block to assimilate the features learned from the data at various scales and comprise some more spatial details. Also, we suggest the incorporation of several convolutional operations along with the skip connections to mitigate the differences between the encode–decoder features. Furthermore, we integrated semantic edge information with semantic polygons to solve the issue of irregular semantic polygons and enhance the boundary of semantic polygons. We tested our network on aerial images for roof segmentation dataset, and the experimental results exhibited that the proposed network can improve the quantitative results of Intersection Over Union to 0.78% after adding semantic edges. We also used state-of-the-art comparative models such as UNet, DeeplabV3, ResNet, and FractalNet networks to show the competency of the introduced network, and the results prove the success of the introduced network for building object extraction from aerial imagery.","AIRS, Buildings mapping, Deep learning, MultiRes-UNet, UNet architecture, Remote sensing"
"Parr T,Wilson JD",Partial dependence through stratification,2021,"Partial dependence curves (FPD) are commonly used to explain feature importance once a supervised learning model has been fitted to data. However, it is common for the same partial dependence algorithm to give meaningfully different curves for different supervised models, even when the algorithm is applied to the same data. As a result, it is difficult to distinguish between model artifacts and true relationships in the data. In this paper, we contribute metods for computing partial dependence curves, for both numerical (StratPD) and categorical explanatory variables (CatStratPD), that work directly from training data rather than the predictions of a fitted model. Our methods provide a direct estimate of partial dependence, and rely on approximating the partial derivative of an unknown regression function. We investigate settings where contemporary partial dependence methods – including FPD, Accumulated Local Effects (ALE), and SHapley Additive exPlanations (SHAP) methods – give biased results. We demonstrate that our approach works correctly on synthetic data and plausibly on real data sets. This work motivates a new line of inquiry into nonparametric partial dependence that provides robust information about the variables considered in a supervised learning task.","Decision trees, Feature importance, Random forests, Variable importance"
"Ghojogh B,Karray F,Crowley M",Quantile–Quantile Embedding for distribution transformation and manifold embedding with ability to choose the embedding distribution,2021,"We propose a new embedding method, named Quantile–Quantile Embedding (QQE), for distribution transformation and manifold embedding with the ability to choose the embedding distribution. QQE, which uses the concept of quantile–quantile plot from visual statistical tests, can transform the distribution of data to any theoretical desired distribution or empirical reference sample. Moreover, QQE gives the user a choice of embedding distribution in embedding the manifold of data into the low dimensional embedding space. It can also be used for modifying the embedding distribution of other dimensionality reduction methods, such as PCA, t-SNE, and deep metric learning, for better representation or visualization of data. We propose QQE in both unsupervised and supervised forms. QQE can also transform a distribution to either an exact reference distribution or its shape. We show that QQE allows for better discrimination of classes in some cases. Our experiments on different synthetic and image datasets show the effectiveness of the proposed embedding method.","Quantile–Quantile Embedding (QQE), Quantile–quantile plot, Distribution transformation, Manifold embedding, Embedding distribution, Class discrimination"
"Amara A,Hadj Taieb MA,Ben Aouicha M",Network representation learning systematic review: Ancestors and current development state,2021,"Real-world information networks are increasingly occurring across various disciplines including online social networks and citation networks. These network data are generally characterized by sparseness, nonlinearity and heterogeneity bringing different challenges to the network analytics task to capture inherent properties from network data. Artificial intelligence and machine learning have been recently leveraged as powerful systems to learn insights from network data and deal with presented challenges. As part of machine learning techniques, graph embedding approaches are originally conceived for graphs constructed from feature represented datasets, like image dataset, in which links between nodes are explicitly defined. These traditional approaches cannot cope with network data challenges. As a new learning paradigm, network representation learning has been proposed to map a real-world information network into a low-dimensional space while preserving inherent properties of the network. In this paper, we present a systematic comprehensive survey of network representation learning, known also as network embedding, from birth to the current development state. Through the undertaken survey, we provide a comprehensive view of reasons behind the emergence of network embedding and, types of settings and models used in the network embedding pipeline. Thus, we introduce a brief history of representation learning and word representation learning ancestor of network embedding. We provide also formal definitions of basic concepts required to understand network representation learning followed by a description of network embedding pipeline. Most commonly used downstream tasks to evaluate embeddings, their evaluation metrics and popular datasets are highlighted. Finally, we present the open-source libraries for network embedding.","Network representation learning, Network embedding, Node embedding, Real-world information networks, Graph embedding, Low-dimensional vector"
"Mallick A,Dhara S,Rath S",Application of machine learning algorithms for prediction of sinter machine productivity,2021,"Sinter machine productivity is key techno-economic parameter of an integrated steel plant. It depends upon the composition of different constituents like iron ore fines, flux and coke breeze which are agglomerated to produce sinter for blast furnaces. It is difficult to assess the interdependence of these constituents and their effect on sinter productivity through physical experimentation. In this paper, machine learning and data analytics approach have been applied to predict the sinter machine productivity. Industrial data of sinter machine productivity from an integrated steel plant have been collected. Linear regression and artificial neural network (ANN) models were developed to predict sinter machine productivity with the composition of constituent materials of the agglomerate as model inputs. The ANN model, developed in the present work, agrees well with measured sinter machine productivity. Sensitivity analysis identified that, percentage of MgO in flux and CaO in sinter have a highly detrimental effect whereas total Fe content in iron ore fines and percentage of SiO 2 in sinter have the most favorable impact on sinter machine productivity.","Sinter machine productivity, Linear regression, Artificial neural network, Sensitivity analysis"
"Tuan PM,Phan TL,Adel M,Guedj E,Trung NL",AutoEncoder-based feature ranking for Alzheimer Disease classification using PET image,2021,"This paper presents a method of ranking the effectiveness of brain region of interest (ROI) in order to separate Normal Control (NC) from Alzheimer’s disease (AD) brains Positron Emission Tomography (PET) images based on AutoEncoder (AE) networks. Firstly, PET brains are mapped into ROIs using an anatomical atlas. Then, multiple AE models are trained and fine-tuned with softmax. After that, the connection weights learned from AEs are used to rank ROIs according to the total contribution of ROIs to the networks. We proposed a 2-phase feature ranking method which is able to significantly improve the ranking results. Lastly, the top-ranked ROIs are then input into a support vector machine (SVM) classifier. In experiments on ADNI dataset, the proposed method significantly improves the accuracy of the classifier when compared to other popular feature ranking methods such as: Fisher score, T-score, Conditional Mutual Information Maximization (CMIM), and Lasso. Our result shows that simple single-hidden-layer AE models can be used effectively to perform the feature ranking task. The proposed method could be easily applied to any image dataset where a feature selection is needed.","AutoEncoder feature ranking, Positron emission tomography, Alzheimer’s Disease classification"
"Asani E,Vahdat-Nejad H,Sadri J",Restaurant recommender system based on sentiment analysis,2021,"Today, exploiting sentiment analysis has become popular in designing recommender systems in various fields, including the restaurant and food area. However, most of the sentiment analysis-based restaurant recommender systems only use static information such as food quality, price, and service quality. The analysis of users’ opinions and the extraction of their food preferences lead to the provision of personalized recommendations, which is a research gap in literature; In this paper, a context-aware recommender system is proposed that extracts the food preferences of individuals from their comments and suggests restaurants in accordance with these preferences. For this purpose, the semantic approach is used to cluster the name of foods extracted from users’ comments and analyze their sentiments about them. Finally, nearby open restaurants are recommended based on their similarity to user preferences. For evaluation, the TripAdvisor website has been used and comments from 100 different users have been collected during the first 9 months of 2018. The precision, recall and f-measure of the system are measured in three scenarios of top1, top3, and top5. The results indicate that the proposed system can provide recommendations with a precision of 92.8%, giving users a high degree of precision. Besides, the system outperforms the previous research in these criteria.","Recommender system, Sentiment analysis, Context-awareness, Preference extraction, Semantic computing"
"Matharaarachchi S,Domaratzki M,Muthukumarana S",Assessing feature selection method performance with class imbalance data,2021,"Identifying the most informative features is a crucial step in feature selection. This paper focuses primarily on wrapper feature selection methods designed to detect important features with F1-score as the target metric. As an initial step, most wrapper methods order features according to importance. However, in most cases, the importance is defined according to the classification method used and varies with the characteristics of the data set. Using synthetically simulated data, we examine four existing feature ordering techniques to find the most desirable and the most effective ordering mechanism to identify informative features. Using the results, an improved method is suggested to extract the most informative feature subset from the data set. The method uses the sum of absolute values of the first k principal component loadings to order the features where k is a user-defined application-specific value. It also applies a sequential feature selection method to extract the best subset of features. We further compare the performance of the proposed feature selection method with results from the existing Recursive Feature Elimination (RFE) by simulating data for several practical scenarios with a different number of informative features and different imbalance rates. We also validate the method using a real-world application on several classification methods. The results based on the accuracy measures indicate that the proposed approach performs better than the existing feature selection methods.","Feature selection, Informative feature, Recursive feature elimination, Principal component loading"
"Paturi UM,Cheruku S,Pasunuri VP,Salike S,Reddy NS,Cheruku S",Machine learning and statistical approach in modeling and optimization of surface roughness in wire electrical discharge machining,2021,"The current work implements machine learning techniques such as artificial neural network (ANN), support vector machine (SVM), and genetic algorithm (GA) to model and optimize the surface roughness during wire electrical discharge machining (WEDM) of Inconel 718. For this, surface roughness values were obtained from real-time WEDM experiments conducted under the different levels of control factors such as pulse on time, pulse off time, peak current, servo voltage, and wire feed rate. The optimum ANN model architecture was identified as 5-10-10-1 and SVM parameters were tuned with the help of the grid search technique. The ANN and SVM models’ predictions were compared with response surface methodology (RSM) predictions and performance was evaluated based on correlation coefficient (R-value) between experimental and model predictions. The SVM predictions were accurate among all the models studied, as determined from the R-value of 0.99998 with experimental results and the least mean absolute percentage error (MAPE) of 0.0347%. Further, the GA approach was implemented using the developed RSM equation as the fitness function and led to 61.31% improvement in the surface roughness. The proposed SVM and GA approach would help quick and high accurate prediction and optimization of surface roughness during WEDM of Inconel 718.","Artificial neural network, Support vector machine, Response surface methodology, Genetic algorithm, WEDM, Surface roughness"
"Liew XY,Hameed N,Clos J",An investigation of XGBoost-based algorithm for breast cancer classification,2021,"Breast cancer is one of the leading cancers affecting women around the world. The Computer-Aided Diagnosis (CAD) system is a powerful tool to assist pathologists during the process of diagnosing cancer, which effectively identifies the presence of cancerous cells. A standard CAD system includes processes of pre-processing, feature extraction, feature selection and classification. In this paper, we propose an enhanced breast cancer classification technique called Deep Learning and eXtreme Gradient Boosting (DLXGB) on histopathology breast cancer images using the BreaKHis dataset. This method first applies data augmentation and stain normalization for pre-processing, then pre-trained DenseNet201 will automatically learn features within an image and combine with a powerful gradient boosting classifier. The proposed classification technique is designed to classify breast cancer histology images into binary benign and malignant, and additionally one of eight non-overlapping/overlapping categories: i.e., Adenosis (A), Fibroadenoma (F), Phyllodes Tumour (PT), And Tubular Adenoma (TA) Ductal Carcinoma (DC), Lobular Carcinoma (LC), Mucinous Carcinoma (MC), And Papillary Carcinoma (PC). With DLXGB, we have obtained an accuracy of 97% for both binary and multi-classification improving the exiting work done by researchers using the BreaKHis dataset. The results indicated that this method could produce a powerful prediction for breast cancer image classification.","Deep learning, Extreme gradient boosting, XGBoost, Machine learning, Computer-aided diagnosis, Breast cancer, Histopathology images, Classification"
"Bishop TR,von Hinke S,Hollingsworth B,Lake AA,Brown H,Burgoine T",Automatic classification of takeaway food outlet cuisine type using machine (deep) learning,2021,"Background and purpose: Researchers have not disaggregated neighbourhood exposure to takeaway (‘fast-’) food outlets by cuisine type sold, which would otherwise permit examination of differential impacts on diet, obesity and related disease. This is partly due to the substantial resource challenge of manual classification of unclassified takeaway outlets at scale. We describe the development of a new model to automatically classify takeaway food outlets, by 10 major cuisine types, based on business name alone. Material and methods: We used machine (deep) learning, and specifically a Long Short Term Memory variant of a Recurrent Neural Network, to develop a predictive model trained on labelled outlets (n=14,145), from an online takeaway food ordering platform. We validated the accuracy of predictions on unseen labelled outlets (n=4,000) from the same source. Results: Although accuracy of prediction varied by cuisine type, overall the model (or ‘classifier’) made a correct prediction approximately three out of four times. We demonstrated the potential of the classifier to public health researchers and for surveillance to support decision-making, through using it to characterise nearly 55,000 takeaway food outlets in England by cuisine type, for the first time. Conclusions: Although imperfect, we successfully developed a model to classify takeaway food outlets, by 10 major cuisine types, from business name alone, using innovative data science methods. We have made the model available for use elsewhere by others, including in other contexts and to characterise other types of food outlets, and for further development.","Takeaway (‘fast-’) food outlets, Cuisine type, Classification, Machine (deep) learning, Universal Language Model Fine-tuning (ULMFiT), Data science"
"Arias-Garzón D,Alzate-Grisales JA,Orozco-Arias S,Arteaga-Arteaga HB,Bravo-Ortiz MA,Mora-Rubio A,Saborit-Torres JM,Serrano JÁ,de la Iglesia Vayá M,Cardona-Morales O,Tabares-Soto R",COVID-19 detection in X-ray images using convolutional neural networks,2021,"COVID-19 global pandemic affects health care and lifestyle worldwide, and its early detection is critical to control cases’ spreading and mortality. The actual leader diagnosis test is the Reverse transcription Polymerase chain reaction (RT-PCR), result times and cost of these tests are high, so other fast and accessible diagnostic tools are needed. Inspired by recent research that correlates the presence of COVID-19 to findings in Chest X-ray images, this papers’ approach uses existing deep learning models (VGG19 and U-Net) to process these images and classify them as positive or negative for COVID-19. The proposed system involves a preprocessing stage with lung segmentation, removing the surroundings which does not offer relevant information for the task and may produce biased results; after this initial stage comes the classification model trained under the transfer learning scheme; and finally, results analysis and interpretation via heat maps visualization. The best models achieved a detection accuracy of COVID-19 around 97%.","COVID-19, Deep learning, Transfer learning, X-ray, Segmentation"
"Lumini A,Nanni L,Scattolaro L,Maguolo G",Image orientation detection by ensembles of Stochastic CNNs,2021,"In this paper we deal with the problem of accurately and automatically detecting the orientation of general images, for instance, of holiday snapshots. Detecting image orientation is an easy task for a human being but can be a long and tedious activity during processing and management of digital photos. Several attempts have been made in the design of systems for automated displaying images in their correct orientation, however, this is still an open problem. In this work we exploit the power of deep learning proposing a transfer learning approach that adjusts pre-trained convolutional neural networks to this classification task. We create ensembles of different Convolutional Neural Network models designed by randomly changing the activation functions in all the activation layers of a given network. Along with several known activation functions we also include the novel Soft Learnable activation function in the “random set”. Our resulting ensembles have been extensively evaluated on more than 45,000 images taken from four different public datasets, showing a remarkable performance improvement with respect to other state-of-the-art approaches. All the source code used for this work is freely available at https://github.com/LorisNanni/.","Image orientation detection, Convolutional neural networks, Photo orientation, Deep learning, Transfer learning"
"Kamath C,Franzman J,Ponmalai R","Data mining for faster, interpretable solutions to inverse problems: A case study using additive manufacturing",2021,"Solving inverse problems, where we find the input values that result in desired values of outputs, can be challenging. The solution process is often computationally expensive and it can be difficult to interpret the solution in high-dimensional input spaces. In this paper, we use a problem from additive manufacturing to address these two issues with the intent of making it easier to solve inverse problems and exploit their results. First, focusing on Gaussian process surrogates that are used to solve inverse problems, we describe how a simple modification to the idea of tapering can substantially speed up the surrogate without losing accuracy in prediction. Unlike block tapering, which approximates the covariance matrix by diagonal blocks, our approach divides the data itself into blocks. Both approaches reduce the computational cost by replacing the Cholesky decomposition of the full matrix by the decomposition of multiple smaller matrices, but our approach gives accurate predictions despite the approximation as we identify hyperparameters optimal for each block. Second, we demonstrate that Kohonen self-organizing maps can be used to visualize and interpret the solution to the inverse problem in the high-dimensional input space. For our data set, as not all input dimensions are equally important, we show that using weighted distances results in a better organized map that not only makes the relationships among the inputs obvious, but also indicates the location of the solution in the input space so an additive manufacturing engineer can control the inputs appropriately for a desired output.","Inverse problem, Code surrogate, Gaussian process, Kohonen maps"
"Bachute MR,Subhedar JM",Autonomous Driving Architectures: Insights of Machine Learning and Deep Learning Algorithms,2021,"Research in Autonomous Driving is taking momentum due to the inherent advantages of autonomous driving systems. The main advantage being the disassociation of the driver from the vehicle reducing the human intervention. However, the Autonomous Driving System involves many subsystems which need to be integrated as a whole system. Some of the tasks include Motion Planning, Vehicle Localization, Pedestrian Detection, Traffic Sign Detection, Road-marking Detection, Automated Parking, Vehicle Cybersecurity, and System Fault Diagnosis. This paper aims to the overview of various Machine Learning and Deep Learning Algorithms used in Autonomous Driving Architectures for different tasks like Motion Planning, Vehicle Localization, Pedestrian Detection, Traffic Sign Detection, Road-marking Detection, Automated Parking, Vehicle Cybersecurity and Fault Diagnosis. This paper surveys the technical aspects of Machine Learning and Deep Learning Algorithms used for Autonomous Driving Systems. Comparison of these algorithms is done based on the metrics like mean Intersect in over Union (mIoU), Average Precision (AP)missed detection rate, miss rate False Positives Per Image (FPPI), and average number for false frame detection. This study contributes to picture a review of the Machine Learning and Deep Learning Algorithms used for Autonomous Driving Systems and is organized based on the different tasks of the system.","Autonomous Driving, Localization, Motion planning, Pedestrian detection, Perception, Taxonomy"
"Giri K,Biswas TK,Sarkar P",ECR-DBSCAN: An improved DBSCAN based on computational geometry,2021,"A new density based clustering algorithm ECR−DBSCAN based on DBSCAN, has been presented in this paper. Computational geometry is applied to develop the modified DBSCAN algorithm. It is well known that the quality of density based clustering depends on its input parameters. However, it is not easy to determine proper values of input parameters for DBSCAN. This paper presents three significant modifications or extensions to DBSCAN related with (i) selection of hyper parameter epsilon (eps) using the radii of empty or voronoi circles (ii) selection of parameter minPoints (mp) for the same epsilon and (iii) redistribution of noise points to suitable clusters using the concept of centroid hinged clustering. ECR−DBSCAN is implemented with PYTHON accompanied by extensive experiment on benchmark data sets. Our experimental results establish the novelty and validity of the proposed clustering method over standard techniques.","Computational geometry, Empty circles, DBSCAN, KNN, Noise, Performance metrics"
"Kundu S,Maulik U",Cloud deployment of game theoretic categorical clustering using apache spark: An application to car recommendation,2021,"Personal vehicles are invariably being preferred over public transport nowadays. Contact-less feature inspection and analysis based on personal preferences will be in high demand among customers in the post-pandemic world. A comprehensive online car recommendation system will be the customers’ spontaneous choice to understand and select the features of vehicles. However, the clustering of such categorical features is a challenging task as it is difficult to compare two textual attributes. In this paper, we have designed a cloud-based system that will automatically address this issue. Motivated by the cooperative game theory and fuzzy technique, and integrating the concept of Shapley theorem, a categorical data clustering algorithm has been developed. At the same time, to overcome the major limitation of having a high time complexity of the order O (n2) associated with the Shapley computation, the proposed algorithm has been distributed using Apache Spark’s Map Reduce architecture in Google Cloud Platform. The model has been thoroughly validated based on its performance on several synthetic as well as real data sets. Finally, a car recommendation system has been proposed and tested on three car sell data sets. The proposed approach outperforms the corresponding existing categorical clustering approaches in terms of various clustering validity indices. To the best of the authors’ knowledge, this is the first attempt to apply Map Reduce based Shapley computation over the categorical clustering, which can find its application beyond the proposed car recommendation system as well.","Car recommendation, Categorical clustering, Cooperative game theory, Shapley value, Apache spark’s"
"Vryzas N,Vrysis L,Kotsakis R,Dimoulas C",A web crowdsourcing framework for transfer learning and personalized Speech Emotion Recognition,2021,"Speech Emotion Recognition (SER) is an important part of Affective Computing and emotionally aware Human–Computer Interaction. Emotional expression may vary depending on the language, culture, and the speaker’s personality and vocal attributes. Speaker-adaptive systems can address this issue. In real-world applications, it is not feasible to obtain big datasets for deep learning model training from a specific speaker. This paper proposes a transfer learning approach for personalized SER based on convolutional neural networks. A CNN is trained in a multi-user dataset for generalization and then is fine-tuned for a small speaker-specific dataset. A VGGish model, pre-trained a large-scale dataset for audio event recognition is also evaluated for the task. This comparison highlights the significance of network capacity, dataset length, and domain-relativity for transfer learning. To enhance the applicability of this approach in real-world conditions, a web crowdsourcing application is implemented. An online platform is provided where contributors can follow a standard procedure to record and submit annotated utterances of emotional speech. The recordings are validated and added to the publicly available AESDD dataset of emotional speech. The platform can be used for the creation of personalized emotional speech datasets for speaker-adaptive SER, following the transfer learning strategies that have been evaluated.","Speech Emotion Recognition, Transfer learning, Crowdsourcing, Convolutional neural networks, VGGish"
"Elgazzar H,Spurlock K,Bogart T",Evolutionary clustering and community detection algorithms for social media health surveillance,2021,"The prominent rise of social networks within the past decade have become a gold mine for data mining operations seeking to model the real world through these virtual worlds. One of the most important applications that has been proposed is utilizing information generated from social networks as a supplemental health surveillance system to monitor disease epidemics. At the time this research was conducted in 2020, the COVID-19 virus had evolved into a global pandemic, forcing many countries to implement preventative measures to halt its expanse. Health surveillance has been a powerful tool in placing further preventative measures, however it is not a perfect system, and slowly collected, misidentified information can prove detrimental to these efforts. This research proposes a new potential surveillance avenue through unsupervised machine learning using dynamic, evolutionary variants of clustering algorithms DBSCAN and the Louvain method to allow for community detection in temporal networks. This technique is paired with geographical data collected directly from the social media Twitter, to create an effective and accurate health surveillance system that grows as time passes. The experimental results show that the proposed system is promising and has the potential to be an advancement on current machine learning health surveillance techniques.","Unsupervised machine learning, Evolutionary clustering, Community detection, Social networks, COVID-19, Health surveillance"
"Zhang Y,Xu X",Machine learning tensile strength and impact toughness of wheat straw reinforced composites,2021,"The wheat straw reinforced composite is considered as a “green composite” as it utilizes biodegradable and recyclable food waste materials as reinforcing materials. Mechanical properties, such as tensile strength and impact toughness, are greatly dependent on the composite content and processing parameters. While compression molding is one of popular methods to fabricate the wheat straw/polypropylene composite, experimental trials to achieve targeted mechanical properties can be time-consuming and expensive. In this work, we develop the Gaussian process regression model to present the relationship among the fiber content, processing parameters of the compression molding, and mechanical performance of wheat straw reinforced polypropylene composites. The model achieves a correlation coefficient of 99.13% (95.68%), a root mean square error of 0.0857 (0.4369), and a mean absolute error of 0.0693 (0.3265) for tensile strength (impact toughness). The models are simple and fast to implement, produce predictions with high accuracy, and thus might be considered as efficient tools for mechanical property estimations. Should data become available, the model may be extended to include other descriptors, such as the wheat straw length, size distribution, and chemical treatment parameters.","Natural fibers, Composites, Tensile strength, Impact toughness, Machine learning"
"Xu X,Zhang Y",Network analysis of corn cash price comovements,2021,"Commodity price comovements are an important issue in economics given their significant implications for food and resource sectors that directly influence social well-being. This study approaches this issue by focusing on daily cash prices of 182 corn markets from the seven largest harvest states in the United States for 2006–2011 by using correlation based hierarchical analysis and synchronization analysis, through which we can determine interactions and interdependence among these prices, heterogeneities in price synchronization, and their changing patterns over time. As the first study of the issue concentrating on prices of hundreds of spatially dispersed markets for a commodity of indubitable economic significance, empirical findings show that the degree of comovements is generally higher after November 2006 but no persistent increase is observed. Different groups of markets are identified, each of which has its members exhibit similar price dynamics. Certain markets show potential of serving as price leaders. Results here benefit food and resource policy analysis and design for economic welfare. The empirical framework has potential of being adapted to network analysis of prices of different commodities.","Corn, Cash price, Comovement, Network, Hierarchy"
"Tahaei N,Yang JJ,Chorzepa MG,Kim SS,Durham SA",Machine learning of Truck Traffic Classification groups from Weigh-in-Motion data,2021,"The pavement Mechanistic-Empirical (ME) design requires high-dimensional traffic feature inputs by categories, including Vehicle Class Distributions (VCD), Monthly Distribution Factors (MDF), Hourly Distribution Factors (HDF), and Normalized Axles Load Spectra (NALS). In simplifying the Pavement ME design practice, Truck Traffic Classification (TTC) groups are commonly used for characterizing traffic inputs. Thus, properly defining TTC groups is critical for state-specific pavement ME design practice. In this study, the truck traffic data from existing Weight-in-Motion (WIM) stations were mined to develop specific TTC groups to assist with pavement ME design practice in Georgia. An effective data analytics procedure was developed by leveraging unsupervised machine learning techniques to reduce the high-dimensional traffic features by stratified Principal Component Analysis (PCA), followed by K-means clustering to establish appropriate TTC groups. For a case study, the performance of two typical designs was evaluated using the AASHTOWare pavement mechanistic-empirical (ME) design software with respect to two scenarios of traffic inputs: (1) the derived cluster-based groups, and (2) the national default TTC groups. The results indicated that direct application of the national default TTC groups resulted in over-design of pavement structure in Georgia. Therefore, it is highly recommended that customized TTC groups should be developed using state-specific WIM data.","Weight-in-Motion (WIM), Truck traffic classification group, Pavement Mechanistic-Empirical (ME) design, Unsupervised learning, Principal Component Analysis (PCA), Clustering analysis"
"Srivastava A,Wang R,Dinda SK,Chattopadhyay K",Ensemble prediction of mean bubble size in a continuous casting mold using data driven modeling techniques,2021,"Gas injection into a slab continuous casting mold is a common practice as it enables long casting sequences by reducing SEN clogging. However, too much gas injection can generate lots of bubbles, and bubbles formed inside the mold are also responsible for the occurrence of various quality defects such as deterioration of steel cleanliness, reoxidation of liquid steel, and occurrence of sliver and blister defects, etc. Mean bubble size is a key parameter and controlling it can resolve/reduce these quality issues. Operating parameters such as gas flow rate and liquid flow rate are the major factors affecting the mean bubble size. Two-phase water modeling​ experiments were performed to generate bubbles in the mold, and the mean bubble diameter was captured using various gas and liquid flow rates. Clear images of bubbles were recorded using a high-speed high-resolution camera along with the application of shadowgraphy. Bubble images were processed using an image processing software, ImageJ to obtain bubble characteristics, and Sauter mean diameter was calculated for each operating condition. Advance machine learning techniques such as Multilinear Regression (MLR), Decision Tree (DT), Support Vector Machine (SVM), and Artificial Neural Network (ANN) were used on the experimental data to predict the combined effect of these operating parameters on the mean bubble diameter. All four ML techniques were compared considering the values of cross-validated adjusted R2, and a performance metric is presented to compare the suitability of ML techniques in this case.","Continuous casting, Physical modeling, Mold, Bubble size distribution, ImageJ, Machine learning algorithms, Bootstrapping"
"Sejr JH,Schneider-Kamp A","Explainable outlier detection: What, for Whom and Why?",2021,"Outlier algorithms are becoming increasingly complex. Thereby, they become much less interpretable to the data scientists applying the algorithms in real-life settings and to end-users using their predictions. We argue that outliers are context-dependent and, therefore, can only be detected via domain knowledge, algorithm insight, and interaction with end-users. As outlier detection is equivalent to unsupervised semantic binary classification, at the core of interpreting an outlier algorithm we find the semantics of the classes, i.e., the algorithm’s conceptual outlier definition. We investigate current interpretable and explainable outlier algorithms: what they are, for whom they are, and what their value proposition is. We then discuss how interpretation and explanation and user involvement have the potential to provide the missing link to bring modern complex outlier algorithms from computer science labs into real-life applications and the challenges they induce.","Unsupervised outlier detection, Explainable artificial intelligence"
"Tendle A,Hasan MR",A study of the generalizability of self-supervised representations,2021,"Recent advancements in self-supervised learning (SSL) made it possible to learn generalizable visual representations from unlabeled data. The performance of Deep Learning models fine-tuned on pretrained SSL representations is on par with models fine-tuned on the state-of-the-art supervised learning (SL) representations. Irrespective of the progress made in SSL, its generalizability has not been studied extensively. In this article, we perform a deeper analysis of the generalizability of pretrained SSL and SL representations by conducting a domain-based study for transfer learning classification tasks. The representations are learned from the ImageNet source data, which are then fine-tuned using two types of target datasets: similar to the source dataset, and significantly different from the source dataset. We study generalizability of the SSL and SL-based models via their prediction accuracy as well as prediction confidence. In addition to this, we analyze the attribution of the final convolutional layer of these models to understand how they reason about the semantic identity of the data. We show that the SSL representations are more generalizable as compared to the SL representations. We explain the generalizability of the SSL representations by investigating its invariance property, which is shown to be better than that observed in the SL representations.","Self-supervised learning, Supervised learning, Transfer learning, Generalizability, Invariance"
"Onah JO,Abdulhamid SM,Abdullahi M,Hassan IH,Al-Ghusham A",Genetic Algorithm based feature selection and Naïve Bayes for anomaly detection in fog computing environment,2021,"The sharp rise in network attacks has been a major source of concern in cyber security, particularly that now internet usage and connectivity are in high demand. As a complement to cloud computing, fog computing can offer low-latency services among users of mobile and the cloud. Because of the closeness of the end users to the fog nodes and having inadequate computing resources, fog devices may get into security issues. Conventional network threats may demolish the fog computing system. The use of Intrusion Detection Systems (IDS) in conventional networks has been extensively researched, applying them directly in to the fog computing platform might become unsuitable. Nodes of the fog generate enormous quantities of data most of the time, so implementing an Intrusion detection system model over large datasets in the fog computing setting is critical. To combat some of these network attacks, an intrusion detection system (IDS), a strategic intrusion prevention innovation that can be applied in the fog computing platform utilizing machine learning techniques for network anomaly detection and network event classification threat, has proven efficient and effective. This paper presented a Genetic Algorithm Wrapper-Based feature selection and Nave Bayes for Anomaly Detection Model (GANBADM) in a Fog Environment which removes extraneous attributes to reduce time complexity while also developing an enhanced model that can predict results with greater accuracy using the Security Laboratory Knowledge Discovery Dataset (NSL-KDD). Based on the analysis, the developed system has a higher overall performance of 99.73% accuracy, with a false positive rate as low as 0.6%. This results show that the proposed GANBADM approach performs better than similar approaches in the literature.","Fog computing, Intrusion detection system, Network anomaly detection, Cyber security, Genetic algorithm, Naïve Bayes"
"Adamu A,Abdullahi M,Junaidu SB,Hassan IH",An hybrid particle swarm optimization with crow search algorithm for feature selection,2021,"The recent advancements in science, engineering, and technology have facilitated huge generation of datasets. These huge datasets contain noisy, redundant, and irrelevant features which negatively affects the performance of classification techniques in machine learning and data mining process. Feature selection is a pre-processing stage for reducing the dimensionality of datasets by selecting the most important attributes while increasing the accuracy of classification at the same time. In this paper, we present a novel hybrid binary version of enhanced chaotic crow search and particle swarm optimization algorithm (ECCSPSOA) to solve feature selection problems. In the proposed ECCSPSOA, in order to navigate the feature space, we hybridized the enhanced version of the CSA algorithm which has a better search strategy and particle swarm optimization (PSO) which is capable of converging into the best global solution in the search field. We further embed opposition-based learning technique in the local search of the hybrid algorithm. The ECCSPSOA was compared using 15 datasets from the UCI repository with four well-known optimization algorithms, such as particle swarm optimization (PSO), binary particle swarm optimization (BPSO), crow search algorithm (CSA), and chaotic crow search algorithm (CCSA). In the experiments with k-Nearest Neighbour (KNN) as a classifier, six different performance metrics were used. To tackle the over-fitting problem, each dataset is divided into training and testing data using K-fold cross-validation. The computational findings demonstrate that the proposed algorithm obtains an average accuracy rate of 89.67 % over 15 datasets, indicating that our technique exceeds state-of-the-art findings in 12 of the 15 datasets studied. Furthermore, the suggested approach outperforms state-of-the-art methods in terms of fitness value and standard deviation, obtaining the lowest value in 13 and 8 of the datasets studied respectively.","Crow search algorithm, Particle swarm optimization, Opposition based learning, Feature selection, Wrapper method"
Pendharkar PC,"Hybrid radial basis function DEA and its applications to regression, segmentation and cluster analysis problems",2021,"This paper uses a radial basis function (RBF) transformation of data envelopment analysis (DEA) data to perform RBF-DEA. It is shown that the RBF-DEA frontier identifies cases that have average efficiency scores in traditional DEA. The formal identification of average efficiency cases allows decision-makers to use these cases and related information for regression, segmentation and cluster analysis. Additionally, negative inputs and outputs can be used in RBF-DEA and unique ranking of fully efficient cases in traditional DEA can be achieved by further evaluating these fully efficient cases against the average RBF-DEA regression frontier. When compared to traditional cluster analysis, RBF-DEA cluster analysis offers unique advantages in that number of clusters do not need to be mentioned and cluster labels are identified by the RBF-DEA technique. Furthermore, unlike the traditional techniques, RBF-DEA cluster memberships are not sensitive to any initial random starting points.","Radial basis functions, Data envelopment analysis, Cluster analysis, Regression analysis"
"Peng Y,Albuquerque PH,Kimura H,Saavedra CA",Feature selection and deep neural networks for stock price direction forecasting using technical analysis indicators,2021,"This paper analyzes the factor zoo, which has theoretical and empirical implications for finance, from a machine learning perspective. More specifically, we discuss feature selection in the context of deep neural network models to predict the stock price direction. We investigated a set of 124 technical analysis indicators used as explanatory variables in the recent literature and specialized trading websites. We applied three feature selection methods to shrink the feature set aiming to eliminate redundant information from similar indicators. Using daily data from stocks of seven global market indexes between 2008 and 2019, we tested neural networks with different settings of hidden layers and dropout rates. We compared various classification metrics, taking into account profitability and transaction costs levels to analyze economic gains. The results show that the variables were not uniformly chosen by the feature selection algorithms and that the out-of-sample accuracy rate of the prediction converged to two values — besides the 50% accuracy value that would suggest market efficiency, a “strange attractor” of 65% accuracy also was achieved consistently. We also found that the profitability of the strategies did not manage to significantly outperform the Buy-and-Hold strategy, even showing fairly large negative values for some hyperparameter combinations.","Deep learning, Technical analysis indicators, Time-series forecasting, Market efficiency, Trading profitability"
"Amram M,Dunn J,Toledano JJ,Zhuo YD",Interpretable predictive maintenance for hard drives,2021,"Existing machine learning approaches for data-driven predictive maintenance are usually black boxes that claim high predictive power yet cannot be understood by humans. This limits the ability of humans to use these models to derive insights and understanding of the underlying failure mechanisms, and also limits the degree of confidence that can be placed in such a system to perform well on future data. We consider the task of predicting hard drive failure in a data center using recent algorithms for interpretable machine learning. We demonstrate that these methods provide meaningful insights about short- and long-term drive health, while also maintaining high predictive performance. We also show that these analyses still deliver useful insights even when limited historical data is available, enabling their use in situations where data collection has only recently begun.","Predictive maintenance, Decision trees, Interpretable machine learning"
"Morris C,Yang JJ",A machine learning model pipeline for detecting wet pavement condition from live scenes of traffic cameras,2021,"Highway safety is largely influenced by weather conditions that have become increasingly volatile due to the climate change. It well known that wet pavement significantly reduces surface friction, leading to inflated collision risk. Thus, timely knowledge of the road surface condition is critical for safe driving. In this paper, a novel machine learning model pipeline is proposed to detect the wetness of pavement based on live images of highway scenes captured by publicly accessible traffic cameras. To simplify the learning task, we finetuned the state-of-the-art instance segmentation baseline models to extract background instance targets, including pavement, sky, and vegetation, which are common in highway scenes. Then, the color mixture attributes in HSV (hue, saturation and value) of each segmented instance were extracted and used as visual cues for inferring pavement condition. Finally, gradient boosting ensemble classifiers are constructed and trained using the HSV features to predict the wetness of pavement. For the segmentation task, we leveraged Detectron2 baseline models (Mask R-CNN) and evaluated three backbone networks: R50-FPN, R101-FPN, and X101-FPN. For the classification task, two most popular gradient boosting algorithms (XGBoost and CatBoost) were evaluated together with a classic logistic model. Based on experiments with our custom dataset, the best performance (F1 score: 0.927, AUC: 0.975) was achieved by the R101-FPN backbone coupled with the CatBoost classifier.","Machine learning, Image segmentation, Convolutional neural networks, Gradient boosting, CatBoost, XGBoost, Wet pavement, Traffic cameras, Highway safety"
"Ma Y,Wang H,Zhang X,Hou L,Song J",Three-objective optimization of boiler combustion process based on multi-objective teaching–learning based optimization algorithm and ameliorated extreme learning machine,2021,"The combustion optimization problem of Circulation Fluidized Bed Boiler (CFBB) can be regarded as a constrained dynamic multi-objective optimization problem, so it has become a hot research to solve the problem for saving energy and reducing polluting gas. However, it is difficult to optimize the combustion process based on traditional optimization method due to a variety of complex characteristics of boiler, such as non-linearity, strong coupling , large lag. In order to address the boiler combustion optimization problem, a kind of multi-objective modified teaching–learning-based optimization (namely MMTLBO) is proposed. For the MMTLBO, a constrained mechanism is firstly introduced into MMTLBO. Finally, the MMTLBO and ameliorated extreme learning machine (AELM) are utilized to optimize the CFBB’s combustion process for increasing the thermal efficiency and reducing the NOx/SO2 emissions concentration. The AELM is used to establish the comprehensive model of the thermal efficiency and NOx/SO2 emissions. The model accuracy and standard deviation can arrive 10−2 and 10−4, separately. So the model shows high generalization ability and good stability. Based on the model, the MMTLBO is applied to optimize the boiler’s combustion process parameters. Experiment results show that the MMTLBO can find several groups reasonable combustion parameters which increase the thermal efficiency and reduce the NOx/SO2 emissions concentration. Therefore, the AELM and MMTLBO are the effective artificial intelligence algorithms.","Multi-objective optimization, Model, Teaching–learning-based​ optimization, Extreme learning machine, Boiler combustion optimization"
"Severino MK,Peng Y",Machine learning algorithms for fraud prediction in property insurance: Empirical evidence using real-world microdata,2021,"This paper evaluated fraud prediction in property insurance claims using various machine learning models based on real-world data from a major Brazilian insurance company. The models were tested recursively and average predictive results were compared controlling for false positives and false negatives. The results showed that ensemble-based methods (random forest and gradient boosting) and deep neural networks yielded the best results, exhibiting superior average performance in comparison to the other classifiers, including the commonly used logistic regression. In addition, we compiled a general profile of confirmed fraudsters from the dataset and estimated the impact of each feature in the global classification performance and for prominent cases of false positive and false negative predictions using eXplainable Artificial Intelligence methods. The findings of this study can aid risk analysts and professionals in assessing the strengths and weaknesses of each model and to build empirically effective decision rules to evaluate future insurance policies.","Fraud detection, Insurance market, Risk management, Decision support systems, Supervised learning, Feature importance"
Dufera TT,Deep neural network for system of ordinary differential equations: Vectorized algorithm and simulation,2021,"This paper is aimed at applying deep artificial neural networks for solving system of ordinary differential equations. We developed a vectorized algorithm and implemented using python code. We conducted different experiments for selecting better neural architecture. For the learning of the neural network, we utilized the adaptive moment minimization method. Finally, we compare the method with one of the traditional numerical methods-Runge–Kutta order four. We have shown that, the artificial neural network could provide better accuracy for smaller numbers of grid points.","Deep Neural Network, Algorithm, Systems of ordinary differential equation"
"Kamangir H,Collins W,Tissot P,King SA,Dinh HT,Durham N,Rizzo J",FogNet: A multiscale 3D CNN with double-branch dense block and attention mechanism for fog prediction,2021,"The reduction of visibility adversely affects land, marine, and air transportation. Thus, the ability to skillfully predict fog would provide utility. We predict fog visibility categories below 1600 m, 3200 m and 6400 m by post-processing numerical weather prediction model output and satellite-based sea surface temperature (SST) using a 3D-Convolutional Neural Network (3D-CNN). The target is an airport located on a barrier island adjacent to a major US port; measured visibility from this airport serves as a proxy for fog that develops over the port. The features chosen to calibrate and test the model originate from the North American Mesoscale Forecast System, with values of each feature organized on a 32 × 32 horizontal grid; the SSTs were obtained from the NASA Multiscale Ultra Resolution dataset. The input to the model is organized as a high dimensional cube containing 288 to 384 layers of 2D horizontal fields of meteorological variables (predictor maps). In this 3D-CNN (hereafter, FogNet), two parallel branches of feature extraction have been designed, one for spatially auto-correlated features (spatial-wise dense block and attention module), and the other for correlation between input variables (variable-wise dense block and attention mechanism.) To extract features representing processes occurring at different scales, a 3D multiscale dilated convolution is used. Data from 2009 to 2017 (2018 to 2020) are used to calibrate (test) the model. FogNet performance results for 6, 12− and 24−h lead times are compared to results from the High-Resolution Ensemble Forecast (HREF) system. FogNet outperformed HREF using 8 standard evaluation metrics.","Fog prediction, Deep learning, 3D Convolutional Neural Network, Dense block, Attention mechanism, Dilated convolutions"
"Nsugbe E,Obajemu O,Samuel OW,Sanusi I",Application of noninvasive magnetomyography in labour imminency prediction for term and preterm pregnancies and ethnicity specific labour prediction,2021,"This paper investigates the application of magnetomyography (MMG) signals from uterine contractions in pregnant patients towards the prediction of labour imminency within or above 48 h. The study utilised the MMG signals collected from a host of pregnant patients retrieved from a Physionet database, which also contained information regarding patients’ ethnicity and pregnancy. Utilising​ the information available in addition to the dataset, the study investigated the prospect of designing an ethnic specific labour imminency classifier to allow for an enhanced prediction, with an emphasis on Black and Caucasian ethnicities due to the nature of the data. Using an extended feature vector and a support vector machine (SVM) classifier, it was seen that the labour imminency was enhanced across the various classifier metrics considered in the ethnic specific classifier when compared with the generalised classifier. The results from the classification exercise, which considered the fusion of MMG signal information with the information on patients’ records, showed greater variability and a slightly lower classifier performance, thus suggesting that the MMG signals present a more reliable way of classifier training. Subsequent work in this area would now involve the application of optimisation algorithms to select an optimal number of electrodes that can be used for data acquisition, and thereby contributing towards the lowering of the cost associated with the implementation of the method using the MMG instrumentation.","Cybernetics, Electromagnetism, Decision support, SVM, Artificial intelligence, Signal processing, Obstetrics, Labour prediction"
"Jardines A,Soler M,Cervantes A,García-Heras J,Simarro J",Convection indicator for pre-tactical air traffic flow management using neural networks,2021,"Convective weather is a large source of disruption for air traffic management operations. Being able to predict thunderstorms the day before operations can help traffic managers plan around weather and improve air traffic flow management operations. In this paper, machine learning is applied on data from satellite storm observations and ensemble numerical weather prediction products to detect convective weather 36 h in advance. The learning task is formulated as a binary classification problem and a neural network is trained to predict the occurrence of storms. The neural network results are used to develop a probabilistic based convection indicator capable of outperforming existing convection indicators found in the literature. Lastly, applications of the neural network based indicator in an air traffic management setting are presented.","Thunderstorms, Air traffic management, Numerical weather prediction, Satellite images, Machine learning"
"Corea F,Bertinetti G,Cervellati EM",Hacking the venture industry: An Early-stage Startups Investment framework for data-driven investors,2021,"Investing in early-stage companies is incredibly hard, especially when no data are available to support the decision process. Venture capitalists often rely on gut feeling or heuristics to reach a decision, which is biased and potentially harmful. This work proposes a new data-driven framework to help investors be more effective in selecting companies with a higher probability of success. We built upon existing interdisciplinary research and augmented it with further analysis on more than 600,000 companies over a 20-year timeframe. The resulting framework is therefore a smart checklist of 21 relevant features that may help investors to select the companies more likely to succeed.","Venture capital, Machine learning, Business angels, Artificial intelligence, Gradient Tree Boosting"
"Ali MS,Miah MS,Haque J,Rahman MM,Islam MK",An enhanced technique of skin cancer classification using deep convolutional neural network with transfer learning models,2021,"Skin cancer is one of the top three perilous types of cancer caused by damaged DNA that can cause death. This damaged DNA begins cells to grow uncontrollably and nowadays it is getting increased speedily. There exist some researches for the computerized analysis of malignancy in skin lesion images. However, analysis of these images is very challenging having some troublesome factors like light reflections from the skin surface, variations in color illumination, different shapes, and sizes of the lesions. As a result, evidential automatic recognition of skin cancer is valuable to build up the accuracy and proficiency of pathologists in the early stages. In this paper, we propose a deep convolutional neural network (DCNN) model based on deep learning approach for the accurate classification between benign and malignant skin lesions. In preprocessing we firstly, apply filter or kernel to remove noise and artifacts; secondly, normalize the input images and extract features that help for accurate classification; and finally, data augmentation increases the number of images that improves the accuracy of classification rate. To evaluate the performance of our proposed, DCNN model is compared with some transfer learning models such as AlexNet, ResNet, VGG-16, DenseNet, MobileNet, etc. The model is evaluated on the HAM10000 dataset and ultimately we obtained the highest 93.16% of training and 91.93% of testing accuracy respectively. The final outcomes of our proposed DCNN model define it as more reliable and robust when compared with existing transfer learning models.","Skin cancer, Pre-processing, Convolutional neural network, Classification, Transfer learning"
"Batarseh FA,Gopinath M,Monken A,Gu Z",Public policymaking for international agricultural trade using association rules and ensemble machine learning,2021,"International economics has a long history of improving our understanding of factors causing trade, and the consequences of free flow of goods and services across countries. The recent shocks to the free-trade regime, especially trade disputes among major economies, as well as black swan events (such as trade wars and pandemics), raise the need for improved predictions to inform policy decisions. Artificial Intelligence (AI) methods are allowing economists to solve such prediction problems in new ways. In this manuscript, we present novel methods that predict and associate food and agricultural commodities traded internationally. Association Rules (AR) analysis has been deployed successfully for economic scenarios at the consumer or store level (such as for market basket analysis). In our work however; we present analysis of imports/exports associations and their effects on country–commodity trade flows. Moreover, Ensemble Machine Learning (EML) methods are developed to provide improved agricultural trade predictions, outlier events’ implications, and quantitative pointers to policy makers.","International trade, Association rules, Ensemble machine learning, Country–commodity transactions, Black swan events, Gravity models"
"Ott J,Bruyette D,Arbuckle C,Balsz D,Hecht S,Shubitz L,Baldi P",Detecting pulmonary Coccidioidomycosis with deep convolutional neural networks,2021,"Coccidioidomycosis is the most common systemic mycosis in dogs in the southwestern United States. With warming climates, affected areas and number of cases are expected to increase in the coming years, escalating also the chances of transmission to humans. As a result, developing methods for automating the detection of the disease is important, as this will help doctors and veterinarians more easily identify and diagnose positive cases. We apply machine learning models to provide accurate and interpretable predictions of Coccidioidomycosis. We assemble a set of radiographic images and use it to train and test state-of-the-art convolutional neural networks to detect Coccidioidomycosis. These methods are relatively inexpensive to train and very fast at inference time. We demonstrate the successful application of this approach to detect the disease with an Area Under the Curve (AUC) above 0.99 using 10-fold cross-validation. We also use the classification model to identify regions of interest and localize the disease in the radiographic images, as illustrated through visual heatmaps. This proof-of-concept study establishes the feasibility of very accurate and rapid automated detection of Valley Fever in radiographic images.",
"Nguyen B,Coelho Y,Bastos T,Krishnan S",Trends in human activity recognition with focus on machine learning and power requirements,2021,"The advancement and availability of technology can be employed to improve our daily lives. One example is Human Activity Recognition (HAR). HAR research has been mainly explored using imagery but is currently evolving to the use of sensors and has the ability to have a positive impact, including individual health monitoring and removing the barrier of healthcare. To reach a marketable HAR device, state-of-the-art classifications and power consumption methods such as convolutional neural network (CNN), data compression and other emerging techniques are reviewed here. The review of the current literature creates a foundation in HAR and addresses the lack of available HAR datasets, recommendation of classification and power reduction techniques, current drawbacks and their respective solutions, as well as future trends in HAR. The lack of publicly available datasets makes it difficult for new users to explore the field of HAR. This paper dedicates a section to publicly available datasets for users to access. Finally, a framework is suggested for HAR applications, which envelopes the current literature and emerging trends in HAR.","HAR, Machine learning, Power consumption, Wearable devices, Telemedicine"
"Hamid TM,Sallehuddin R,Yunos ZM,Ali A",Ensemble Based Filter Feature Selection with Harmonize Particle Swarm Optimization and Support Vector Machine for Optimal Cancer Classification,2021,"Explosive increase of dataset features may intensify the complexity of medical data analysis in deciding necessary treatment for the patient. In most cases, the accuracy of diagnosis system is vitally impacted by the data dimensionality and classifier parameters. Since these two processes are dependent, conducting them independently could deteriorate the accuracy performance. Filter algorithm is used to eliminate irrelevant features based on ranking. However, independent filter still incapable to consider features dependency and resulting in imbalance selection of significant features which consequently degrade the classification performance. In order to mitigate this problem, ensemble of multi filters algorithm such as Information Gain (IG), Gain Ratio (GR), Chi-squared (CS) and Relief-F (RF) are utilized as it can considers the intercorrelation between features. The proper kernel parameters settings may also influence the classification performance. Hence, a harmonize classification technique using Particle Swarm Optimization (PSO) and Support Vector Machine (SVM) is employed to optimize the searching of optimal significant features and kernel parameters synchronously without degrading the accuracy. Therefore, an ensemble filter feature selection with harmonize classification of PSO and SVM (Ensemble-PSO-SVM) are proposed in this research. The effectiveness of the proposed method is examined on standard Breast Cancer and Lymphography datasets. Experimental results showed that the proposed method successfully signify the classifier accuracy performance with optimal significant features compared to other existing methods such as PSO-SVM and classical SVM. Hence, the proposed method can be used as an alternative method for determining the optimal solution in handling high dimensional data.",
"Clémentin TD,Cabrel TF,Belise KE",A novel algorithm for extracting frequent gradual patterns,2021,"The extraction of frequent gradual pattern is an important problem in computer science and largely studied by the scientist’s community of research in data mining. A frequent gradual pattern translates a recurrent co-variation between the attributes of a database. Many applications issues from many domains, such as economy, health, education, market, bio-informatics, astronomy or web mining, are based on the extraction of frequent gradual patterns. Algorithms to extract frequent gradual patterns in the large databases are greedy in CPU time and memory space. This raises the problem of improving the performances of these algorithms. This paper presents a technique for improving the performance of frequent gradual pattern extraction algorithms. The exploitation of this technique leads to a new, more efficient algorithm called SGrite. The experiments carried out confirm the interest of the proposed technique.","Pattern mining, Pruning, Search space, Gradual support, Lattice, Adjacency matrix"
"Martarelli NJ,Nagano MS",How have high-impact scientific studies designing their experiments on mixed data clustering? A systematic map to guide better choices,2021,"Many scientific works on grouping mixed data have chosen different experimental scenarios to structure their findings, which involve deciding from the programming language to the use of real-world and/or simulated datasets and performance measures, for example. Due to these characteristics directly influence the conclusion of the studies and the way new scientific works are proposed, it would be useful to have a wide map with the main choices that have been done by the authors of high-impact scientific documents so that the community can reflect on the thematic direction, identify best practices, and propose new paths for future research. To the best of our knowledge, such a map does not exist, neither a methodological procedure to build it. Therefore, this paper proposes a systematic methodology to reach such maps and provides a wide and in-depth map of the main choices the authors of high-impact scientific documents on mixed data clustering and surrounding studies have done in their experiments. As a result, 160 documents were systematically selected and classified into one of the six class of data clustering approaches, besides individually tabulated. From the tables for each class, we found, for instance, that real-world datasets are used more frequently than simulated ones, the documents used more external indices, followed by internal and relative ones, it is not common for the authors to inform the programming language they have used, except in the partitional class. We also provided the address of the algorithms’ code when they are made available by the authors.","Mixed data clustering, Computational experiments, Systematic literature review, Numerical and categorical data, Mixed datasets, Performance measures"
"Zhang G,Bai X,Wang Y",Short-time multi-energy load forecasting method based on CNN-Seq2Seq model with attention mechanism,2021,"Integrated Energy Systems have become a vital energy utilization to alleviate the multiple stress of energy, environment, and economy worldwide. Integrated Energy Microgrid (IEM) is a small-scale integrated energy system located in a distribution network close to the demand side. The accurate forecasting of multi-load is an essential prerequisite for ensuring the reliable and economic operation of an IEM. Comprehensively considering temperature, humidity, wind speed, and the coupling relationship of multi-energy, this paper proposes a CNN-Seq2Seq model with an attention mechanism based on a multi-task learning method for a short-time multi-energy load forecasting. In detail, CNN is used to extract useful features of the input data. Then, the short-time multi-energy load is forecasted by using Seq2Seq according to the extracted features. Meanwhile, the attention mechanism and multi-task learning method are introduced to improve the accuracy of load forecasting. The simulation results with the actual data of an IEM validate the effectiveness of the proposed short-time multi-energy load forecasting method.","Integrated Energy Microgrid (IEM), Multi-energy load, Load forecasting, Multi-task learning, Attention mechanism"
"Hossain MS,Miah MS",Machine learning-based malicious user detection for reliable cooperative radio spectrum sensing in Cognitive Radio-Internet of Things,2021,"The Cognitive Radio based Internet of Things (CR-IoT) is a promising technology that provides IoT endpoints, i.e., CR-IoT users the capability to share the radio spectrum otherwise allocated to licensed Primary Users (PUs). Cooperative Spectrum Sensing (CSS) improves spectrum sensing accuracy in a CR-IoT network. However, its performance may be degraded by potential attacks of the malicious CR-IoT users that send their incorrect sensing information to the corresponding Fusion Center (FC). This study presents a promising Machine Learning (ML)-based malicious user detection scheme for a CR-IoT network that uses a Support Vector Machine (SVM) algorithm to identify and classify malicious CR-IoT users. The classification allows the FC to make a more robust global decision based on the sensing results (i.e., energy vectors) which are reported only by the normal CR-IoT users. The effectiveness of the proposed SVM algorithm based ML in a CR-IoT network with the malicious CR-IoT users is verified via simulations.","Cooperative spectrum sensing, Cognitive radio, Internet of Things, Machine learning, Support vector machine, Cognitive Radio-Internet of Things, Fusion center"
"Singh S,Sharma A,Chauhan VK",Online handwritten Gurmukhi word recognition using fine-tuned Deep Convolutional Neural Network on offline features,2021,"The recognition of online handwriting is a vital application of pattern recognition, which involves the extraction of spatial and temporal information of handwritten patterns, and understanding the handwritten text while writing on the digital surface. Although, online handwriting recognition is a mature but exciting and fast developing field of pattern recognition, the same is not true for many of the Indic scripts. Gurmukhi is one of such popular scripts of India, and online handwriting recognition issues for larger units as words or sentences largely remained unexplored for this script till date. The existing study and first ever attempt for online handwritten Gurmukhi word recognition has relied upon the widely used hidden Markov model. This existing study evaluated against and performed very well in their chosen metrics. But, the available online handwritten Gurmukhi word recognition system could not obtain more than 90% recognition accuracy in data dependent environment too. The present study provided benchmark results for online handwritten Gurmukhi word recognition using deep learning architecture convolutional neural network, and obtained above 97% recognition accuracy in data dependent mode of handwriting. The previous Gurmukhi word recognition system followed the stroke based class labeling approach, whereas the present study has followed the word based class labeling approach. Present Online handwritten Gurmukhi word recognition results are quite satisfactory. Moreover, the proposed architecture can be used to improve the benchmark results of online handwriting recognition of several major Indian scripts. Experimental results demonstrated that the deep learning system achieved great results in Gurmukhi script and outperforms existing results in the literature.","Online handwriting recognition, Word recognition, Gurmukhi, Deep learning, Convolutional neural network"
"Saha P,Sircar R,Bose A","Using hospital Admission, Discharge & Transfer (ADT) data for predicting readmissions",2021,"Readmission of patients within a specific period after their discharge from a hospital is a cause of concern for the healthcare industry due to the cost involved. Most of the work done for predicting such readmissions using machine learning (ML) have been based on EHR, claims or authorization data from specific sources, which are mostly snapshot data at one static point in time and hence delayed. ADT being dynamic as the data is available instantaneous on occurrence of a medical event/visit adds value. Our goal is to utilize machine learning on unlabeled ADT data to identify patients who are at a high risk of being readmitted. We approached the problem in three parts. First, we labeled patient events using logical rules and finalized one of many readmission definitions that was more encapsulating of varied scenarios. Second, feature engineering was done which encapsulates the longitudinal timeline of each patient in a representative way considering all the contextual information. Third, we developed an automated machine learning pipeline which takes modeling inputs from the user, runs various models to generate readmission prediction, does a cross validation and returns the best model. We tried multiple combinations of models and cross-validation strategies and decided on a random forest model with specific hyper-parameter values and to be the most effective method to classify high risk patients. It had a test AUC-ROC of 72% which is better than quite a few industry standards. The model currently implemented in the client environment identifies the high-risk patients in real-time to care nurses who in turn take proper interventions to reduce their chances of readmission.","Healthcare, Readmission, ADT, Machine learning, Auto ml"
"Xu X,Zhang Y",Individual time series and composite forecasting of the Chinese stock index,2021,"We explore the short-run forecasting problem at horizons of 1, 5, 10, 15, and 20 days for three forecasting periods within one year for the Chinese stock index from April 16, 2010, the launch date of the index futures, to May 19, 2014 with daily closing prices. We study forecast performance of 51 individual time series models that are different variations of autoregressive models, (Bayesian) vector autoregressive models, and (Bayesian) vector error correction models, and 41 composite models based on different trimming strategies of these individual models. The composite models, including the previous best forecast, equal-weighted average, inverse mean squared error, bias adjusted mean, shrinkage, and odds matrix approaches, utilize the idea of model boosting to diversify against possible mis-specifications, breaks, and structural changes in individual models, and aim at more robust performance. Across all forecasting horizons and forecasting periods investigated, we arrive at a shrinkage composite model with the shrinkage parameter of 0.25 that is optimal based on the mean squared error. This result is robust against the choice of futures series used in individual models and the pre-processing of structural breaks in data. We also discuss empirical findings at a more granular level, including comparisons of individual models and those of composite forecasts. Our results should fulfill different forecasting users’ information needs for decision making and policy analysis. The empirical framework also has potential of being adapted to similar time series forecasting problems in different fields.","Time series models, Composite models, Chinese stock index, Spot prices, Forecasting"
"Islam MK,Ali MS,Miah MS,Rahman MM,Alam MS,Hossain MA","Brain tumor detection in MR image using superpixels, principal component analysis and template based K-means clustering algorithm",2021,"In the present era, human brain tumor is the extremist dangerous and devil to the human being that leads to certain death. Furthermore, the brain tumor arises more complexity of patients life with time. As a result, early detection of tumors is most crucial to save and prolong the patient’s lifetime. Therefore, enhanced brain tumor detection is required in medical fields. Automatic human brain tumor detection in magnetic resonance imaging (MRI) is playing a vital role in several symptomatic and cures applications. However, the existing schemes (e.g., random forest, Fuzzy C-means, artificial neural network (ANN) and wavelet transform) can detect brain tumors with insufficient accuracy and longer execution time (in minutes). In this paper, we propose an enhanced brain tumor detection scheme based on the template-based K-means (TK) algorithm with superpixels and principal component analysis (PCA) which efficiently detects the human brain tumors in lower execution time. At first, we extract essential features using both superpixels and PCA which helps accurately to detect brain tumors. Then, image enhancement is done using a filter that helps to improve accuracy. Finally, the image segmentation is performed through TK-means clustering algorithm to detect the brain tumor. The experimental results show that the proposed detection scheme achieves a better accuracy and a reduced execution time (in seconds) than other existing schemes for the detection of brain tumor in MR image.","Magnetic resonance imaging, Segmentation, Feature extraction, Superpixels, Principal component analysis, Template based K-means algorithm"
"Sant'Ana DA,Pache MC,Martins J,Soares WP,de Melo SL,Garcia V,de Moares Weber VA,da Silva Heimbach N,Mateus RG,Pistori H",Weighing live sheep using computer vision techniques and regression machine learning,2021,"This research arose from the need to aggregate computer vision technology and machine learning in sheep weight control and facilitate the weighing process of animals in farms. The experiment was conducted to collect the images of the animals and their weights, and later, the annotations of the images were made, generating a mask image dataset. We selected the attribute extraction algorithms that extracted shape, size, and angles with k-curvature. With these extracted data, we used the stratified five-fold cross-validation. Also, we used eight machine learning techniques aimed at regression, and the result obtained when compared to the metric Adjusted R2 was the technique called Random Forest Regressor to obtain Adjusted R2 0.687 (±0.09) and MAE of 3.099 (±1.52) kilograms. By performing the ANOVA test to check if it is statistically relevant using the Adjusted R2 measure, we got a p-value of 0.00000807 (8.07e−06). The contribution of the work is sheep weight prediction in a non-invasive way using images. Therefore, the results achieved make it possible to measure the animal’s weight with an MAE of 3.099 kg.","Weight prediction, Mass estimation, Top-view body area, Body size measurements, Image processing"
"Akpan UI,Starkey A",Review of classification algorithms with changing inter-class distances,2021,"Machine learning algorithms are often faced with several data related problems. Real-world datasets come in various types and dimensions, each of which constitute some form of data related problems; moreover, they often contain irrelevant or noisy features. As a result of these, different data related problems require different techniques for the classification process. In this paper, some data related problems of interest are replicated in different synthetic datasets in order to investigate and evaluate the performance of a range of learning algorithms. Specifically, the data problems studied in this research are: datasets with varying inter class distances (classes are separated by different amounts); datasets with classes having different input relevance; datasets with classes defined by multiple features and by multiple underlying pattern; datasets with increasing number of noisy features; and datasets with varying amplitudes of noisy features. Also, datasets with combination of some of the problems were also synthesized. These datasets were then used to measure and validate the performance of a number of selected classification algorithms. The results of the experimental investigations show that the GNG had the best performance on datasets with varying inter class distances while DL performed best on the other datasets of different data problems.","Machine learning, Classification, Features selection, Noisy features, Data related problems, Synthetic data"
"Teague S,Chahl J",Time series classification of radio signal strength for qualitative estimate of UAV motion,2021,"Many common navigation solutions fall short when an aircraft’s GPS signal is either jammed or spoofed. This is typically due to the iterative nature of the estimation process, which requires an acceptably accurate initial estimate, or due to the accumulated error of inertial sensors, which are unable to directly observe the position of an aircraft. A mechanism is presented in this paper which operates on qualitative information, allowing an aircraft to remain within a vicinity despite an absence of precision localization. A long-short-term-memory neural network was used for time series classification of radio signal strength data on a light weight fixed wing UAV. Simulation results show that the two class classifier is able to determine the motion of an aircraft with respect to a radio beacon with 97.73% accuracy. The classes used for classification represent motion as either towards, or away from a beacon. A simple high level controller was designed to use the classification output and converge on a beacon. Results from this paper indicate that this unique application of qualitative navigation by the application of time series classification offers a viable alternative to aircraft navigation in GPS denied environments.","LSTM, Received signal strength, UAV, Navigation"
"Merlini D,Rossini M",Text categorization with WEKA: A survey,2021,"This work shows the use of WEKA, a tool that implements the most common machine learning algorithms, to perform a Text Mining analysis on a set of documents. Applying these methods requires initial steps where the text is converted into a structured format. Both the processing phase and the analysis of the transformed dataset, using classification and clustering algorithms, can be carried out entirely with this tool, in a rigorous and simple way. The work describes the construction of two classification models starting from two different sets of documents. These models are not meant to be good or realistic, but just illustrate how WEKA can be used for a Text Mining analysis.","Classification, Clustering, Text categorization, Text Mining,"
"Sazzed S,Jayarathna S",SSentiA: A Self-supervised Sentiment Analyzer for classification from unlabeled data,2021,"In recent years, supervised machine learning (ML) methods have realized remarkable performance gains for sentiment classification utilizing labeled data. However, labeled data are usually expensive to obtain, thus, not always achievable. When annotated data are unavailable, the unsupervised tools are exercised, which still lag behind the performance of supervised ML methods by a large margin. Therefore, in this work, we focus on improving the performance of sentiment classification from unlabeled data. We present a self-supervised hybrid methodology SSentiA (Self-supervised Sentiment Analyzer) that couples an ML classifier with a lexicon-based method for sentiment classification from unlabeled data. We first introduce LRSentiA (Lexical Rule-based Sentiment Analyzer), a lexicon-based method to predict the semantic orientation of a review along with the confidence score of prediction. Utilizing the confidence scores of LRSentiA, we generate highly accurate pseudo-labels for SSentiA that incorporates a supervised ML algorithm to improve the performance of sentiment classification for less polarized and complex reviews. We compare the performances of LRSentiA and SSSentA with the existing unsupervised, lexicon-based and self-supervised methods in multiple datasets. The LRSentiA performs similarly to the existing lexicon-based methods in both binary and 3-class sentiment analysis. By combining LRSentiA with an ML classifier, the hybrid approach SSentiA attains 10%–30% improvements in macro F1 score for both binary and 3-class sentiment analysis. The results suggest that in domains where annotated data are unavailable, SSentiA can significantly improve the performance of sentiment classification. Moreover, we demonstrate that using 30%–60% annotated training data, SSentiA delivers similar performances of the fully labeled training dataset.",
"Almasi ON,Rouhani M",A geometric-based data reduction approach for large low dimensional datasets: Delaunay triangulation in SVM algorithms,2021,"Training a support vector machine (SVM) on large datasets is a slow daunting process. Further, SVM becomes slow in the testing phase, due to its large number of support vectors (SVs). This paper proposes an effective geometric algorithm based on construction of Delaunay triangulation (DT) algorithm using Quickhull algorithm with a novel strategy to exactly identify and extract the boundary data points laid between the two classes of a dataset, and later uses these most informative data points as a reduced dataset to solve various SVM algorithms and proposes new DT-SVM algorithms Two synthetic datasets with the size of 1K incrementally up to 500K datasets are generated to extensively verify the effectiveness of the proposed DT-SVM algorithms over various data sizes and for further assessment, the most efficient version of proposed DT-SVM is applied on well-known benchmark datasets from UCI Machine Learning Repository. Two variant of sequential minimization optimization (SMO) decomposition methods, in addition to Least Square form of SVM are implemented to present the scalability of new DT-SVM algorithms in linear/nonlinear separable/non-separable large low dimensional datasets. Moreover, the most efficient version of the proposed algorithm is compared to RCH-SK as a known geometric approach in the SVM literature. The results demonstrate that while the proposed approach improves the scalability of DT-SVM in large low dimensional datasets, it leads SVM algorithms to maintain the accuracy in an acceptable range with considerably lower time in both training and testing phases with using a noticeably fewer number of SVs.","Support vector machine, Delaunay triangulation, Geometric method, Large datasets"
"Kiangala SK,Wang Z",An effective adaptive customization framework for small manufacturing plants using extreme gradient boosting-XGBoost and random forest ensemble learning algorithms in an Industry 4.0 environment,2021,"The prevailing competitive manufacturing industry calls for continuous customer satisfaction for business sustainability. With the emergence of the Industry 4.0 paradigm, product customization, which gives customers the means to personalized products to meet their needs, has become a strategy to increase companies’ value. High-tech manufacturing firms are already diving deep into Industry 4.0 standards adopting innovative strategies to outstand themselves in the market, while small manufacturing plants are slow in embracing the digital transformation. The high cost involved in acquiring indispensable resources and the lack of expertise are some of the obstacles low-tech businesses face in endorsing this new paradigm. Inspired by the customization challenges of a small manufacturing plant, our main research contribution is to develop an effective adaptive customization platform that encodes the customization data history of a small manufacturing plant, from a static database, into a dynamic machine learning model to produce personalized products for their customers accurately. Our research improves customers’ experience by reducing the customization system’s complexity consisting of inputting several parameters to obtain personalized products to a single entry. The back-end of the platform uses powerful machine learning (ML) algorithms like extreme gradient boosting (XGBoost) and Random Forest (RF) ensemble learning to match a single customer input to the desired customized product category. Our research experiments convey insights, such as the best scenarios to use XGBoost over RF algorithms for regression problems with non-linear data. The excellent experimental results achieved on both machine learning models show the merits of this customization platform.","Product customization, Industry 4.0 manufacturing, XGBoost algorithm, Ensemble learning, Random Forest (RF) algorithm"
Siraskar R,Reinforcement learning for control of valves,2021,"This paper is a study of reinforcement learning (RL) as an optimal-control strategy for control of nonlinear valves. It is evaluated against the PID (proportional–integral–derivative) strategy, using a unified framework. RL is an autonomous learning mechanism that learns by interacting with its environment. It is gaining increasing attention in the world of control systems as a means of building optimal-controllers for challenging dynamic and nonlinear processes. Published RL research often uses open-source tools (Python and OpenAI Gym environments). We use MATLAB’s recently launched (R2019a) Reinforcement Learning Toolbox\texttrademark to develop the valve controller; trained using the DDPG (Deep Deterministic Policy-Gradient) algorithm and Simulink® to simulate the nonlinear valve and create the experimental test-bench for evaluation. Simulink allows industrial engineers to quickly adapt and experiment with other systems of their choice. Results indicate that the RL controller is extremely good at tracking the signal with speed and produces a lower error with respect to the reference signal. The PID, however, is better at disturbance rejection and hence provides a longer life for the valves. Successful machine learning involves tuning many hyperparameters requiring significant investment of time and efforts. We introduce “Graded Learning” as a simplified, application oriented adaptation of the more formal and algorithmic “Curriculum for Reinforcement Learning”. It is shown via experiments that it helps converge the learning task of complex non-linear real world systems. Finally, experiential learnings gained from this research are corroborated against published research.","Curriculum learning, Graded learning, MATLAB, Optimal-control, Reinforcement learning, Valve control"
"Khan JY,Khondaker MT,Afroz S,Uddin G,Iqbal A",A benchmark study of machine learning models for online fake news detection,2021,"The proliferation of fake news and its propagation on social media has become a major concern due to its ability to create devastating impacts. Different machine learning approaches have been suggested to detect fake news. However, most of those focused on a specific type of news (such as political) which leads us to the question of dataset-bias of the models used. In this research, we conducted a benchmark study to assess the performance of different applicable machine learning approaches on three different datasets where we accumulated the largest and most diversified one. We explored a number of advanced pre-trained language models for fake news detection along with the traditional and deep learning ones and compared their performances from different aspects for the first time to the best of our knowledge. We find that BERT and similar pre-trained models perform the best for fake news detection, especially with very small dataset. Hence, these models are significantly better option for languages with limited electronic contents, i.e., training data. We also carried out several analysis based on the models’ performance, article’s topic, article’s length, and discussed different lessons learned from them. We believe that this benchmark study will help the research community to explore further and news sites/blogs to select the most appropriate fake news detection method.","Fake news, Fake news detection, Benchmark study, Machine learning, Neural network, Deep learning, BERT, Natural language processing"
"Bendali-Braham M,Weber J,Forestier G,Idoumghar L,Muller PA",Recent trends in crowd analysis: A review,2021,"When overpopulated cities face frequent crowded events like strikes, demonstrations, parades or other sorts of people gatherings, they are confronted to multiple security issues. To mitigate these issues, security forces are often involved to monitor the gatherings and to ensure the security of their participants. However, when access to technology is limited, the security forces can quickly become overwhelmed. Fortunately, more and more important smart cities are adopting the concept of intelligent surveillance systems. In these situations, intelligent surveillance systems require the most advanced techniques of crowd analysis to monitor crowd events properly. In this review, we explore various studies related to crowd analysis. Crowd analysis is commonly broken down into two major branches: crowd statistics and crowd behavior analysis. When crowd statistics determines the Level Of Service (LoS) of a crowded scene, crowd behavior analysis describes the motion patterns and the activities that are observed in a scene. One of the hottest topics of crowd analysis is anomaly detection. Although a unanimous definition of anomaly has not yet been met, each of crowd analysis subtopics can be subjected to abnormality. The purpose of our review is to find subareas, in crowd analysis, that are still unexplored or that seem to be rarely addressed through the prism of Deep Learning.","Crowd analysis, Crowd behavior analysis, Group behavior analysis, Abnormal behavior detection, Deep Learning, Video-surveillance"
"Buhendwa AB,Adami S,Adams NA",Inferring incompressible two-phase flow fields from the interface motion using physics-informed neural networks,2021,"In this work, physics-informed neural networks are applied to incompressible two-phase flow problems. We investigate the forward problem, where the governing equations are solved from initial and boundary conditions, as well as the inverse problem, where continuous velocity and pressure fields are inferred from scattered-time data on the interface position. We employ a volume of fluid approach, i.e. the auxiliary variable here is the volume fraction of the fluids within each phase. For the forward problem, we solve the two-phase Couette and Poiseuille flow. For the inverse problem, three classical test cases for two-phase modeling are investigated: (i) drop in a shear flow, (ii) oscillating drop and (iii) rising bubble. Data of the interface position over time is generated by numerical simulation. An effective way to distribute spatial training points to fit the interface, i.e. the volume fraction field, and the residual points is proposed. Furthermore, we show that appropriate weighting of losses associated with the residual of the partial differential equations is crucial for successful training. The benefit of using adaptive activation functions is evaluated for both the forward and inverse problem.","Physics-informed neural networks, Two-phase flows, Volume-of-fluid, Hidden fluid mechanics, Incompressible Navier–Stokes equations"
"Molin NL,Molin C,Dalpatadu RJ,Singh AK",Prediction of obstructive sleep apnea using Fast Fourier Transform of overnight breath recordings,2021,"The objective of this study is to address the problem of predicting the risk of obstructive sleep apnea (OSA) from overnight breath recordings collected by a subject using a smartphone or an iPhone. The dataset used in this study was collected at a health care facility and consists of breathing amplitudes of 42 subjects using the smart phone App ZeeAppnea. A total of four data mining multi-level classifiers are used on the Fast Fourier Transform (FFT) of each time series, and prediction accuracies are computed. The Random Forest (RF) and the Support Vector Machine (SVM) classifiers yielded the best results, with overall multi-level prediction accuracies of 93% and 90%, respectively; the overall multi-level prediction accuracy of manual interpretations of recordings was 55%. The binary overall accuracies for the severe OSA class were 98% (RF), 95% (SVM) and 69% (manual interpretations). Our results show that either RF or SVM can be used on the recordings obtained from ZeeAppnea instead of the time-consuming manual interpretation of charts of breathing amplitudes by medical personnel, as this would improve prediction accuracy and automate the process of this screening application.","Obstructive sleep apnea, Machine learning, Smartphone, Application, Screening"
"Alar HS,Mamaril RO,Villegas LP,Cabarrubias JR",Audio classification of violin bowing techniques: An aid for beginners,2021,"Playing violin requires both left and right hands that move into one another to produce one distinctive sound. While some violin players improve their hearing and recognize these techniques, it can be difficult for some people. Although there are names and categories for each violin technique, distinctions sometimes become ambiguous. This paper presents an audio classification model utilizing Convolutional Neural Network (CNN) that determines the sound produced by violin and classifies the used technique. The dataset used was gathered from real violin players who were tasked to record themselves playing one specific technique. The recorded tracks were then carefully trimmed to remove the noise. The pre-processed recordings served as an input to a benchmark CNN model. To fully optimize the CNN model, we modified the architecture of the model and tweaked the hyper-parameters. A comparative analysis between the two models was discussed in the latter part of this paper. The result of the analysis showed that our proposed model with an average of 94.8 % accuracy outperformed the benchmark model with an average of 87.6% accuracy. Using stratified cross-validation of five folds, we were able to measure the accuracy, training time, and predicting time of the models. A paired t-test with a p-value of 0.01 that shows a significance between the performance of the two models.","Violin, Techniques, Convolutional Neural Network, Audio classification"
"Lau AJ,Tan GW,Loh XM,Leong LY,Lee VH,Ooi KB",On the way: Hailing a taxi with a smartphone? A hybrid SEM-neural network approach,2021,"Undoubtedly, mobile taxi booking (MTB) services have resulted in a significant disruption to the lives of the general public. However, with a lot of firms offering the service in Malaysia, this will bring about confusion to users, especially in deciding which MTB service is the best for their usage. As such, this research looks into determining the antecedents that affect the adoption of MTB services. This was achieved through the utilization of an extended Mobile Technology Acceptance Model (MTAM). A total of 330 usable responses were analyzed using Partial Least Squares-Structural Equation Modeling​ (PLS-SEM) and Artificial Neural Network (ANN) that yielded novel insights which will significantly benefit numerous stakeholders. Furthermore, this research extends the literature on MTB services from the perspective of a developing country and verifies the robustness of using an extended MTAM.","Sharing economy, Mobile taxi booking services, Mobile Technology Acceptance Model (MTAM), Partial Least Squares-Structural Equation Modeling (PLS-SEM), Artificial Neural Network (ANN), Malaysia"
"Verma P,Goyal R",Influence propagation based community detection in complex networks,2021,"Interaction between nodes in a complex network showing the property of homophily tends to produce community structure in the network. The detection of these communities is of immense financial and informational value. For this purpose, we propose a semi-supervised community detection algorithm, inspired by genetic genealogy and based on Label Propagation Algorithm, that detects communities in the network by taking into account the propagation of influence from different community centers identified in the network. Analysis of our proposed algorithm showed improved performance in detecting communities in real social networks.","Social network analysis, Community detection, Complex systems"
"Stapelberg NJ,Randall M,Sveticic J,Fugelli P,Dave H,Turner K",Data mining of hospital suicidal and self-harm presentation records using a tailored evolutionary algorithm,2021,"The assessment of outcomes for the Gold Coast Mental Health and Specialist Services Suicide Prevention Strategy implementation required data on suicidal and self-harm presentations to be captured from the Emergency Department Information System (EDIS) database. Suicidal and self-harm presentations are not uniformly coded in the EDIS and require human assessment to differentiate these presentations from other cases (e.g., accidental injuries). A novel evolutionary algorithm was used to learn weighting variables from a psychiatrist-rated training dataset in order to generate an appropriate cut-off score for identifying suicidal and self-harm presentations from EDIS. The resulting Searching EDIS for Records of Suicidal Presentations (SERoSP) program was then run on a psychiatrist-rated validation dataset using the weights generated by the algorithm. SERoSP is optimised to be able to detect suicidal and self-harm presentations with a high degree of accuracy (a sensitivity of 0.95 and a specificity of 0.92). The SERoSP program is a reliable and cost-effective tool for the identification of suicidal and self-harm presentations from EDIS data, and is currently being successfully used in the suicide prevention strategy evaluation.","Suicide prevention, Evolutionary algorithms, Machine learning, Data mining, SERoSP, n-grams"
"Ray A,Chaudhuri AK","Smart healthcare disease diagnosis and patient management: Innovation, improvement and skill development",2021,"Data mining (DM) is an instrument of pattern detection and retrieval of knowledge from a large quantity of data. Many robust early detection services and other health-related technologies have developed from clinical and diagnostic evidence in both the DM and healthcare sectors. Artificial Intelligence (AI) is commonly used in the research and health care sectors. Classification or predictive analytics is a key part of AI in machine learning (ML). Present analyses of new predictive models founded on ML methods demonstrate promise in the area of scientific research. Healthcare professionals need accurate predictions of the outcomes of various illnesses that patients suffer from. In addition, timing is another significant aspect that affects clinical choices for precise predictions. In this regard, the authors have reviewed numerous publications in this area in terms of method, algorithms, and performance. This review paper summarized the documentation examined in accordance with approaches, styles, activities, and processes. The analyses and assessment techniques of the selected papers are discussed and an appraisal of the findings is presented to conclude the article. Present statistical models of healthcare remedies have been scientifically reviewed in this article. The uncertainty between statistical methods and ML has now been clarified. The study of related research reveals that the prediction of existing forecasting models differs even if the same dataset is used. Predictive models are also essential, and new approaches need to be improved.","Chronic kidney disease (CKD), Cardio vascular disease (CVD), Diabetes mellitus, Data mining, Machine learning, Neural networks"
"Al-Shabandar R,Jaddoa A,Liatsis P,Hussain AJ",A deep gated recurrent neural network for petroleum production forecasting,2021,"Forecasting of oil production plays a vital role in petroleum engineering and contributes to supporting engineers in the management of petroleum reservoirs. However, reliable production forecasting is difficult to achieve, particularly in view of the increase in digital oil big data. Although a significant amount of work has been reported in the literature in relation to the use of machine learning in the oil and gas domain, traditional forecasting approaches have limited potential in terms of representing the complex features of time series data. More specifically, in a high-dimensional nonlinear multivariate time series dataset, a shallow machine is incapable of inferring the dependencies between past and future values. In this context, a novel forecasting model for petroleum production is proposed in this work. The model is a deep-gated recurrent neural network consisting of multiple hidden layers, where each layer has a number of nodes. The proposed model has a low-complexity architecture and the capacity to track long-interval time-series datasets. To evaluate the robustness of our model, the proposed technique was benchmarked with various standard approaches. The extensive empirical results demonstrate that the proposed model outperforms existing approaches.","Deep gated recurrent unit networks, Long short-term memory networks, Recurrent Neural Networks"
"Zhang Y,Xu X",Predictions of adsorption energies of methane-related species on Cu-based alloys through machine learning,2021,"Recent studies show that the adsorption energy can be used as a descriptor of the catalytic activity in methane direct conversion. We develop Gaussian process regression models to predict DFT-calculated adsorption energies of CH4 related species – CH3 , CH2, CH, C, and H – on Cu-based alloys from elements’ readily available physical properties. As compared to conventional first-principle-based methods, the models are simple and fast to implement. They produce predictions with root mean squared errors of below 0.15 eV. The models also present numerical and statistical relationships between fundamental physiochemical parameters of doped elements and adsorption energies. Hence, they might be considered as efficient alternatives to the DFT approach for adsorption energy calculations, which allow for further assessments of certain solid catalysts’ catalytic performance.","Adsorption energy, Catalysis, Methane conversion, Machine learning, Gaussian process regression"
"Zervoudakis S,Marakakis E,Kondylakis H,Goumas S",OpinionMine: A Bayesian-based framework for opinion mining using Twitter Data,2021,"This article studies opinion mining from social media with probabilistic logic reasoning. As it is known, Twitter is one of the most active social networks, with millions of tweets sent daily, where multiple users express their opinion about traveling, economic issues, political decisions etc. As such, it offers a valuable source of information for opinion mining. In this paper we present OpinionMine, a Bayesian-based framework for opinion mining, exploiting Twitter Data. Initially, our framework imports Tweets massively by using Twitter’s API. Next, the imported Tweets are further processed automatically for constructing a set of untrained rules and random variables. Then, a Bayesian Network is derived by using the set of untrained rules, the random variables and an evidence set. After that, the trained model can be used for the evaluation of new Tweets. Finally, the constructed model can be retrained incrementally, thus becoming more robust. As application domain for the development of our methodology we have selected tourism because it is one of the most popular topics in social media. Our framework can predict users’ intention to visit a place. Among the advantages of our framework is that it follows an incremental learning strategy. That is, the derived model can be retrained incrementally with new training sets thus becoming more robust. Further, our framework can be easily adapted to opinion mining from social media on other topics, whereas the rules of the derived model are constructed in an efficient way and automatically.","Statistical Relational Learning, Probabilistic rules, Bayesian reasoning, Twitter Data, Incremental learning"
"Finlay C,Oberman AM",Scaleable input gradient regularization for adversarial robustness,2021,"In this work we revisit gradient regularization for adversarial robustness with some new ingredients. First, we derive new per-image theoretical robustness bounds based on local gradient information. These bounds strongly motivate input gradient regularization. Second, we implement a scaleable version of input gradient regularization which avoids double backpropagation: adversarially robust ImageNet models are trained in 33 h on four consumer grade GPUs. Finally, we show experimentally and through theoretical certification that input gradient regularization is competitive with adversarial training. Moreover we demonstrate that gradient regularization does not lead to gradient obfuscation or gradient masking.","Adversarial robustness, Gradient regularization, Certifiable robustness"
"G.s. T,Dheeshjith S,Iyengar SS,Sunitha NR,Badrinath P",A hybrid and effective learning approach for Click Fraud detection,2021,"Click Fraud is a fraudulent act of clicking on pay-per-click advertisements to increase the site’s revenue or to drain revenue from the advertiser. This illegal act has been putting commercial industries in a dilemma for quite some time. These industries think twice before advertising their products on websites and mobile-apps, as many parties try to exploit them. To safely promote their products, there must be an efficient system to detect click fraud. To address this problem, we propose a model called CFXGB (Cascaded Forest and XGBoost). The proposed model, classified under supervised machine learning, is a combination of two learning models used for feature transformation and classification. We showcase its superior performance compared to other related models, and make a comparison with multiple click fraud datasets with varying sizes.","Click Fraud, Ad network, Cascaded Forest, Feature transformation, XGBoost"
"Gharavi E,Veisi H,Silwal R,Gerber MS",Improving discourse representations with node hierarchy attention,2021,"Long text representation for natural language processing tasks has capture researchers’ attention recently. Beyond the sentence, finding a good representation for the text turns to the bag of the words that losses sequence order. Indeed, the text does not pattern in a haphazard way; rather, in a coherent document there exist systematic connections between sentences. Rhetorical structure theory models this connection in a tree structure format. This tree models text span and their relation. The importance of each text span is distinguished by their hierarchy type in the tree named nucleus and satellite. In this paper, we try to enrich text representation by taking into account the contribution of each phrase in the text based on its hierarchy type. We employ a deep recursive neural network as the attention mechanism to improve text representation. Our hypothesis is evaluated in a sentiment analysis framework. In addition, basic recursive neural network and predefined weighting attention consider as benchmarks. Results show that reweighting span vectors via a deeper layer of recursive neural network outperforms predefined scalar and no attention methods.","Text representation, Recursive neural network, Rhetorical structure theory, Attention mechanism, Sentiment analysis, Document embedding"
"Subramanian R,Moar RR,Singh S",White-box Machine learning approaches to identify governing equations for overall dynamics of manufacturing systems: A case study on distillation column,2021,"Dynamical equations form the basis of design for manufacturing processes and control systems; however, identifying governing equations using a mechanistic approach is tedious. Recently, Machine learning (ML) has shown promise to identify the governing dynamical equations for physical systems faster. This possibility of rapid identification of governing equations provides an exciting opportunity for advancing dynamical systems modeling. However, applicability of the ML approach in identifying governing mechanisms for the dynamics of complex systems relevant to manufacturing has not been tested. We test and compare the efficacy of two white-box ML approaches (SINDy and SymReg) for predicting dynamics and structure of dynamical equations for overall dynamics in a distillation column. Results demonstrate that a combination of ML approaches should be used to identify a full range of equations. In terms of physical law, few terms were interpretable as related to Fick’s law of diffusion and Henry’s law in SINDy, whereas SymReg identified energy balance as driving dynamics.","Machine learning, ASPEN dynamics, Distillation column, SINDy, Dynamic equation, Symbolic regression, Genetic programming"
"Mahmoodzadeh A,Mohammadi M,Ibrahim HH,Ahmed Rashid T,Aldalwie AH,Ali HF,Daraei A",Tunnel geomechanical parameters prediction using Gaussian process regression,2021,"The purpose of this study is to apply a modern intelligent method of Gaussian process regression (GPR) to predict the geological parameter of Rock Quality Designation (RQD) along the tunnel route. This method can also be used for any geological parameter prediction of tunnel future levels. The GPR method has been studied based on data obtained from 51 tunnels all over the world. Fifty data sets were utilized for intelligent modeling, while one of the data sets that belonged to Hamru tunnel in Iran, was used to evaluate the prediction approach. The comparisons’ results indicate that the GPR model’s prediction results are generally in good agreement with the actual results. The proposed GPR, on the whole, performs better than the support vector machine (SVM), artificial neural network (ANN) and linear regression (LR) in predictive analysis of the RQD parameter.","Tunnel construction, Tunnel geology, Gaussian process regression, Rock quality designation"
"Rai HM,Chatterjee K",Detection of brain abnormality by a novel Lu-Net deep neural CNN model from MR images,2020,"The identification and classification of tumors in the human mind from MR images at an early stage play a pivotal role in diagnosis such diseases. This work presents the novel Deep Neural network with less number of layers and less complex in designed named U-Net (LU-Net) for the detection of tumors. The work is comprised of classifying the brain MR images into normal and abnormal class from the dataset of 253 images of high pixels. The MR images were 1st resized, cropped, preprocessed, and augmented for the accurate and fast training of deep neural models. The performance of the Lu-Net model is evaluated using five types of statistical assessment metrics Precision, Recall, Specificity, F-score, and Accuracy, and compared with the other two types of model Le-Net and VGG-16. The CNN models were trained and tested on augmented images and validation is performed on 50 untrained data. The overall accuracy of Le-Net, VGG-16 and Proposed model received were 88%, 90%, and 98% respectively.","Deep Learning, CNN, Artificial Neural Network, Biomedical imaging, Magnetic Resonance Imaging"
"Mehrotra R,Ansari MA,Agrawal R,Anand RS",A Transfer Learning approach for AI-based classification of brain tumors,2020,"Classification of Brain Tumor (BT) is a vital assignment for assessing Tumors and making a suitable treatment. There exist numerous imaging modalities that are utilized to identify tumors in the brain. Magnetic Resonance Imaging (MRI) is generally utilized for such a task because of its unrivaled quality of the image and the reality that it does not depend on ionizing radiations. The relevance of Artificial Intelligence (AI) in the form of Deep Learning (DL) in the area of medical imaging has paved the path to extraordinary developments in categorizing and detecting intricate pathological conditions, like a brain tumor, etc. Deep learning has demonstrated an astounding presentation, particularly in segmenting and classifying brain tumors. In this work, the AI-based classification of BT using Deep Learning Algorithms are proposed for the classifying types of brain tumors utilizing openly accessible datasets. These datasets classify BTs into (malignant and benign). The datasets comprise 696 images on T1-weighted images for testing purposes. The projected arrangement accomplishes a noteworthy performance with the finest accuracy of 99.04%. The achieved outcome signifies the capacity of the proposed algorithm for the classification of brain tumors.","Image processing, Image classification, Deep Learning, Transfer Learning"
"Sidiropoulos G,Kiourt C,Moussiades L",Crowd simulation for crisis management: The outcomes of the last decade,2020,"The last decades, crowd simulation for crisis management is highlighted as an important topic of interest for many scientific fields. As the continuous evolution of computational resources increases, along with the capabilities of Artificial Intelligence, the demand for better and more realistic simulation has become more attractive and popular to scientists. Along those years, there have been published hundreds of research articles and numerous different systems have been created that aim to simulate crowd behaviors, crisis cases and emergency evacuation scenarios. For better outcomes, recent research has focused on the separation of the problem of crisis management, to multiple research sub-fields (categories), such as the navigation of the simulated pedestrians, their psychology, group dynamics etc. There have been extended research works suggesting new methods and techniques for those categories of problems. In this paper, we propose three main research categories, each one consisting of several sub-categories, relying on crowd simulation for crisis management aspects and we present the outcomes of the last decade, focusing mostly on works exploiting multi-agent technologies. We analyze a number of technologies, methodologies, techniques, tools and systems introduced throughout the last years. A comparative review and discussion of the proposed categories is presented toward the identification of the most efficient aspects of the proposed categories. A general framework toward the future crowd simulation for crisis management is presented to yield the most realistic outcomes. The paper is concluded with some highlights and open questions for future directions.","Crowd simulation, Crisis management, Multi-agent systems, Machine learning"
"Hon KK,Ng CW,Chan PW",Machine learning based multi-index prediction of aviation turbulence over the Asia-Pacific,2020,"In-flight turbulence is recognized as a major safety hazard for the global aviation system, capable of causing serious injuries to crew and passengers as well as structural damage to the aircraft. Its prediction at 1 to 2 days ahead mainly relies on numerical weather prediction (NWP) models, which suffer from various practical and inherent deficiencies. This paper applies the XGBoost algorithm in generating skillful aviation turbulence forecasts through optimal combination of a collection of conventional “turbulence indices” produced by an NWP model. Verification over a 1-year period against over 16000 aircraft pilot reports demonstrated consistent superior performance of the machine-learning based multi-index consensus (MIC) over the Asia-Pacific region, with median gains in skill score between 3% to 17% compared to constituent turbulence indices when taken individually.",
"Kreuzer D,Munz M,Schlüter S",Short-term temperature forecasts using a convolutional neural network — An application to different weather stations in Germany,2020,"Local temperature forecasts for horizons up to 24 h are required in many applications. A common method to generate such forecasts is the Seasonal Autoregressive Integrated Moving Average (SARIMA) model or, much simpler, the naïve forecast. In this paper, we test whether deep neural networks are able to improve on the results from the above mentioned methods. In addition to univariate long short-term memory (LSTM) networks, we present an alternative method based on a 2D-convolutional LSTM (convLSTM) network. For benchmarking our approach we set up a case study using data from five different weather stations in Germany. The SARIMA model and the univariate LSTM network perform quite well in the first few hours, but are then outperformed by the multivariate LSTM network and our convolutional LSTM network for longer forecast horizons. Besides, both multivariate approaches show better performance when the temperature is changing in the course of the day. Overall, our presented approach based on a convolutional LSTM network performs best on all used test data sets.","Deep learning, LSTM, SARIMA, Temperature forecasts"
"Adamopoulou E,Moussiades L","Chatbots: History, technology, and applications",2020,"This literature review presents the History, Technology, and Applications of Natural Dialog Systems or simply chatbots. It aims to organize critical information that is a necessary background for further research activity in the field of chatbots. More specifically, while giving the historical evolution, from the generative idea to the present day, we point out possible weaknesses of each stage. After we present a complete categorization system, we analyze the two essential implementation technologies, namely, the pattern matching approach and machine learning. Moreover, we compose a general architectural design that gathers critical details, and we highlight crucial issues to take into account before system design. Furthermore, we present chatbots applications and industrial use cases while we point out the risks of using chatbots and suggest ways to mitigate them. Finally, we conclude by stating our view regarding the direction of technology so that chatbots will become really smart.","Chatbot, Pattern matching, Machine learning, Natural dialog interfaces, Natural language processing, Human–computer interaction"
"Muzammel M,Salam H,Hoffmann Y,Chetouani M,Othmani A",AudVowelConsNet: A phoneme-level based deep CNN architecture for clinical depression diagnosis,2020,"Depression is a common and serious mood disorder that negatively affects the patient’s capacity of functioning normally in daily tasks. Speech is proven to be a vigorous tool in depression diagnosis. Research in psychiatry concentrated on performing fine-grained analysis on word-level speech components contributing to the manifestation of depression in speech and revealed significant variations at the phoneme-level in depressed speech. On the other hand, research in Machine Learning-based automatic recognition of depression from speech focused on the exploration of various acoustic features for the detection of depression and its severity level. Few have focused on incorporating phoneme-level speech components in automatic assessment systems. In this paper, we propose an Artificial Intelligence (AI) based application for clinical depression recognition and assessment from speech. We investigate the acoustic characteristics of phoneme units, specifically vowels and consonants for depression recognition via Deep Learning. We present and compare three spectrogram-based Deep Neural Network architectures, trained on phoneme consonant and vowel units and their fusion respectively. Our experiments show that the deep learned consonant-based acoustic characteristics lead to better recognition results than vowel-based ones. The fusion of vowel and consonant speech characteristics through a deep network significantly outperforms the single space networks as well as the state-of-art deep learning approaches on the DAIC-WOZ database.","Major Depressive Disorder, Clinical depression detection, AI-based application, HCI-based healthcare, Speech depression recognition, Deep phoneme-level learning"
"Javed A,Lee BS,Rizzo DM",A benchmark study on time series clustering,2020,"This paper presents the first time series clustering benchmark utilizing all time series datasets currently available in the University of California Riverside (UCR) archive — the state of the art repository of time series data. Specifically, the benchmark examines eight popular clustering methods representing three categories of clustering algorithms (partitional, hierarchical and density-based) and three types of distance measures (Euclidean, dynamic time warping, and shape-based), while adhering to six restrictions on datasets and methods to make the comparison as unbiased as possible. A phased evaluation approach was then designed for summarizing dataset-level assessment metrics and discussing the results. The benchmark study presented can be a useful reference for the research community on its own; and the dataset-level assessment metrics reported may be used for designing evaluation frameworks to answer different research questions.","Time series, Clustering, Benchmark, UCR archive"